# Models {#Chap-03-03-models}

<hr>

<div style = "float:right; width:45%;">
<img src="visuals/badge-models.png" alt="badge models">  
</div>  

Uninterpreted data is uninformative. We cannot generalize, draw inferences or attempt to make predictions unless we make (however minimal) assumptions about the data at hand: what it represents, how it came into existing, which parts relate to which other parts etc. One way of explicitly acknowledging these assumptions is to engage in model-based data analysis. **A statistical model is a conventionally condensed formal representation of the assumptions we make about what the data is and how it might have been generated.** In this way, model-based data analysis is more explicit about the analyst's assumptions than other approaches, such as test-based approaches, which we will encounter in Chapter \@ref(ch-03-05-hypothesis-testing). 

There is room for divergence in how to think about a statistical model, the assumptions it encodes and truth. Some will want to reason with models using language like "if we assume that model $M$ is true, then ..." or "this shows convincingly that $M$ is likely to be the true model". Others feel very uncomfortable with such language. In times of heavy discomfort they might repeat their soothing mantra:

> All models are wrong, but some are useful.
> --- @Box1979:Robustness-in-t

To become familiar with model-based data analysis, Section \@ref(Chap-03-03-models-general) introduces the concept of a **probabilisic statistical model** and explains key notions, such as *likelihood function*, *prior*, *free parameter* or *model predictions*. Section \@ref(Chap-03-03-models-representation) expands on the notation, both formulaic and graphical, which we will use in this book to communicate about models.

FILL ME

```{block, type='infobox'}
The learning goals for this chapter are:

- become acquainted with statistical models
- meet pivotal exemplars:
  - binomial model
  - Gaussian model
  - the "t-test" model
  - simple linear regression
  - naive Bayesian classifier
- understand notation to communicate models
  - formulas & graphs
- become able to implement a model in R
- become able to derive predictions from a model in R

```



<!-- - what's a model? -->
<!--   - binomial distribution is a model -->
<!--   - normal distribution is a model too -->
<!--   - given a processing tree like model for some psychological data -->
<!--     - mental chronometry: adding processes (?) -->
<!--     - similarity-based classification? -->
<!--     - signal detection theory? -->
<!-- - formal definition of model -->
<!--   - frequentist vs Bayes -->
<!--   - terminology: likelihood, prior, free parameters, predictive distributions -->
<!--     - i.i.d. data -->
<!-- - graphical notation -->
<!-- - examples -->
<!--   - binomial single group -->
<!--   - normal single group -->
<!--   - normal two groups -->
<!--   - normal three groups -->
<!--     - mental chronometry -->
<!--   - linear regression -->
<!-- - first glimpse at hierarchical modeling: -->
<!--   - therapeutic touchers -->



## Probabilistic models in statistics {#Chap-03-03-models-general}

In its most common natural sense, a "model" is a model *of* something. It intends to represent something else in a condensed, abstract and more practical form; where what is practical is conditioned by a given purpose. Often the purpose of a model is epistemic, i.e., related to knowledge gain or a deeper understanding of the world: even a model plane arguably serves the epistemic purpose of getting a better idea of what real planes look like; a model of bridge to be constructed helps us imagine how the real thing would turn out to be; this is how models differ from a more ordinary picture or sculpture without such an epistemic purpose. For any given purpose, a good model will try to represent some aspects of reality and abstract away from irrelevant features which might otherwise blur our vision.

A statistical model is a model of (what we imagine to be) a random process $R$. In most common parlance, however, we often speak of "a model of the data" or of "modeling the data", but this is only sloppy slang for "a model of (what we assume is) a random process that could generate data of this kind".

Let $D$ be (rectangular, tidy) data that represents the kind of data that random process $R$ is assumed to generate. A model $M$ for random process $R$ fixes which variables (columns) of $D$ are to be modelled as dependent and which are independent variables (and which do not matter at all). Let $D_{\text{DV}}$ by the subset of $D$ containing the depedendent variables and $D_{\text{IV}}$ the subset of $D$ containing the independent variables.^[Naturally, $D_{\text{DV}}$ and $D_{\text{IV}}$ are disjoint: it makes no sense to predict or explain $x$ based on an observation of $x$.] We want $D_{\text{DV}}$ to contain at least one variable. A model with empty $D_{\text{IV}}$ is fine.

A model $M$ for data $D$ also fixes a **likelihood function** for $D_\text{DV}$. The likelihood function determines how likely any potential data observation $D_\text{DV}$ is, given the corresponding observations in $D_\text{IV}$. Most often, the likelihood function also has **free parameters**, represented by a parameter vector $\theta$. The basic (and yet rather uninformative) notation for a likelihood function of model $M$ for data $D$ with parameter vector $\theta$ is therefore:

$$ P_M(D_\text{DV} \mid D_\text{IV}, \theta) $$ 

*Bayesian models* have an additional component, namely a **prior distribution** over parameter values, commonly written as:

$$ P_M(\theta) $$.


In sum, let's adopt the following definition. A **statistical model** $M$ for data $D$ consists of:

1. a selection of (disjoint) sets of dependent and independent variables $D_\text{DV}$ and $D_\text{IV}$, where the latter is possibly empty, but the former is not; and
2. a parameterized likelihood function: $P_M(D_\text{DV} \mid D_\text{IV}, \theta)$.

A statistical model is a **Bayesian model** if it also contains:

3. a prior distribution: $P_M(\theta)$.

The Bayesian prior over parameter values can be used to regularize inference and/or to represent any motivated and justifiable *a priori* assumptions about parameter values that are plausible given our knowledge so far. The [next section](Chap-03-03-models-parameters-priors) elaborates on parameters, priors and key differences between frequentist and Bayesian models. But first, we shouldl take a look at two simple examples of models.

### Example 1: a single draw from an urn {#Chap-03-03-models-general-urn-example}

In front of us is an urn. We cannot see what is inside. We assume (!) that there are $N = 10$ balls in the urn and that any number $0 \le k \le 10$ is black, the rest white. Our data is minimal. There is only one variable, which therefore is also our dependent variable. We have drawn a ball from the urn once, and we observed that it is black.

```{r}
minimal_data_from_an_urn <- 
  tribble(~ draw, c("black"))
```

So far, so boring. But what is a reasonable parameterized likelihood function for this case? -- Well, we do not know what the content of the urn is but, given our (modelling) assumptions, there are only eleven possible states of the world $k \in \{0, 1, \dots, 10\}$. If we assume (as part of the model structure) that the total number of balls $N$ in the urn is known $N = 10$, then the number $k$ of black balls in the urn straightforwardly entails the likelihood of the data:

$$ P_M(D = \text{"black"} \mid k) = \frac{k}{N}$$

```{block, type='beware'}
It is important to realize that this (and any other likelihood function) defines the probability, not only of the observed data, but for the whole class of *observerable data*, including observations that are only logically conceivable, but possibly ruled out by the model.
```

The model of the single-draw random process has a single free parameter $k$, which feeds into the likelihood function. We naturally think of the likelihood of the data as probabilistically dependent on the parameter value $k$.

A Bayesian model of this situation would additionally also include a *prior* over parameter values. There are only eleven possible values for $k$, so this is a discrete probability distribution. If we do not have any relevant *a priori* knowledge of the process, we might want to assign the same probability to each value of $k$:

$$ P_M(k = i) = \frac{1}{11} \text{; for all } \ i \in \{0, 1, \dots, 10\} $$

### Example 2: avocado prices by type

<div style = "float:right; width:11%;">
<img src="visuals/badge-avocado.png" alt="badge-avocado">
</div>

We must also consider a slightly less minimalistic example. The [avocado data set](#app-93-data-sets-avocado) is useful for that. As before, we load the data into a variable named `avocado_data` and do some minor data wrangling (see also Appendix Chapter \@ref(app-93-data-sets-avocado)):

```{r, echo = F}
avocado_data <- read_csv('data_sets/avocado.csv') %>% 
  # remove currently irrelevant columns
  select( -X1 , - contains("Bags"), - year, - region) %>% 
  # rename variables of interest for convenience
  rename(
    total_volume_sold = `Total Volume`,
    average_price = `AveragePrice`,
    small  = '4046',
    medium = '4225',
    large  = '4770',
  )
```

```{r, eval = F}
avocado_data <- read_csv(url('https://raw.githubusercontent.com/michael-franke/intro-data-analysis/master/data_sets/avocado.csv')) %>% 
  # remove currently irrelevant columns
  select( -X1 , - contains("Bags"), - year, - region) %>% 
  # rename variables of interest for convenience
  rename(
    total_volume_sold = `Total Volume`,
    average_price = `AveragePrice`,
    small  = '4046',
    medium = '4225',
    large  = '4770',
  )
```

We are interested in the random process that generates avocado prices. The data relevant for modeling this random process contains `average_price` as the dependent variable and `type` as the independent variable. We could also say that we are interested in predicting / explaining the average prices in terms of the avocado type.To get a feeling for how the data to be modeled looks like, here are histograms for the price data for conventionally and organically grown avocados:

```{r}
avocado_data %>% 
  ggplot(aes(x = average_price, fill = type)) +
  geom_histogram(binwidth = 0.01) +
  facet_wrap(type ~ ., ncol = 1) + 
  ylab('') +
  xlab('Average price') +
  theme(legend.position = "none")
```


Our model assumes that the data observations in `average_price` are samples from a normal distribution, whose mean $\mu$ and standard deviation $\sigma$ are free parameters, one pair of $\mu$ and $\sigma$ for each `type` of avocado. So, this model has four free parameters, which constitute the parameter vector $\theta = \langle \mu_c, \sigma_c, \mu_o, \sigma_o \rangle$. As for the likelihood function, if $\vec{y}$ is the vector `average_price`, so that $y_i \in \mathbb{R}^+$ is the average price observed in row $i$, and if $\vec{x}$ is an indicator variable such that $x_i \in \{ 1, 0\}$ is the entry for the type of avocado in line $i$ where 1 represents conventionally grown and 0 represents organically grown, and if there are $k$ rows in the data set, the likelihood function can be written as:

$$ P_M(\vec{y} \mid \vec{x}, \theta) = 
\prod_{i = 1}^k x_i \ \text{Normal}(y_i, \mu_c, \sigma_c) \ + \ (1- x_i) \  \text{Normal}(y_i, \mu_o, \sigma_o)  $$

If we aspire to handle a Bayesian model, we need to supply a prior for parameters $\theta$ as well. General strategies of fixing priors for Bayesian data analysis are discussed in the next subsection. To give a concrete example for this case, we could assume that all parameter vectors are independent of each other and assume that the means $\mu_c$ and $\mu_o$ are themselves normally distributed. We could use a *truncated normal distribution*^[A truncated normal distribution is like a normal distribution, but restricted to a certain range of possible values. In general, if $P$ is a continuous probability distribution on some interval which properly contains $[a;b]$, a truncated version of $P$ to the interval $[a;b]$ such that:
$$ \text{Trunc-}P(x, \text{min} = a, \text{max} = b) = 
\begin{cases} 
\frac{P(x)}{\int_{a}^{b} P(x') \text{d}x'} & \text{ if } a \le x \le b \\
0 & \text{otherwise}
\end{cases} $$ 
] as the priors for the standard deviations $\sigma_c$ and $\sigma_o$:

$$ 
\begin{align*}
  P(\mu_c, \sigma_c, \mu_o, \sigma_o) & = P(\mu_c) \ P(\sigma_c) \ P(\mu_o) \ P(\sigma_o), \text{ where} \\
  P(\mu_c) & = \text{Normal}(\mu_c, \mu = 1.5, \sigma = 0.25)  \\
  P(\mu_o) & = \text{Normal}(\mu_o, \mu = 1.5, \sigma = 0.25)  \\
  P(\sigma_c) &= \text{Trunc-Normal}(\sigma_c, \mu = 0.2, \sigma = 0.05, \text{lower} = 0) \\
  P(\sigma_o) &= \text{Trunc-Normal}(\sigma_o, \mu = 0.25, \sigma = 0.1, \text{lower} = 0)
\end{align*}
$$

## Parameters, priors, probability and preditions {#Chap-03-03-models-parameters-priors}

We defined a model as containing a parameterized likelihood function, and, if it is a Bayesian model, also a prior distribution distribution:

$$ 
\begin{align*}
  \text{Likelihood: } & P_M(D \mid \theta) \\
  \text{Prior: } & P_M(\theta) \ \ \ \text{[if Bayesian]}
\end{align*}
$$ 

More needs to be said about what a parameter is, what a prior distribution $P_M(\theta)$ is, and what the difference is between a non-Bayesian / frequentist model without priors over $\theta$ and a Bayesian model with priors over $\theta$.

The running example for this section is the **Binomial Model**, which is also included in the cast of main characters in Section \@ref(Chap-03-03-models-examples).^[We should actually speak of a class of (infinitely many) models, all sharing the same likelihood function. Sloppily, we still speak of "the" Binomial Model.] The Binomial Model is a generalization of [the urn-model covered in the previous section](Chap-03-03-models-general-urn-example). We imagine a flip of a coin with bias $\theta \in [0;1]$, which is flipped $N$ times. We are interested in the number $k$ of heads (represented as an outcome of 1). The likelihood function for this model is the [Binomial distribution](app-91-distributions-binomial):

$$ P_M(k \mid \theta, N) = \text{Binomial}(k, N, \theta) = \binom{N}{k}\theta^k(1-\theta)^{N-k} $$

As a concrete application case, we consider a case with $N=24$ flips and $k=7$ head outcomes.

### What's a model parameter?

Parameters are defined by their role: changing a model parameter changes the likelihood of the data. Figure \@ref{ch-03-02-LH-Binomial-Model} shows the likelihood function of the Binomial Model for $\theta \in [0;1]$. 

```{r ch-03-02-LH-Binomial-Model, fig.cap= "Likelihood function for the Binomial Model, for $k=7$ and $N=24$.", echo = F}
# data
k <- 7
N <- 24

# plot LH-function
tibble(
  theta = seq(0,1, length.out = 401),
  LH = dbinom(x = k, size = N, prob = theta)
) %>% 
  ggplot(aes(x = theta, y = LH)) +
  geom_line(size = 3) +
  labs(
    x = latex2exp::TeX("Coin bias $\\theta$"),
    y = latex2exp::TeX("likelihood $Binomial(k=7, N=24, \\theta)$")
  )
```

Several things are important to note, even though their significance might only reveal itself in full much later. Firstly, since there is a direct influence of a model parameter on the likelihood of data observations, we might be able to express subjective beliefs about that parameter value, even if the paramter itself is not clearly interpretable in intuitive ways. In other words, we might hold beliefs about the likelihood of the data, and we might express these beliefs by beliefs about likelihood parameter vectors. Secondly, not all parameters are equal. Some parameters may have a much stronger effect on the likelihood than others (all else equal). Just counting the number of model parameters as an indicator of model complexity will therefore not be enough.

### Priors over parameters

The prior distribution over parameter values $P_M(\theta)$ is an integral part of a model, when we adopt a Bayesian approach to data analysis. This entails that two (Bayesian) models can share the same likelihood function, and yet ought to be considered as different models. 

In Bayesian data analysis priors $P_M(\theta)$ are most saliently interpreted as encoding the modeller's prior beliefs about the parameters in question. As mentioned, this need not necessarily be beliefs derived from fundamental convictions about coin biases, means or standard deviations; these could be beliefs held because of the effects certain parameter values have on the likelihood of the data. Ideally, the beliefs that support the specification of a prior should be supported by argument, results of previous research or other clearly justifiable motivations. But these informed subjective priors are really just one way in which priors over parameters can be justified.

There are three main types of motivations for priors $P_M(\theta)$, and it is possible that these motivations are mixed in the choice of a particular prior for a particular application:

1. **Subjective priors** capture the modeller's subjective beliefs in the sense described above.
2. **Objective priors** are priors that, as some argue, *should* be adopted for a given likelihood function to avoid conceptually paradoxical consequences.
3. **Practical priors** are priors that are used because they simplify a mathematical calculation or a computer simulation.

Orthogonally to the kind of motivation given for a prior, we can distinguish different priors based on how strongly they commit the modeller to a particular range of parameter values. The most extreme case are **uninformative priors** which assign the same level of credence to all paramter values. Uninformative priors are also called *flat priors* because they express themselves as flat lines for discrete probability distributions and continuous distributions defined over a finite (convex) interval. It is possible to maneuver uninformative priors also for continuous distributions defined over an unbounded interval, in which case we speak of *improper priors* (to remind ourselves that, mathematically, we are doing something tricky). Informative priors, on the other hand, can be weakly informative or strongly informative, depending on how much commitment they express. The most extreme case of commitment would be expressed in a **point-valued prior**, which puts all probabiliy on a single value of a parameter. Since this is no longer a respectable probability distribution, although it satisfies the definition, we speak of a *degenerate prior* here. 

Figure \@ref(ch-03-02-models-types-of-priors) shows examples of objective, uninformative, as well as weakly or strongly informative priors for the Binomial Model.^[We will not go into the topic of objective priors in this course. This is a topic we must reserve for a follow-up course. It is therefore also not important to "see" from Figure \@ref(ch-03-02-models-types-of-priors) how or why the curve shown in an objective prior. For what it's worth, the objective prior shown here is given by $\theta \sim \text{Beta}(0.5,0.5)$.]

```{r ch-03-02-models-types-of-priors, echo = F, fig.cap = "Examples of different kinds of Bayesian priors for the coin bias $\theta$ in the Binomial Model."}

tibble(
  theta = seq(0, 1, length.out = 401),
  objective = dbeta(theta, 0.5, 0.5),
  uninformative = dbeta(theta, 1, 1),
  `weakly informative` = dbeta(theta, 2, 3),
  `strongly informative` = dbeta(theta, 20, 30)
) %>% 
  pivot_longer(
    cols = -1,
    names_to = "prior_type",
    values_to = "prior"
  ) %>% 
  ggplot(aes(x = theta, y = prior)) +
  geom_line(size = 2) +
  facet_wrap(~ prior_type, ncol = 2, scales = "free") +
  labs(
    x = latex2exp::TeX("Coin bias $\\theta$"),
    y = latex2exp::TeX("Prior probability $P_{M_i}(\\theta)$"),
    title = latex2exp::TeX("Different kinds of prior probability of coin bias $\\theta$ for the Binomial Model.")
  ) 

```


### Two notions of probability (revisited)

To understand why frequentist models do not have priors, but Bayesian models do, we need to revisit the interpretaion of the notion of probability, in particular frequentism and subjectivism. We should be reminded that although both notions imply different approaches how to deal with probabilities, the mathematical properties are quite similar [@kruschke2015].

A crude and overly simplified version of why frequentist models do not contain priors is this. Extreme frequentism denies that a probability distribution over a latent parameter like $\theta$ is meaningful. It cannot be justified or defended in a scientifically rigorous manner. The only statements about probabilities that are conceptually sound, according to a frequentist interpretation, are those that derive from intuitions about limiting frequencies when (hypothetically) performing a random process (like throwing a dice or drawing a ball from an urn). Bluntly put, there is no ``(thought) experiment'' which can be repeated so that its objective results, on average, align with whatever subjective prior beliefs the Bayesian analysis needs. As a result, the frequentist approach to statistical inference needs alternative methods for parameter estimation --- methods that do \emph{not} rely on (subjective) priors $P(\theta)$.

In contrast, a parameter in *Bayesian approaches* is conceptualized as a random variable with its own distribution (the posterior) that summarizes the current state of knowledge or a hypothetical state of belief which to assume serves good practical purposes. 

## Three pillars of data analysis {#Chap-03-03-models-three-pillars}

There are three main uses for models in statistical data analysis:

1. **Parameter inference**: Based on model $M$ and data $D$, we try to infer which value of the parameter vector $\theta$ we should believe in, or work with (e.g., base our decision on). Paremeter inference can also serve knowledge gain, especially if (some component of) $\theta$ is theoretically interesting.
2. **Model comparison**: If we formulate at least two alternative models, we can ask which model better explains or better predicts some data. In some of its guises, model comparison helps with the question of whether a given data set provides evidence in favor of one model and against another other, and if so, how much.
3. **Prediction**: Models can also be used to make predictions about future or hypothetical data observations. 

The frequentist and the Bayesian approach each have their own methods and techniques to do inference, comparison and prediction. Even within each approach (frequentist or Bayesian) and a particular goal (inference, comparison or prediction) there is not necessarily unanimity about the best method or technique. 

Table \@ref(tab:ch-03-03-pillars-of-DA) lists the most common / salient methods used for each goal in the frequentist and Bayesian approach. Large part of the remainder of this course will be dedicated to understanding the methods name-dropped in this table, and to compare them against each other and further, as of yet unmentioned alternatives. Chapter \@ref(Chap-03-06-model-comparison) deals with model comparison, Chapter \@ref(ch-03-04-parameter-inference). The second main goal of this course is to understand the relation between model-based data analysis, as summarized in Table \@ref(tab:ch-03-03-pillars-of-DA), to test-based approaches as described in Chapter \@ref(ch-03-05-hypothesis-testing) and Chapter \@ref(ch-03-07-hypothesis-testing-Bayes).

```{r ch-03-03-pillars-of-DA, echo = F}
table_data <- tribble(
  ~goal, ~frequentist, ~Bayesian,
  "inference", "MLE: $\\hat{\\theta} = \\arg \\max_{\\theta}\  P_M(D \\mid \\theta)$", "posterior: $P_M(\\theta \\mid D)$",
  "comparison", "AIC, LR-test", "Bayes factor",
  "prediction", "MLE-based: $P_M(D_{rep} \\mid \\hat{\\theta})$", "Posterior-based: $P_M(D_{rep} \\mid D)$"
)
knitr::kable(
  table_data,
  escape = F,
  caption = "Most common/salient methods of frequentist and Bayesian approaches for the three major goals of model-based data analysis. The abbreviations used are: MLE for 'maximum likelihood estimate', AIC for 'Akaike information criterion', LR-test for 'likelihood-ratio test' and $D_{rep}$ for 'repeat data'.", 
  booktabs = TRUE
)
```


The three pillars of data analysis mentioned above are tightly related, of course. For one, model comparison is often parasitic on prediction: whereas prediction asks which data is to be expected, given the model, model comparison looks at how well a given data set is or would have been predicted by different models. For another, parameter inference and data predictions are something like each other's reverse operations. Let's elaborate on the latter briefly.

If we flip a coin flip once, the likelihood of each outcome $x \in X = \{0;1\}$ (representing heads or tails, encoded as 1 and 0, respectively) can be modeled with the **Bernoulli distribution** as follows, where $\theta \in [0;1]$ is the coins bias towards landing heads:

$$P_M( X = x \mid \theta)=\theta^{[x]}(1-\theta)^{(1-[x])}$$

This likelihood function relates two variables of interest: the coin flip outcome (= data $D$) $x$ and the coin's bias (= model parameter $\theta$). Depending on what is given or assumed to be known, we can then use the same likelihood function, to either infer something about the unknown parameter $\theta$ or, when $\theta$ is given make predictions about the unknown outcome $x$. 

To make this even clearer, we can temporarily use the following bracket notation: the bracket $[ \cdot ]$ indicates that the bracketed parameter is treated as known, given or assumed. The **predicitive distribution** for unknown data $x$ is then:

$$\text{Predictive Distribution: }\ \ \ \ F(\theta) = P_M(X=x \mid [\theta])=[\theta]^x(1-[\theta])^{(1-x)}$$



But often the contrary is the case, that is one is interested in the value of $\theta$ by a given data set. Then $\theta$ is unknown and the data are observed. Treating $\theta$ as parameter instead of $x$ leads to the *likelihood function* --- a mathematical formula that specifies the plausibility of the data as a function of $\theta$. It states the probability of any possible observation:
$$\text{Likelihood Function: }\ \ \ \ F(x) =P_M( [X = x] \mid \theta)=\theta^{[x]}(1-\theta)^{(1-[x])}$$
 Figure \@ref(fig:ch-03-03-likelihood-distribution) shows the likelihood function associated with the one-coin-flip model when the observed and known outcome is $x = 1$ (heads). Notice that the likelihood function is not a probability distribution and thus does not necessarily integrate or sum to 1, even though it does in the case at hand.

```{r ch-03-03-likelihood-distribution, echo = FALSE, fig.cap= "Bernoulli likelihood for the one-coin-flip-model with observed outcome $x =1$ (heads)."}
# x-axis
stepsize <- 100
theta = seq(from = 0, to = 1, by = 1/stepsize)

# beroulli likelihood
likelihood_bern <- tibble(
  theta = theta,
  n = 1,                                    # number of observations
  k = 1,                                    # number of heads
  likelihood = (theta^k)*(1-theta)^(n-k)     # bernoulli likelihood
) %>%
mutate(likelihood_norm = (likelihood / sum(likelihood)*stepsize)
           )
# plot likelihood
ggplot(likelihood_bern, aes(x = theta, y = likelihood_norm)) +
  geom_line(size = 2) +
  labs(x = expression(theta), y = "Likelihood")
```




## Notation & graphical representation {#Chap-03-03-models-representation}

If it is important to communicate the assumptions underlying a statistical argument, and if models are means of making formally explicit these assumptions, then it follows that efficient communication of models is important too. We here follow common practice of representing models using both a special purpose formulaic notation and, where useful, a graph-based visual display in which probabilistic dependencies are perspicuously represented.

The running example for this section is the **Binomial Model**, which is also included in the cast of main characters in Section \@ref(Chap-03-03-models-examples). The Binomial Model is a generalization of [the urn-model covered earlier in this chapter](Chap-03-03-models-general-urn-example). We imagine a flip of a coin with bias $\theta \in [0;1]$, which is flipped $N$ times. We are interested in the number $k$ of heads (represented as an outcome of 1). The likelihood function for this model is the [Binomial distribution](app-91-distributions-binomial):

$$ P_M(k \mid \theta, N) = \text{Binomial}(k, N, \theta) = \binom{N}{k}\theta^k(1-\theta)^{N-k} $$

For purposes of illustration we use a [Beta distribution](app-91-distributions-beta) for the prior of $\theta$, but set its parameters so that the ensuing distribution is flat (uninformative priors):

$$ P_M(\theta) = \text{Beta}(\theta, 1, 1) $$ 

### Formula notation

To concisely represent models, we use a special notation, which is very intuitive when we think about sampling. Instead of the above notation for the prior we write:

$$ \theta \sim \text{Beta}(1,1) $$ 

The symbol "$\sim$" is often read as "is distributed as". You can also think of it as meaning that $\theta$ is sampled from a uniform distribution.

Similarly, for the likelihood function, we would just write:

$$k \sim \text{Binomial}(\theta, N).$$

### Graphical notation

When models get very complex and incorporate many parameters it can be difficult to tease out all relations between the model components. In such a situation a graphical notation of a model might be helpful. We here adopt the convention described in Wagenmakers and Lee's *Bayesian Cognitive Modelling* (2014): the graph structure is used to indicate dependencies between the variables, with children depending on their parents [@leeWagen2014]. We represent every relevant variable as a node in a directed acyclic graph structure (a probabilistic network). In visualizing this, we use the following general conventions:

- known or unknown (= latent) variable
  - *shaded nodes*: observed variables
  - *unshaded nodes*: unobserved / latent variables
  
- kind of variable:  
  - *circular nodes*: continuous variables
  - *square nodes*: discrete variables
  
- kind of dependency:
  - *single line*: stochastic dependency
  - *double line*: deterministic dependency

For the Binomial Model this results in the relevant variables:

- number of trials ($N$)
- number of success ($k$)
- probability for a success ($\theta$)

Of these $N$ and $k$ are observed and discrete variables, and $\theta$ is a latent continuous variable. Clearly,the number of heads $k$ depends on the coin bias $\theta$ as well as on the number of trials $N$. This yields a graphical and formulaic notation as in Figure \@ref(fig:ch-03-02-Binomial-Model).

```{r ch-03-02-Binomial-Model, echo = F, fig.cap="The Binomial Model.", out.width = '40%'}
knitr::include_graphics("visuals/binomial-model.png")
```

### Multiple observations

When we have several observations, like in the avocado price data set, we use indexed variables. For exmple, the likelihood function handled in Section XYZ for modeling avocado prices as a function the type of avocado was previously written like so:

$$ P_M(\vec{y} \mid \vec{x}, \theta) = 
\prod_{i = 1}^k x_i \ \text{Normal}(y_i, \mu_c, \sigma_c) \ + \ (1- x_i) \  \text{Normal}(y_i, \mu_o, \sigma_o)  $$

An alternative notation for this likelihood function achieves conciseness with the help of the `~` symbol:

$$ y_i \sim \begin{cases} \text{Normal}(\mu_c, \sigma_c) & \text{if} \ x_i = 1 \\ 
\text{Normal}(\mu_0, \sigma_0) & \text{otherwise} \\ \end{cases} $$ 

Notice that this latter notation makes clearer than the previous, that each observation in vector $\vec{y}$ is what is often written as "iid": **i**ndependent of all other observations and **i**dentically **d**istributed just like all other observations. Reversedly, when we see concise notatation like $y_i \sim \dots$ we understand that the likelihood of the whole data is to be calculated as the product of the likelihood of each individual observation.

In the graphical representation, we may conveniently group variables with the same index together in dotted boxes, like shown below for the Linear Regression with Two Groups Model, which is introduced in the next section:

```{r, echo = F, out.width = '60%'}
knitr::include_graphics("visuals/linear-regression-with-groups.png")
```

## Strolling the zoo of models {#Chap-03-03-models-examples}

Let's have a look at some more models. Some of the characters we will encounter here, will play leading roles in the plot to come. Some are for familiarization and exercise. All are pleasant.

### The Binomial Model

We just repeat the Binomial Model discussed above for completeness in Figure \@ref(fig:ch-03-02-Binomial-Model-repeated).

```{r ch-03-02-Binomial-Model-repeated, echo = F, fig.cap="The Binomial Model (repeated from before).", out.width = '40%'}
knitr::include_graphics("visuals/binomial-model.png")
```

### Flip-and-Draw Model

The Flip-and-Draw Model is a model for the flip-and-draw scenario introduced in Section \@ref(Chap-03-01-probability-marginal). Remember that we first flip a coin and then draw from one of two urns, depending on the outcome of the coinflip. Let's generalize this and assume that the coin has a possibly unknown bias $\theta$. The probability of sampling a black or white ball from the first urn is given by a probability vector $\vec{p_0} = \langle 0.2, 0.8 \rangle$ (where the first entry gives the probability of sampling a black ball). The other urn has a corresponding probability vector $\vec{p_1} = \langle 0.4, 0.6 \rangle$. The [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) gives the probability of sampling an index from a given probability vector $\vec{p}$. It is defined as:

$$ \text{Categorical}(i) = \vec{p}_i $$

Figure \@ref(fig:ch-03-02-FlipDraw-Model) gives a concise representation of the model.

```{r ch-03-02-FlipDraw-Model, echo = F, fig.cap="The Flip-and-Draw Model.", out.width = '30%'}
knitr::include_graphics("visuals/flip-and-draw-model.png")
```

### Flip-and-Draw-Hypergeometric Model

The Flip-and-Draw-Hypergeometric Model is exactly like the previous Flip-and-Draw Model, except that we allow ourselves to sample repeatedly *without replacement* from urn the coin flip selected for us. The probability of observing $k$ black balls when drawing $n$ balls from an urn which contains $N$ balls in total out of which $K$ balls are black, when we do not put each drawn ball back into the urn is described the the so-called [hypergeometric distribution](https://en.wikipedia.org/wiki/Hypergeometric_distribution). The hypergeometric distribution assigne to each $k \in \{\max(0, n+K-N), \dots, \min(n,K)\}$ the probability mass:

$$ \text{Hypergeometric}(k \mid n, K, N) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}  $$ 

Suppose we keep the total number of urns fixed to $N = 100$ and always draw $n = 20$ balls. The two urns we have (indexed 0 and 1) hold $K_0 = 20$ and $K_1 = 80$ black balls. For a Bayesian model we could use a $\text{Beta}$ prior for $\theta$. Figure \@ref(fig:ch-03-02-FlipDraw-Hypergeometric) shows the model.

```{r ch-03-02-FlipDraw-Hypergeometric, echo = F, out.width = '60%', fig.cap="The Flip-and-Draw-Hypergeometric Model."}
knitr::include_graphics("visuals/flip-and-draw-hypergeometric.png")
```

### T-Test Model: comparing two groups

Figure \@ref(fig:ch-03-02-Simple-Linear-Regression) shows the resulting model.

```{r ch-03-02-T-Test-Model, echo = F, out.width = '60%', fig.cap="The T-Test Model."}
knitr::include_graphics("visuals/t-test-model.png")
```


### Simple Linear Regression Model

Figure \@ref(fig:ch-03-02-Simple-Linear-Regression) summarizes the full model.

```{r ch-03-02-Simple-Linear-Regression, echo = F, out.width = '60%', fig.cap="The Simple Linear Regression Model."}
knitr::include_graphics("visuals/linear-regression-model.png")
```

### Linear Regression with Two Groups

The full model is shown in Figure \@ref(fig:ch-03-02-Linear-Regression-Groups).

```{r ch-03-02-Linear-Regression-Groups, echo = F, out.width = '60%', fig.cap="The Linear Regression with Two Groups Model."}
knitr::include_graphics("visuals/linear-regression-with-groups.png")
```

## How to create a model

The approach described here is based on [@mcelreath2015; @kruschke2015]. Although the approach is introduced in a Bayesian context, it can be used as a general guideline (with some caveats):

* Identify the relevant variables according to the hypothesis (Measurement scales, predicted vs. predictor variables).
* Define the descriptive model for the relevant variables.
  + likelihood distribution (distribution of each outcome variable that defines the plausibility of individual observations)
  + parameters (define and name all parameters of the model in order to relate the likelihood to the predictor variable(s))
* Bayesian context: Specify prior distribution(s).

Further steps that will be subject of later chapters:

* Inference and interpretation of the results.
* Model checking (Is the defined model adequate?)

*In the following we are interested in the question if a certain coin is biased.*

**First step** is to *identify the relevant variables*. For the coin flip experiment a coin is flipped $n$ times, whereby each observation consists of $x$ trials. Imagine for example 10 people flip a coin 30 times, then $n=10$ and $x=30$. The variable *coin flip* $Y$ is dichotomous with the possible outcomes "head" and "tail". For each observation the outcome is recorded: "0" for coming up tail and "1" for coming up head. The data are summarized for each observation. The variable $k$ indicates the number of heads coming up in $x$ trials.

In **the second step** a *descriptive model for the identified variables* has to be defined. An underlying probability $\theta$ is assumed, indicating the probability of heads coming up $p(y=1)$. The probability that the outcome is head, given a value of parameter $\theta$, is the value of $\theta$ [@kruschke2015, p.109]. Formally, this can be written as
$$p(y=1|\theta)=\theta$$
As only two outcomes of $Y$ exists, the probability that the outcome is tail is the complementary probability $1-\theta$. Both probabilities can be combined in one probability expression:
$$Pr(Y|n,\theta)=\frac{n!}{y!(n-y)!}\theta^{y}(1-\theta)^{n-y}.$$
This probability distribution is called the **Binomial distribution**. The fracture at the beginning indicates how many ordered sequences of $n$ outcomes a count $y$ have.

```{r ch-03-03-binomial-distribution-coin-flip-example, echo = FALSE, fig.cap = "Binomial-distribution for different coin biases"}
# how many trials
trials = 30

rv_binom <- tibble(
  x = seq(0, trials),
  y1 = dbinom(x, size = trials, p = 0.2),
  y2 = dbinom(x, size = trials, p = 0.5),
  y3 = dbinom(x, size = trials, p = 0.8)
) %>%
  pivot_longer(cols = starts_with("y"),
               names_to  = "parameter",
               values_to = "y") %>%
  mutate(
    parameter = case_when(parameter == "y1" ~ "(n,0.2)",
                          parameter == "y2" ~ "(n,0.5)",
                          parameter == "y3" ~ "(n,0.8)")
  )

# dist plot
ggplot(rv_binom, aes(x, y, fill = parameter)) +
  geom_col(position = "identity", alpha = 0.8) +
  labs(fill = "X ~ Binomial", y = "Probability")

```

When the coin is flipped only once, then the probability can be written as:
$$Pr(Y|\theta)=\theta^{y}(1-\theta)^{1-y}.$$
This special variant of the Binomial distribution is the so-called **Bernoulli distribution**. To see the connection to the first considerations: When the outcome "head" is observed the equation reduces to $Pr(y=1|\theta)=\theta$ and when the outcome "tail" is observed the equation results in $Pr(y=0|\theta)=(1-\theta).$

Accordingly, for the introductory example it can be noted that the coin flip variable $Y$ *is distributed as* Binomial distribution. (Note: For Bayes' rule the *likelihood function* is needed. Remember, the likelihood function treats $\theta$ as unknow and the data as known. This role of parameter is exchanged in a probability distribution.)

```{r ch-03-03-binomial-likelihood-coin-flip-example, echo = FALSE, fig.cap = "Binomial likelihoods for different observed coin flip outcomes."}

binomial.likelihood <- function(n, k, theta){theta^k*(1-theta)^(n-k)}

tibble(
  n = 10,
  theta = seq(from=0, to=1, by=0.01),
  y_1 = binomial.likelihood(n,2,theta),
  y_2 = binomial.likelihood(n,5,theta),
  y_3 = binomial.likelihood(n,8,theta)
) %>%
pivot_longer(cols = starts_with("y"),
               names_to  = "parameter",
               values_to = "y") %>%
  mutate(
    parameter = case_when(parameter == "y_1" ~ "(n=10,x=20,p)",
                          parameter == "y_2" ~ "(n=10,x=50,p)",
                          parameter == "y_3" ~ "(n=10,x=80,p)")
  ) %>%
ggplot(aes(theta, y, color = parameter)) +
  geom_line(size = 2) +
  labs(color = "X ~ Binomial", y = "Likelihood", x = expression(theta))
```

**The third step** is solely a *Bayesian idea*, that is the *incorporation of prior knowledge*. What do we believe about the coin bias $\theta$ before seeing the data? Assuming that no expectation about $\theta$ exists a priori, indicating that all values of $\theta$ between 0 and 1 are equally probable. This can be modeled by a uniform distribution or as already visualized as Beta distribution with parameters a=1 and b=1 (see following figure).

```{r ch-03-03-prior-distribution-coin-flip-example, echo = FALSE, fig.cap = "Using uninformative prior distributions: The Uniform(0,1) and Beta(1,1) prior."}

tibble(
  x = seq(from = -0.01, to = 1.01, by = 0.01),
  y_1 = dunif(x, min = 0, max = 1),
  y_2 = dbeta(x, shape1 = 1, shape2 = 1), # only for legend
  beta = dbeta(x, shape1 = 1, shape2 = 1)
) %>%
  pivot_longer(cols = starts_with("y"),
               names_to  = "prior",
               values_to = "y") %>%
  mutate(
    prior = case_when(prior == "y_1" ~ "Uniform(0,1)",
                      prior == "y_2" ~ "Beta(1,1)")
  ) %>%
ggplot() +
  geom_line(aes(x, y, color = prior), size = 2) +
  geom_line(aes(x, beta), color = project_colors[2], size = 2, linetype = "dashed") +
  labs(y = "Density", x = expression(theta)) +
  ylim(0,1.5)
```

So far, the coin flip model is defined conceptually. In the following some notational considerations have to be made.


### An outlook: Hierarchical models

Often data can be considered as part of an overall structure. Single observations can be modelled belonging into different groups. These groups in turn are part of a superordinate group etc. Such information are presented in a model in form of a hierarchy.

For example, consider again the coin flip experiment. The outcome of *head* is influenced by the probability $\theta$. Further, $\theta$ is assumed to be distributed as Beta(1,1). Remember that the parameter a and b of a Beta-distribution can be considered in this context as: $a=$number of heads and $b=$ number of tails, consequently, $n=a+b$.

#### Reparameterization of a Beta distribution

Probability distributions can be described by their *central tendency* and *spread* (or dispersion). The *mode* of a Beta distribution is defined as:

$\omega=\frac{a-1}{a+b-2}$,

and the concentration as:

$\kappa=a+b.$

The nice thing is, that the definition of the *mode* as well as of the *concentration* consists solely of the parameters a and b. Therefore, it is possible to re-express the parameters of a Beta density in terms of $\omega$ and $\kappa$, such that:

$$Beta(a,b)=Beta\left(\omega(\kappa -2)+1, (1-\omega)(\kappa -2)+1\right).$$

*Why this is useful? And what is its value in connection with hierarchical modeling?*

Return back to the coin flip experiment. So far, the parameters of the prior on $\theta$ are fixed: $a=1$ and $b=1$. Assume that we get further information: The manufacturing process of the coins has a bias near $\omega$ (example taken from [@kruschke2015]). But how to incorporate this additional knowledge in the model?

At this point, the hierarchy and the reparameterization come into play. Hierarchy because a further assumption is placed on top of the existing model and reparameterization, because we want to express the prior in terms of the mode $\omega$.

Such that the model can be assumed as follows:

![Graphical notation hierarchical Beta-Binomial Model - One group](chapters/images/binom-oneLevel.png)


Now, the parameters of the hyperpriors (Gamma and Beta) are fixed, but they can be treated as parameters as well ... as such hierarchical models can be created with any degree of complexity:

![Graphical notation hierarchical Beta-Binomial Model - One group](chapters/images/hierarchical-model.png)

## Further examples

### Difference between two groups

In the introductory example we asked for the underlying probability $\theta$ of a single coin that was flipped repeatedly.
Consider now, that a second coin $y_2$ is introduced. One question that arises might be for example: *How different are the biases of the two coins?*

```{r}
#simulate flips of two coins
sample.space <- c(0,1)
##First coin:
theta1 <- 0.5              # probability of a success (here: head)
X1 <- 30                   # number of trials in the experiment
n1 <- 100                  # number of observations
k1 <- 0                    # number of heads [initialization]

for (i in 1: n1) {
  k1[i] <- sum(sample(sample.space, size = X1, replace = TRUE,
                     prob = c(theta1, 1 - theta1)))
}
##Second coin:
theta2 <- 0.7              # probability of a success (here: head)
X2 <- 30                   # number of trials in the experiment
n2 <- 100                  # number of observations
k2 <- 0                    # number of heads [initialization]

## repeat experiment N-times
for (i in 1: n2) {
  k2[i] <- sum(sample(sample.space, size = X2, replace = TRUE,
                     prob = c(theta2, 1 - theta2)))
}

## show results in a tibble
coin.flip2 <- tibble("coin" = c(replicate(n1,"coin1"), replicate(n2,"coin2")),
                     "n" = c(seq(from=1, to=n1, by=1), seq(from=1, to=n2, by=1)),
                     "k" = c(k1,k2),
                     "x" = c(replicate(n1,X1), replicate(n2,X2))
) %>%
  print()
```

```{r}
#Plotting the observed results
ggplot(data=coin.flip2,mapping = aes(x=k, fill=coin ))+
          geom_histogram()
```

#### Conceptual steps for modeling

We suppose that the underlying probabilities of the two coins correspond to *different* latent variables $\theta_1$ and $\theta_2$.

**First step** is again the *identification of the relevant variables* according to the research question. As already indicated for the "one coin" example we have:

* the observed number of heads $k_1$ and $k_2$ (for each coin, respectively), which is influenced by
* the number of observations $n_1$ and $n_2$ and by
* the underlying probabilities $\theta_1$ and $\theta_2$.

Furthermore, from a conceptional perspective, we are interested in the *difference between the coin biases*. Therefore a further variable will be introduced $\delta$, defined by:
$$\delta =\theta_1 - \theta_2.$$

The *distributional assumptions*, according to the **second and third step**, can be adopted from the "one coin" example, such that the graphical notation (including the textual notation) can be denoted as follows:

#### Notation Beta-Binomial Model - Two Groups

![Graphical notation Beta-Binomial Model - Two groups](chapters/images/Graph-Factorial.png)

### Simple linear regression with one metric predictor

The following example originates from a data set in which speed of cars and the distance taken to stop was recorded. It is a simple data set good for introducing the basic ideas for simple linear regression.
```{r}
#The "cars" data set
data(cars)
#take a look at the variables included in the data set
str(cars)
```
One possible question could be how much the stopping distance increases when the speed of a car increases.

#### Conceptual steps for modeling

First step is to **identify the relevant variables**. In this case these are "speed" measured in mph and "distance" measured in ft, thus, both variables are metric variables. As distance will be predicted from speed. The *predicted variable* is "distance" and the *predictor variable* is "speed". A scatter plot can visualize a possible relationship between both variables.
```{r}
plot(x=cars$speed,y=cars$dist, type="p", main="scatter plot of cars data set",
     ylab="distance in ft", xlab="speed in mph")
```

Next step is to define a **descriptive model of the data**. According to the scatter plot it is not too absurd to think that distance might be proportional to speed. Therefore, a linear relationship between both variables can be assumed, where speed is used i order to predict distance. But how can the distribution of the predicted variable "distance" be described? The following plot shows in blue the density of the actual distance values.

```{r, eval=FALSE}
#density of distance values in blue
#(in black simulation of a normal distribution)
dens(cars$dist, col="blue", norm.comp = TRUE, main="Distribution of distance",
     xlab="distance in ft")
```

Although the distribution of "distance" values is not identical to the corresponding normal distribution, it can be assumed that the values follow a *normal distribution*. The underlying consideration is that the distance values $y_i$ are distributed randomly according to a normal distribution around the predicted value $\hat{y}$ and with a standard deviation denoted with $\sigma$. This can be denoted as:
$$y_i\sim Normal(\mu, \sigma).$$
The index $i$ indicates each element (i.e. car) of the list $y$, which in turn is the list of distances.

In the third step, a Bayesian perspective is taken the **prior knowlege** (before seeing the data) has to be defined. The parameters of the current model are the predicted value $\mu$ and the standard deviation $\sigma$. For the parameter $\mu$ a normal distribution can be assumend with parameters that reflect the estimated values from the sample.

```{r}
#descriptive statistics from the sample
tibble(variables=c("speed", "distance"),
       mean=c(mean(cars$speed),mean(cars$dist)),
       sigma = c(sd(cars$speed), sd(cars$dist)))
```

$$\mu\sim Normal(43,26)$$

For the standard deviation $\sigma$ a uniform distribution is assumed:
$$\sigma\sim Uniform(0,40)$$

#### Excursus: Identically and independently distributed (*iid*)

The short model description $y_i\sim Normal(\mu, \sigma)$ incorporates often already an assumption about the distribution of distance-values: They are *identically and independently distributed*. Often the abbreviation *iid* can be found for this assumption:
$$y_i\overset{\text{iid}}{\sim} Normal(\mu, \sigma).$$

The abbreviation *iid* indicates that each value $y_i$ has the same probability function, independent of the other $y$ values and using the same parameters [@mcelreath2015]. This is hardly ever true (why hierarchical modeling is very attractive). For example, thinking about the cars in the current example data set. Some cars may be of different types or even the same type but different batches. But the question is: Is this underlying dependency relevant for the model? If yes, this information has to be added in the model (e.g. in form of a hierarchical model). Janyes states it as follows: "*The onus is always on the user to make sure that all information, which his common sense tells him is relevant to the problem, is actually incorporated into the equations, (...).*"[@jaynes2003,p.339]. But if one do not know any relevant underlying relationships the most conservative distribution to use is *iid*. Note, that the stated assumptions define how the model represents a problem and not how the world should be understood. For example, there might exist underlying correlations but on the overall distribution there influence tends towards zero. In such cases it remains usefull to assume iid [@mcelreath2015].

### Notation Simple Regression model
![Graphical notation Simplre Regression model](chapters/images/Graph-SimpReg.png)

## Greta

```{r, eval = F}
## --- greta model code ---

## --- --- data --- ---

velocity  <- as_data(cars$speed)
distance  <- as_data(cars$dist)

## --- --- latent variables --- ---

intercept <- normal(0, 10)
slope     <- normal(0, 10)
sigma     <- student(3, 0 , 1, truncation = c(0, Inf))

# intercept <- variable()
# slope     <- variable()
# sigma     <- variable(lower = 0)

mean_g <- intercept + slope * velocity

## --- --- likelihood --- ---

distribution(distance) <- normal(mean_g, sigma)

## --- --- model --- ---

m <- model(intercept, slope, sigma)

# plot(m)

## --- sampling ---

draws <- mcmc(m, n_samples = 1000)

tidy_draws = ggs(draws)

tidy_draws %>% group_by(Parameter) %>%
  summarise(mean = mean(value),
            '|95%' = quantile(value, probs = 0.025),
            '95|%' = quantile(value, probs = 0.975))
```

## WebPPL

<pre class="webppl">
var theta = 0.2; var K = [20,80];
///fold:
var N = 100;
var n = 20;

var factorial = function(x) {
  if (x < 0) {return "input to factorial function must be non-negative"}
  return x == 0 ? 1 : x * factorial(x-1)
}

var binom = function(a, b) {
  var numerator = factorial(a)
  var denominator = factorial(a-b) *  factorial(b)
  return numerator / denominator
}

// urn contains N balls of which K are black
// and N-K are white; we draw n balls at random
// without replacement; what's the probability
// of obtaining k black balls?
var hypergeometricPMF = function(k,N,K,n) {
  k > Math.min(n, K) ? 0 :
  k < n+K-N ? 0 :       
  binom(K,k) * binom(N-K, n-k) / binom(N,n)
}

var hypergeometricSample = function(N,K,n) {
  var support = _.range(N+1) // possible values 0, ..., N
  var PMF = map(function(k) {hypergeometricPMF(k,N,K,n)}, support)
  categorical({vs: support, ps: PMF })    
}
viz(Infer({model: function() {var K_urn = K[flip(theta) ? 1 : 0];
                              hypergeometricSample(N, K_urn, n)},
           method: "forward",
           samples: 1500}))
///
</pre>

<pre class=" CodeMirror-line " role="presentation">
</pre>

<script>
// find all <pre> elements and set up the editor on them
var preEls = Array.prototype.slice.call(document.getElementsByClassName("webppl"));
preEls.map(function(el) { console.log(el); editor.setup(el, {language: 'webppl'}); });
</script>

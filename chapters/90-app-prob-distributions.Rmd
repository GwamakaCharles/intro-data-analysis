
# (APPENDIX) Appendix {-} 

# Common probability distributions

## Selected continous distributions of random variables

### Normal distribution
One of the most important distribution families is the *gaussian* or *normal family* because it fits many natural phenomena. Furthermore the sampling distributions of many estimators depend on the normal distribution. On the one hand because they are derived from normally distributed random variables or on the other hand because they can be asymptotically approximated by a normal distribution for large samples (*Central limit theorem*). 

Distributions of the normal family have two parameters $\mu$ and $\sigma$ that are referred to, respectively, as the *mean* and the *standard deviation* of the normal random variable. These parameters are examples of *location* and *scale* parameters. The normal distribution is located at $\mu$ and its width is scaled by choice of $\sigma$. The distribution is symmetric with most observations lying aroung the central peak $\mu$ and more extreme values are further away depending on $\sigma$. 

$$X\sim Normal(\mu,\sigma^2)$$

Fig.~\ref{fig:ch-app-01-normal-distribution-density} shows the probability density function of three normal distributed random variables with different parameters. Fig.~\ref{fig:ch-app-01-normal-distribution-cumulative} shows the corresponding cumulative function of the three normal distributions.

```{r ch-app-01-normal-distribution-density, fig.cap = "Examples of probability density function of normal distributions."}
# how many samples to use
n <- 1e5

rv_normal_intro <- tibble(
  X = rnorm(n, mean = -2, sd = 3),
  Y = rnorm(n, mean =  0, sd = 1),
  Z = rnorm(n, mean =  2, sd = 2)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), names_to = "parameter_set", values_to = "x")

ggplot(rv_normal_intro, aes(x = x, color = parameter_set)) +
  # draw density lines
  stat_density(geom = "line", position = "identity", size = 2) +
  # add text annotations to lines
  annotate("text", x = -10, y = 0.1, label = "X~Normal(-2,3)", color = project_colors[1], size = 6) +
  annotate("text", x = -6, y = 0.30, label = "X~Normal(0,1)", color = project_colors[2], size = 6) +
  annotate("text", x =  8, y = 0.15, label = "X~Normal(2,2)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```

```{r ch-app-01-normal-distribution-cumulative, fig.cap = "Examples of the cumulative distribution function of normal distributions corresponding to the previous probability density functions."}
ggplot(rv_normal_intro, aes(x = x, color = parameter_set)) +
  # draw cumulative lines
  stat_ecdf(geom = "step", size = 2) +
  # add text annotations to lines
  annotate("text", x = -8, y = 0.50, label = "X~Normal(-2,3)", color = project_colors[1], size = 6) +
  annotate("text", x = -8, y = 0.75, label = "X~Normal(0,1)", color = project_colors[2], size = 6) +
  annotate("text", x =  8, y = 0.25, label = "X~Normal(2,2)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```

A special case of normal distributed random variables is the *standard normal* distributed variable with $\mu=0$ and $\sigma=1$: $Y\sim Normal(0,1)$. Each normal distribution can be converted into a standard normal distribution by *z-standardization* (see equation below). The advantage of standardization is that values from different scales can be compared. This is because they become *scale independent* by z-transformation. 

**Probability density function**

$$f(x)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-0.5\left(\frac{x-\mu}{\sigma}\right)^2\right)$$

**Cumulative distribution function**

$$F(x)=\int_{-\inf}^{x}f(t)dt$$

**Expected value** $E(X)=\mu$

**Variance** $Var(X)=\sigma^2$

**Z-transformation** $Z=\frac{X-\mu}{\sigma}$

**Deviation and *Coverage**
The normal distribution is often associated with the \emph{68-95-99.7 rule}. It is associated with the probability of a random data point landing within \emph{one}, \emph{two} or \emph{three} standard deviations of the mean (Fig.~\ref{fig:ch-app-01-normal-distribution-coverage} depicts this three intervals). For example, about 68% of values drawn from a normal distribution are within one standard deviation $\sigma$ away from the mean $\mu$.

* $P(\mu-\sigma \leq X \leq \mu+\sigma)=0.6827$ 
* $P(\mu-2\sigma \leq X \leq \mu+2\sigma)=0.9545$ 
* $P(\mu-3\sigma \leq X \leq \mu+3\sigma)=0.9973$ 

```{r ch-app-01-normal-distribution-coverage, fig.cap = "Coverage of normal distribution"}
# plot normal distribution with intervals
ggplot(NULL, aes(x = c(-10, 10))) +
  # plot area under the curve
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "area",
                fill = project_colors[1],
                xlim = c(-6, 6)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "area",
                fill = project_colors[2],
                xlim = c(-4, 4)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "area",
                fill = project_colors[3],
                xlim = c(-2, 2)) +
  # plot the curve
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "line",
                xlim = c(-10, 10),
                size = 2) +
  # scale x-axis
  xlim(-10, 10) +
  # label x-axis
  xlab("X") +
  # label ticks of x-axis
  scale_x_continuous(breaks = c(-6,-4,-2,0,2,4,6), 
                     labels = c(expression(-3~sigma),expression(-2~sigma),
                              expression(-sigma),"0",expression(sigma),
                              expression(2~sigma),expression(3~sigma)))
```

**Linear transformations**

1. If $X\sim Normal(\mu, \sigma^2)$ is linear transformed by $Y=a*X+b$, then the new random variable is again normal distributed with $Y \sim Normal(a\mu+b,a^2\sigma^2)$. See Fig.~\ref{} left side.
2. Are $X\sim Normal(\mu_x, \sigma^2)$ and $Y\sim Normal(\mu_y, \sigma^2)$ normal distributed and independent, then their sum is again normal distributed with $X+Y \sim Normal(\mu_x+\mu_y, \sigma_x^2+\sigma_y^2)$. See plot right side.

### Chi-squared distribution
The $\chi^2$-distribution is widely used in hypothesis testing in inferential statistics, because many test statistics are approximately distributed as $\chi^2$-distribution. 

The $\chi^2$-distribution is directly related to the standard normal distribution: The sum of $n$ independent and standard normal distributed random variables $X_1,X_2,...,X_n$ is distributed according to a $\chi^2$ distribution with $n$ \emph{degrees of freedom}:

$$Y=X_1^2+X_2^2+...+X_n^2.$$

Accordinlgy, the $\chi^2$ distribution has only one parameter: $n$, the *degrees of freedom*. 

$$Y\sim \chi^2(n)$$

(Note, there exists also a generalization of the $\chi^2$ distribution: the *non-central* $\chi^2$ distribution, where a second parameter $\lambda$ is introduced.)

Fig.~\ref{fig:ch-app-01-chi-squared-distribution-density} shows the probability density function of three chi-squared distributed random variables with different parameters. Note, that with increasing degrees of freedom the chi-squared distribution approximates the normal distribution. For $n \geq 30$ the chi-squared distribution can be approximated by a normal distribution. Fig.~\ref{fig:ch-app-01-chi-squared-distribution-cumulative} shows the corresponding cumulative function of the three chi-squared density distributions.

```{r ch-app-01-chi-squared-distribution-density, fig.cap = "Examples of probability density function of chi-squared distributions."}
rv_chisq_intro <- tibble(
  X = rchisq(n, df = 2),
  Y = rchisq(n, df = 4),
  Z = rchisq(n, df = 9)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), names_to = "parameter_set", values_to = "x")

ggplot(rv_chisq_intro, aes(x = x, color = parameter_set)) +
  # draw density lines
  stat_density(geom = "line", position = "identity", size = 2) +
  # add text annotations to lines
  annotate("text", x = 10, y = 0.25, label = "X~Chi-Squared(2)", color = project_colors[1], size = 6) +
  annotate("text", x = 12, y = 0.15, label = "X~Chi-Squared(4)", color = project_colors[2], size = 6) +
  annotate("text", x = 20, y = 0.07, label = "X~Chi-Squared(9)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```
```{r ch-app-01-chi-squared-distribution-cumulative, fig.cap = "Examples of the cumulative distribution function of chi-squared distributions corresponding to the previous probability density functions."}

ggplot(rv_chisq_intro, aes(x = x, color = parameter_set)) +
  # draw cumulative lines
  stat_ecdf(geom = "step", size = 2) +
  # add text annotations to lines
  annotate("text", x = 20, y = 0.75, label = "X~Chi-Squared(2)", color = project_colors[1], size = 6) +
  annotate("text", x = 18, y = 0.50, label = "X~Chi-Squared(4)", color = project_colors[2], size = 6) +
  annotate("text", x = 15, y = 0.25, label = "X~Chi-Squared(9)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")

```

**Expected value** $E(Y)=n$

**Variance** $Var(Y)=2n$

**Transformations**
Sum of two $\chi^2$-distributed random variables $X \sim \chi^2(m)$ and $Y \sim \chi^2(n)$ is again a $chi^2$-distributed random variable $X+Y=\chi^2(m+n)$.

### F distribution
The F distribution, named after R.A. Fisher, is used in particular in regression and variance analysis.
It is defined by the ratio of two $chi^2$-distributed random variables $X\sim \chi^2(m)$ and $Y\sim \chi^2(n)$, each divided by its degree of freedom:

$$F=\frac{\frac{X}{m}}{\frac{Y}{n}}.$$
Consequently, the F distribution has two parameters $m$ and $n$, corresponding to the degrees of freedom of the two $chi^2$-distributed random variables:

$$F \sim F(m,n).$$

Fig.~\ref{fig:ch-app-01-F-distribution-density} shows the probability density function of three F distributed random variables with different parameters. For a small number of degrees of freedom the density distribution is skewed to the left side. When the number increases, the density distribution gets more and more symmetric. Fig.~\ref{fig:ch-app-01-F-distribution-cumulative} shows the corresponding cumulative function of the three F density distributions.
 
```{r ch-app-01-F-distribution-density, fig.cap = "Examples of probability density function of F distributions."}
rv_F_intro <- tibble(
  X = rf(n, df1 = 2, df2 = 4),
  Y = rf(n, df1 = 4, df2 = 6),
  Z = rf(n, df1 = 12, df2 = 12)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), names_to = "parameter_set", values_to = "x")

ggplot(rv_F_intro, aes(x = x, color = parameter_set)) +
  # draw density lines
  stat_density(geom = "line", position = "identity", size = 2) +
  # scale x-axis
  xlim(0,7) +
  # add text annotations to lines
  annotate("text", x = 3, y = 0.75, label = "X~F(2,4)", color = project_colors[1], size = 6) +
  annotate("text", x = 3, y = 0.45, label = "X~F(4,6)", color = project_colors[2], size = 6) +
  annotate("text", x = 3, y = 0.60, label = "X~F(12,12)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```

```{r ch-app-01-F-distribution-cumulative, fig.cap = "Examples of the cumulative distribution function of F distributions corresponding to the previous probability density functions."}
ggplot(rv_F_intro, aes(x = x, color = parameter_set)) +
  # draw cumulative lines
  stat_ecdf(geom = "step", size = 2) +
  # scale axes
  xlim(0,7) +
  ylim(0,1) +
  # add text annotations to lines
  annotate("text", x = 3, y = 0.4, label = "X~F(2,4)", color = project_colors[1], size = 6) +
  annotate("text", x = 3, y = 0.5, label = "X~F(4,6)", color = project_colors[2], size = 6) +
  annotate("text", x = 3, y = 0.6, label = "X~F(12,12)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```

**Expected value** $E(F) = \frac{n}{n-2}$ (for $n \geq 3$)

**Variance** $Var(F) = \frac{2n^2(n+m-2)}{m(n-4)(n-2)^2}$ (for $n \geq 5$)

### Student t-distribution 
The t or student-t distribution was discovered by William S. Gosset in 1908 [@vallverdu2015], who published his work under the pseudonym "student". He worked at the Guinness factory and had to deal with the problem of small sample sizes. This challenge resulted finally in the t distribution. This distribution is used in particular when the sample size is small and the variance unknown, which is often the case in reality. Its shape ressembles the normal bell shape and has a peak at zero, but the t distribution is a bit lower and wider (bigger tails) than the normal distribution. 

The t distribution consists of a standard normal distributed random variable $X\sim Normal(0,1)$ and a $\chi^2$-distributed random variable $Y\sim \chi^2(n)$ (X and Y are independent):

$$T = \frac{X}{\sqrt{\frac{Y}{n}}}.$$
The t distribution has one parameter $n$, the degrees of freedom. The degrees of freedom can be calculated by the sample size $n$ minus one:
$$T \sim t(n).$$

Fig.~\ref{fig:ch-app-01-t-distribution-density} shows the probability density function of three t distributed random variables with different parameters. Notice that for small degrees of freedom $n$, the t-distribution has fatter tails. This is because the t distribution was specially designed to provide more conservative test results when analyzing small samples. When the degrees of freedom increases, the t distribution approaches a normal distribution. For $n \geq 30$ this approximatio is quite good. Fig.~\ref{fig:ch-app-01-t-distribution-cumulative} shows the corresponding cumulative function of the three t density distributions.
 
```{r ch-app-01-t-distribution-density, fig.cap = "Examples of probability density function of t distributions."}
rv_t_intro <- tibble(
  X = rt(n, df = 1),
  Y = rt(n, df = 2),
  Z = rt(n, df = 10)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), names_to = "parameter_set", values_to = "x")

ggplot(rv_t_intro, aes(x = x, color = parameter_set)) +
  # draw density lines
  stat_density(geom = "line", position = "identity", size = 2) +
  # scale x-axis
  xlim(-7,7) +
  # add text annotations to lines
  annotate("text", x = 4, y = 0.32, label = "X~t(1)", color = project_colors[1], size = 6) +
  annotate("text", x = 4, y = 0.35, label = "X~t(2)", color = project_colors[2], size = 6) +
  annotate("text", x = 4, y = 0.38, label = "X~t(10)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none") 
 
```

```{r ch-app-01-t-distribution-cumulative, fig.cap = "Examples of the cumulative distribution function of t distributions corresponding to the previous probability density functions."}
ggplot(rv_t_intro, aes(x = x, color = parameter_set)) +
  # draw cumulative lines
  stat_ecdf(geom = "step", size = 2) +
  # scale axes
  xlim(-7,7) +
  ylim(0,1) +
  # add text annotations to lines
  annotate("text", x = 4, y = 0.40, label = "X~t(1)", color = project_colors[1], size = 6) +
  annotate("text", x = 4, y = 0.50, label = "X~t(2)", color = project_colors[2], size = 6) +
  annotate("text", x = 4, y = 0.60, label = "X~t(10)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```

**Expected value** $E(T) = 0$

**Variance** $Var(T) = \frac{n}{n-2}$ (for $n \geq 3$)

### Beta distribution

### Uniform distribution


## Selected discrete distributions of random variables

### Binomial distribution

$$X \sim Binomial(n,p)$$

```{r ch-app-01-binomial-distribution-mass, fig.cap = "Examples of probability mass function of Binomial distributions."}
# how many trials
size <- 30

rv_binomial_intro <- tibble(
  X = rbinom(n, size = size, prob = 0.2),
  Y = rbinom(n, size = size, prob = 0.5),
  Z = rbinom(n, size = size, prob = 0.8)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), names_to = "parameter_set", values_to = "x")

ggplot(rv_binomial_intro, aes(x = x, y = (..count..)/sum(..count..), fill = parameter_set)) +
  # draw bars
  stat_bin(geom = "bar", position="dodge", binwidth = 1) +
  # add text annotations to lines
  annotate("text", x = 5, y = 0.07, label = "X~Binomial(n,0.2)", color = project_colors[1], size = 6) +
  annotate("text", x = 15, y = 0.07, label = "X~Binomial(n,0.5)", color = project_colors[2], size = 6) +
  annotate("text", x = 25, y = 0.07, label = "X~Binomial(n,0.8)", color = project_colors[3], size = 6) +
  # add title for y-axis
  ylab("Probability") +
  # suppress legend
  theme(legend.position = "none") 
 
```


```{r ch-app-01-binomial-distribution-cumulative, fig.cap = "Examples of the cumulative distribution function of Binomial distributions corresponding to the previous probability mass functions."}
ggplot(rv_binomial_intro, aes(x = x, color = parameter_set)) +
  # draw cumulative lines
  stat_ecdf(geom = "step", size = 2) +
  # add text annotations to lines
  annotate("text", x = 10, y = 0.5, label = "X~Binomial(n,0.2)", color = project_colors[1], size = 5) +
  annotate("text", x = 19, y = 0.5, label = "X~Binomial(n,0.5)", color = project_colors[2], size = 5) +
  annotate("text", x =28, y = 0.5, label = "X~Binomial(n,0.8)", color = project_colors[3], size = 5) +
  # suppress legend
  theme(legend.position = "none")
```

**Probability mass function**

$$f(x)=\binom{n}{x}p^x(1-p)^{n-x}$$
**Cumulative function**

$$F(x)=\sum_{k=0}^{x}\binom{n}{k}p^k(1-p)^{n-k}$$

**Expected value** $E(X)=n \cdot p$

**Variance** $Var(X)=n \cdot p \cdot (1-p)$

### Poisson distribution

$$X \sim Po(\lambda)$$

```{r ch-app-01-poisson-distribution-mass, fig.cap = "Examples of probability mass function of Poisson distributions."}
rv_poisson_intro <- tibble(
  X = rpois(n, lambda = 5),
  Y = rpois(n, lambda = 15),
  Z = rpois(n, lambda = 25)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), 
               names_to  = "parameter_set", 
               values_to = "x")

ggplot(rv_poisson_intro, aes(x = x, color = parameter_set)) +
  # draw density lines
  stat_density(geom = "line", position="identity", size = 2) +
  # add text annotations to lines
  annotate("text", x = 10, y = 0.15, label = "X~Poisson(5)", color = project_colors[1], size = 6) +
  annotate("text", x = 10, y = 0.09, label = "X~Poisson(15)", color = project_colors[2], size = 6) +
  annotate("text", x = 10, y = 0.05, label = "X~Poisson(25)", color = project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none") 
 
```


```{r ch-app-01-poisson-distribution-cumulative, fig.cap = "Examples of the cumulative distribution function of Poisson distributions corresponding to the previous probability mass functions."}
ggplot(rv_poisson_intro, aes(x = x, color = parameter_set)) +
  # draw cumulative lines
  stat_ecdf(geom = "step", size = 2) +
  # add text annotations to lines
  annotate("text", x=10, y=0.15,  label="X~Binomial(n,0.2)", color=project_colors[1], size = 6) +
  annotate("text", x=10 , y=0.09,  label="X~Binomial(n,0.5)",  color=project_colors[2], size = 6) +
  annotate("text", x=10,   y=0.05, label="X~Binomial(n,0.8)",  color=project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")
```

**Probability mass function**

$$f(x)=\frac{\lambda^x}{x!}e^{-\lambda}$$

**Cumulative function**

$$F(x)=\sum_{k=0}^{x}\frac{\lambda^k}{k!}e^{-\lambda}$$

**Expected value** $E(X)= \lambda$

**Variance** $Var(X)=\lambda$

## Understanding distributions as random variables

```{r}
#initialize parameters
a = 3
b = 1.5
n = 1e6

#create random variables
## normal distributed RVs 
X_norm <- rnorm(n = n, mean = 1, sd = 2)
Y_norm <- rnorm(n = n, mean = 1.5, sd = 2.5)
## standard normal distributed RVs
stdNormal1 <- rnorm(n = n, mean = 0, sd = 1)
stdNormal2 <- rnorm(n = n, mean = 0, sd = 1)
stdNormal3 <- rnorm(n = n, mean = 0, sd = 1)
## chi-square distributed RV
C <- rchisq(n=n, df=3)
## student-t distributed RV
student <- rt(n=20, df=3)
## F distributed RV
fisher <- rf(n=n, df1=1, df2=3)

## create linear transformation of X
X_lin <- a*X_norm+b
## create RV A as addition of X + Y
sum_xy <- X_norm + Y_norm
## create chisquare distributed RV 
C2 <- stdNormal2^2+stdNormal3^2
C3 <- stdNormal1^2+stdNormal2^2+stdNormal3^2
## create student-t distributed RV
T1 <- stdNormal1/sqrt(C2/1)
## create F distributed RV
F1 <- (C2/2)/(C3/1)

## normal ditributed RV B (equal to addition: X+Y)
N_add <- rnorm(n = n, mean = 1 + 1.5, sd = sqrt(2^2 + 2.5^2))
## normal distributed RV V (equal to linear transformation: a*X+b)
N_lin <- rnorm(n = n, mean = a*1+b, sd = (a*2))
```

```{r}
par(mfrow=c(1,2))
plot(density(X_norm), main="Normal RV: a*X+b", xlim=c(-20,20),xlab="RVs")+
  points(density(N_lin), type = "l", col="blue")+
plot(density(X_norm), main="Normal RV: X+Y", xlim=c(-20,20),xlab="RVs")+
  points(density(Y_norm), type = "l", lty="dotted")+
  points(density(N_add), type = "l", col="blue")
par(mfrow=c(1,2))
plot(density(stdNormal1), main=expression("X,Y,Z ~N(0,1);"~X^2+Y^2+Z^2),   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(C3), type = "l", col="blue")
plot(density(C), main="Chi-square distribution", xlim=c(0,15),ylim=c(0,0.4),
     xlab="RVs", col="red", lwd=2, lty="dashed")+
  points(density(C3), type = "l", col="blue")
```

```{r}
par(mfrow=c(2,2))
plot(density(stdNormal1), main="Normal devided by Chi-square RVs",   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(C), type = "l")+
  points(density(T1),type="l", col="blue")
plot(density(T1), main="Student-t distribution",   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(student),type="l", col="red")
plot(density(stdNormal1), main=expression("X~N(0,1),"~Y~"~"~chi^2~(2)~";"~X/sqrt(Y/n)),   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(C2), type = "l")+
  points(density(T1), type = "l", col="blue")
plot(density(stdNormal1), main="Student-t distribution",   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(student), type = "l", col="red")

```

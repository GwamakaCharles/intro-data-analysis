
# (APPENDIX) Appendix {-} 

# Appendix: Common probability distributions

## Selected continous distributions of random variables

### Normal distribution

$$X\sim Normal(\mu,\sigma^2)$$

[usage of Normal distribution -> normal by addition, multiplication, log-multiplication]

```{r ch-app-01-normal-distribution, fig.cap = "Examples of the cumulative normal distribution corresponding to the previous probability density functions."}
# how many samples to use
n <- 1e6

rv_normal_intro <- tibble(
  X = rnorm(n, mean= -2, sd=3),
  Y = rnorm(n, mean=  0, sd=1),
  Z = rnorm(n, mean=  2, sd=2)
) %>% 
  pivot_longer(cols = c("X", "Y", "Z"), names_to = "parameter_set", values_to = "x")

ggplot(rv_normal_intro, aes(x = x, color = parameter_set)) +
  # draw density lines
  stat_density(geom = "line", position="identity", size = 2) +
  # add text annotations to lines
  annotate("text", x=-10, y=0.1,  label="X~Normal(-2,3)", color=project_colors[1], size = 6) +
  annotate("text", x=-6 , y=0.3,  label="X~Normal(0,1)",  color=project_colors[2], size = 6) +
  annotate("text", x=8,   y=0.15, label="X~Normal(2,2)",  color=project_colors[3], size = 6) +
  # suppress legend
  theme(legend.position = "none")

```

Special case of normal distributed random variables is the *standard normal* distributed variable with $\mu=0$ and $\sigma=1$: $Y\sim Normal(0,1)$ 

**Probability density function**

$$f(x)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-0.5\left(\frac{x-\mu}{\sigma}\right)^2\right)$$

**Cumulative distribution function**

$$F(x)=\int_{-\inf}^{x}f(t)dt$$

**Expected value** $E(X)=\mu$

**Variance** $Var(X)=\sigma^2$

**Z-transformation** $Z=\frac{X-\mu}{\sigma}$

**Deviation and *Coverage**

* $P(\mu-\sigma \leq X \leq \mu+\sigma)=0.6827$ (see dark blue area under the curve)
* $P(\mu-2\sigma \leq X \leq \mu+2\sigma)=0.9545$ (see medium blue area under the curve)
* $P(\mu-3\sigma \leq X \leq \mu+3\sigma)=0.9973$ (see light blue area under the curve)

(Interpretation example: About 68% of values drawn from a normal distribution are within one standard deviation $\sigma$ away from the mean $\mu$.)

```{r}
# plot standard deviations of a normal distribution

ggplot(NULL, aes(x = c(-10, 10))) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "line",
                xlim = c(-10, 10)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "area",
                fill = "blue",
                alpha = .2,
                xlim = c(-6, 6)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "area",
                fill = "blue",
                alpha = .4,
                xlim = c(-4, 4)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
                geom = "area",
                fill = "blue",
                alpha = .6,
                xlim = c(-2, 2)) +
  xlim(-10, 10)+
  xlab("X")+
  scale_x_continuous(breaks=c(-6,-4,-2,0,2,4,6), 
                     labels=c(expression(-3~sigma),expression(-2~sigma),
                              expression(-sigma),"0",expression(sigma),
                              expression(2~sigma),expression(3~sigma)))
```

**Linear transformations**

1. If $X\sim Normal(\mu, \sigma^2)$ is linear transformed by $Y=a*X+b$, then the new random variable is again normal distributed with $Y \sim Normal(a\mu+b,a^2\sigma^2)$. See plot left side.
2. Are $X\sim Normal(\mu_x, \sigma^2)$ and $Y\sim Normal(\mu_y, \sigma^2)$ normal distributed and independent, then their sum is again normal distributed with $X+Y \sim Normal(\mu_x+\mu_y, \sigma_x^2+\sigma_y^2)$. See plot right side.

### Chi-square distribution

$$Y\sim \chi^2(n)$$

The $\chi^2$-distribution is widely used in hypothesis testing in inferential statistics and less in modelling natural phenomena. The reason why it is used so often in inferential statistics is its relationsship to the standard normal distribution:

The sum of $n$ independent and standard normal distributed random variables $X_1,X_2,...,X_n$ is distributed according to a $\chi^2$ distribution with $n$ \emph{degrees of freedom}. The degrees of freedom refers to the number of independent standard normal random variables.

$$Y=X_1^2+X_2^2+...+X_n^2$$

```{r}
plot(density(rchisq(1e6,3)),col="green", main=expression(chi^2~"distribution"), xlab="RVs")+
  points(density(rchisq(1e6,10)),col="blue", type="l")+
  points(density(rchisq(1e6,20)),col="red", type="l")
```


**Expected value** $E(Y)=n$

**Variance** $Var(Y)=2n$

**Transformations**
Sum of two $\chi^2$-distributed random variables $X \sim \chi^2(m)$ and $Y \sim \chi^2(n)$ is again a $chi^2$-distributed random variable $X+Y=\chi^2(m+n)$.

### F distribution

$$F \sim F(m,n)$$

Used in particular in regression and variance analysis and consists of two $chi^2$-distributed random variables $X\sim \chi^2(m)$ and $Y\sim \chi^2(n)$:

$$F=\frac{\frac{X}{m}}{\frac{Y}{n}}$$

```{r}
plot(density(rf(1e6,10,10)),col="green", main="F distribution",ylim=c(0,2),xlim=c(0,5), 
     xlab="RVs")+
  points(density(rf(1e6,20,20)),col="blue", type="l")+
  points(density(rf(1e6,100,100)),col="red", type="l")
```

**Expected value** $E(F)=\frac{n}{n-2}$ (for $n \geq 3$)

**Variance** $Var(F)=\frac{2n^2(n+m-2)}{m(n-4)(n-2)^2}$ (for $n \geq 5$)

### Student t-distribution (not part of exponential family)

$$T \sim t(n)$$

The student-t-distribution is not part of the exponential family but is directly related to the normal distribution. It is used in particular when the sample size is small and the variance is unknown, which is often the case in reality. Its shape ressembles the normal bell shape, but the student-t-distribution is a bit lower and wider (bigger tails). For a large sample size ($n \geq 30$) the student-t-distribution can be approximated by a standard normal distribution.  

It consists of a standard normal distributed random variable $X\sim Normal(0,1)$ and a $\chi^2$-distributed random variable $Y\sim \chi^2(n)$ (X and Y are independent):

$$T=\frac{X}{\sqrt{\frac{Y}{n}}}$$


```{r}
plot(density(rt(1e6,3)),col="green", main="Student-t distribution",xlim=c(-10,10), 
     xlab="RVs")+
  points(density(rt(1e6,3.5)),col="blue", type="l")+
  points(density(rt(1e6,15)),col="red", type="l")+
  points(density(rnorm(1e6)), type="l")
```

**Expected value** $E(T)=0

**Variance** $Var(T)=\frac{n}{n-2}$ (for $n \geq 3$)


## Selected discrete distributions of random variables

### Binomial distribution

$$X \sim Binomial(n,p)$$


```{r}
par(mfrow=c(2,2))
hist(rbinom(1e6,15,0.1),col="blue", freq = FALSE,xlim=c(0,15),xlab="RV", 
     main="Binomial(n,0.1)")
hist(rbinom(1e6,15,0.5),col="green", freq = FALSE,xlim=c(0,15),xlab="RV", 
     main="Binomial(n,0.5)")
hist(rbinom(1e6,15,0.8),col="red", freq = FALSE,xlim=c(0,15),xlab="RV", 
     main="Binomial(n,0.8)")
```

**Probability mass function**

$$f(x)=\binom{n}{x}p^x(1-p)^{n-x}$$
**Cumulative function**

$$F(x)=\sum_{k=0}^{x}\binom{n}{k}p^k(1-p)^{n-k}$$

**Expected value** $E(X)=n \cdot p$

**Variance** $Var(X)=n \cdot p \cdot (1-p)$

### Poisson distribution

$$X \sim Po(\lambda)$$

```{r}
par(mfrow=c(2,2))
hist(rpois(1e6,3.5),col="blue", freq = FALSE,xlim=c(0,40),xlab="RV", main="Poisson(3.5)")
hist(rpois(1e6,6),col="green", freq = FALSE,xlim=c(0,40),xlab="RV", main="Poisson(6)")
hist(rpois(1e6,20),col="red", freq = FALSE,xlim=c(0,40),xlab="RV", main="Poisson(20)")
```

**Probability mass function**

$$f(x)=\frac{\lambda^x}{x!}e^{-\lambda}$$

**Cumulative function**

$$F(x)=\sum_{k=0}^{x}\frac{\lambda^k}{k!}e^{-\lambda}$$

**Expected value** $E(X)= \lambda$

**Variance** $Var(X)=\lambda$

## Understanding distributions as random variables

```{r}
#initialize parameters
a = 3
b = 1.5
n = 1e6

#create random variables
## normal distributed RVs 
X_norm <- rnorm(n = n, mean = 1, sd = 2)
Y_norm <- rnorm(n = n, mean = 1.5, sd = 2.5)
## standard normal distributed RVs
stdNormal1 <- rnorm(n = n, mean = 0, sd = 1)
stdNormal2 <- rnorm(n = n, mean = 0, sd = 1)
stdNormal3 <- rnorm(n = n, mean = 0, sd = 1)
## chi-square distributed RV
C <- rchisq(n=n, df=3)
## student-t distributed RV
student <- rt(n=20, df=3)
## F distributed RV
fisher <- rf(n=n, df1=1, df2=3)

## create linear transformation of X
X_lin <- a*X_norm+b
## create RV A as addition of X + Y
sum_xy <- X_norm + Y_norm
## create chisquare distributed RV 
C2 <- stdNormal2^2+stdNormal3^2
C3 <- stdNormal1^2+stdNormal2^2+stdNormal3^2
## create student-t distributed RV
T1 <- stdNormal1/sqrt(C2/1)
## create F distributed RV
F1 <- (C2/2)/(C3/1)

## normal ditributed RV B (equal to addition: X+Y)
N_add <- rnorm(n = n, mean = 1 + 1.5, sd = sqrt(2^2 + 2.5^2))
## normal distributed RV V (equal to linear transformation: a*X+b)
N_lin <- rnorm(n = n, mean = a*1+b, sd = (a*2))
```

```{r}
par(mfrow=c(1,2))
plot(density(X_norm), main="Normal RV: a*X+b", xlim=c(-20,20),xlab="RVs")+
  points(density(N_lin), type = "l", col="blue")+
plot(density(X_norm), main="Normal RV: X+Y", xlim=c(-20,20),xlab="RVs")+
  points(density(Y_norm), type = "l", lty="dotted")+
  points(density(N_add), type = "l", col="blue")
par(mfrow=c(1,2))
plot(density(stdNormal1), main=expression("X,Y,Z ~N(0,1);"~X^2+Y^2+Z^2),   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(C3), type = "l", col="blue")
plot(density(C), main="Chi-square distribution", xlim=c(0,15),ylim=c(0,0.4),
     xlab="RVs", col="red", lwd=2, lty="dashed")+
  points(density(C3), type = "l", col="blue")
```

```{r}
par(mfrow=c(2,2))
plot(density(stdNormal1), main="Normal devided by Chi-square RVs",   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(C), type = "l")+
  points(density(T1),type="l", col="blue")
plot(density(T1), main="Student-t distribution",   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(student),type="l", col="red")
plot(density(stdNormal1), main=expression("X~N(0,1),"~Y~"~"~chi^2~(2)~";"~X/sqrt(Y/n)),   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(C2), type = "l")+
  points(density(T1), type = "l", col="blue")
plot(density(stdNormal1), main="Student-t distribution",   
     xlim=c(-10,10),ylim=c(0,0.4),xlab="RVs")+
  points(density(student), type = "l", col="red")

```

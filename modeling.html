<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 Modeling | Introduction to Data Analysis</title>
  <meta name="description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="generator" content="bookdown 0.14.1 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 Modeling | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 Modeling | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="likelihood-prior-posterior.html"/>
<link rel="next" href="further-examples.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="testing-showcasing.html"><a href="testing-showcasing.html"><i class="fa fa-check"></i><b>0.1</b> Testing / Showcasing</a><ul>
<li class="chapter" data-level="0.1.1" data-path="testing-showcasing.html"><a href="testing-showcasing.html#quotes"><i class="fa fa-check"></i><b>0.1.1</b> Quotes</a></li>
<li class="chapter" data-level="0.1.2" data-path="testing-showcasing.html"><a href="testing-showcasing.html#infobox"><i class="fa fa-check"></i><b>0.1.2</b> Infobox</a></li>
<li class="chapter" data-level="0.1.3" data-path="testing-showcasing.html"><a href="testing-showcasing.html#plots"><i class="fa fa-check"></i><b>0.1.3</b> Plots</a></li>
<li class="chapter" data-level="0.1.4" data-path="testing-showcasing.html"><a href="testing-showcasing.html#shiny-apps"><i class="fa fa-check"></i><b>0.1.4</b> Shiny Apps</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro-learning-goals.html"><a href="intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="intro-course-structure.html"><a href="intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="intro-tools-methods.html"><a href="intro-tools-methods.html"><i class="fa fa-check"></i><b>1.3</b> Tools and topics covered (and not covered) here</a></li>
<li class="chapter" data-level="1.4" data-path="intro-data-sets.html"><a href="intro-data-sets.html"><i class="fa fa-check"></i><b>1.4</b> Data sets covers</a></li>
<li class="chapter" data-level="1.5" data-path="intro-installation.html"><a href="intro-installation.html"><i class="fa fa-check"></i><b>1.5</b> Installation</a></li>
<li class="chapter" data-level="1.6" data-path="further-useful-material.html"><a href="further-useful-material.html"><i class="fa fa-check"></i><b>1.6</b> Further useful material</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basics-of-r.html"><a href="basics-of-r.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a><ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.1</b> Variables</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.2</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.3</b> Objects</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#getting-help"><i class="fa fa-check"></i><b>2.1.4</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numbers"><i class="fa fa-check"></i><b>2.2.1</b> Numbers</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch1-functions.html"><a href="ch1-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a></li>
<li class="chapter" data-level="2.4" data-path="ch1-loops-and-maps.html"><a href="ch1-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Data</a><ul>
<li class="chapter" data-level="3.1" data-path="kinds-of-data.html"><a href="kinds-of-data.html"><i class="fa fa-check"></i><b>3.1</b> Kinds of data</a></li>
<li class="chapter" data-level="3.2" data-path="summary-statistics.html"><a href="summary-statistics.html"><i class="fa fa-check"></i><b>3.2</b> Summary statistics</a><ul>
<li class="chapter" data-level="3.2.1" data-path="summary-statistics.html"><a href="summary-statistics.html#exploring-numerical-data-in-a-vector"><i class="fa fa-check"></i><b>3.2.1</b> Exploring numerical data in a vector</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>3.3</b> Data Wrangling</a></li>
<li class="chapter" data-level="3.4" data-path="data-plotting.html"><a href="data-plotting.html"><i class="fa fa-check"></i><b>3.4</b> Data Plotting</a></li>
</ul></li>
<li class="part"><span><b>III Models and inferences</b></span></li>
<li class="chapter" data-level="4" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html"><i class="fa fa-check"></i><b>4</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4.1</b> Probability</a><ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#outcomes-events-observations"><i class="fa fa-check"></i><b>4.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="4.1.2" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>4.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="4.1.3" data-path="probability.html"><a href="probability.html#interpretations-of-probability"><i class="fa fa-check"></i><b>4.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="4.1.4" data-path="probability.html"><a href="probability.html#urns-and-frequencies"><i class="fa fa-check"></i><b>4.1.4</b> Urns and frequencies</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="structured-events-marginal-distributions.html"><a href="structured-events-marginal-distributions.html"><i class="fa fa-check"></i><b>4.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="4.2.1" data-path="structured-events-marginal-distributions.html"><a href="structured-events-marginal-distributions.html#probability-table-for-a-flip--draw-scenario"><i class="fa fa-check"></i><b>4.2.1</b> Probability table for a flip-&amp;-draw scenario</a></li>
<li class="chapter" data-level="4.2.2" data-path="structured-events-marginal-distributions.html"><a href="structured-events-marginal-distributions.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>4.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="4.2.3" data-path="structured-events-marginal-distributions.html"><a href="structured-events-marginal-distributions.html#marginalization"><i class="fa fa-check"></i><b>4.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="4.3.1" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-rule"><i class="fa fa-check"></i><b>4.3.1</b> Bayes rule</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>4.4</b> Random variables</a><ul>
<li class="chapter" data-level="4.4.1" data-path="random-variables.html"><a href="random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>4.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="4.4.2" data-path="random-variables.html"><a href="random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>4.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="expected-value-variance.html"><a href="expected-value-variance.html"><i class="fa fa-check"></i><b>4.5</b> Expected value &amp; variance</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="two-approaches-to-statistical-inference.html"><a href="two-approaches-to-statistical-inference.html"><i class="fa fa-check"></i><b>5</b> Two approaches to statistical inference</a><ul>
<li class="chapter" data-level="5.1" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="two-notions-of-probability-revisited.html"><a href="two-notions-of-probability-revisited.html"><i class="fa fa-check"></i><b>5.2</b> Two notions of probability (revisited)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="two-notions-of-probability-revisited.html"><a href="two-notions-of-probability-revisited.html#frequentism-probabilities-as-properties-of-the-world"><i class="fa fa-check"></i><b>5.2.1</b> Frequentism — Probabilities as properties of the world</a></li>
<li class="chapter" data-level="5.2.2" data-path="two-notions-of-probability-revisited.html"><a href="two-notions-of-probability-revisited.html#bayesianism-probabilities-as-subjective-beliefs"><i class="fa fa-check"></i><b>5.2.2</b> Bayesianism — Probabilities as subjective beliefs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>6</b> Models</a><ul>
<li class="chapter" data-level="6.1" data-path="likelihood-prior-posterior.html"><a href="likelihood-prior-posterior.html"><i class="fa fa-check"></i><b>6.1</b> Likelihood, Prior, &amp; Posterior</a><ul>
<li class="chapter" data-level="6.1.1" data-path="likelihood-prior-posterior.html"><a href="likelihood-prior-posterior.html#probability-density-function-vs.likelihood-function"><i class="fa fa-check"></i><b>6.1.1</b> Probability density function vs. Likelihood function</a></li>
<li class="chapter" data-level="6.1.2" data-path="likelihood-prior-posterior.html"><a href="likelihood-prior-posterior.html#prior-posterior"><i class="fa fa-check"></i><b>6.1.2</b> Prior &amp; Posterior</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>6.2</b> Modeling</a><ul>
<li class="chapter" data-level="6.2.1" data-path="modeling.html"><a href="modeling.html#introductory-example"><i class="fa fa-check"></i><b>6.2.1</b> Introductory example</a></li>
<li class="chapter" data-level="6.2.2" data-path="modeling.html"><a href="modeling.html#steps-of-data-analysis"><i class="fa fa-check"></i><b>6.2.2</b> Steps of Data Analysis</a></li>
<li class="chapter" data-level="6.2.3" data-path="modeling.html"><a href="modeling.html#notation"><i class="fa fa-check"></i><b>6.2.3</b> Notation</a></li>
<li class="chapter" data-level="6.2.4" data-path="modeling.html"><a href="modeling.html#an-outlook-hierarchical-models"><i class="fa fa-check"></i><b>6.2.4</b> An outlook: Hierarchical models</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="further-examples.html"><a href="further-examples.html"><i class="fa fa-check"></i><b>6.3</b> Further examples</a><ul>
<li class="chapter" data-level="6.3.1" data-path="further-examples.html"><a href="further-examples.html#difference-between-two-groups"><i class="fa fa-check"></i><b>6.3.1</b> Difference between two groups</a></li>
<li class="chapter" data-level="6.3.2" data-path="further-examples.html"><a href="further-examples.html#simple-linear-regression-with-one-metric-predictor"><i class="fa fa-check"></i><b>6.3.2</b> Simple linear regression with one metric predictor</a></li>
<li class="chapter" data-level="6.3.3" data-path="further-examples.html"><a href="further-examples.html#notation-simple-regression-model"><i class="fa fa-check"></i><b>6.3.3</b> Notation Simple Regression model</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html"><a href="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html"><i class="fa fa-check"></i><b>6.4</b> Further elaboration on modeling (in anticipation of the topic “estimation”)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html"><a href="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html#beta-binomial-model---one-group-revisited"><i class="fa fa-check"></i><b>6.4.1</b> Beta-Binomial model - one group (revisited)</a></li>
<li class="chapter" data-level="6.4.2" data-path="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html"><a href="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html#beta-binomial-model---two-groups-revisited"><i class="fa fa-check"></i><b>6.4.2</b> Beta-Binomial model - two groups (revisited)</a></li>
<li class="chapter" data-level="6.4.3" data-path="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html"><a href="further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation.html#simple-linear-regression-model-revisited"><i class="fa fa-check"></i><b>6.4.3</b> Simple linear regression model (revisited)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="parameter-inference.html"><a href="parameter-inference.html"><i class="fa fa-check"></i><b>7</b> Parameter inference</a></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>8</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="9" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>9</b> Model Comparison</a></li>
<li class="chapter" data-level="10" data-path="bayesian-hypothesis-testing.html"><a href="bayesian-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="11" data-path="model-criticism.html"><a href="model-criticism.html"><i class="fa fa-check"></i><b>11</b> Model criticism</a></li>
<li class="part"><span><b>IV Appliied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="12" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>12</b> Simple linear regression</a></li>
<li class="chapter" data-level="13" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>13</b> Logistic regression</a></li>
<li class="chapter" data-level="14" data-path="multinomial-regression.html"><a href="multinomial-regression.html"><i class="fa fa-check"></i><b>14</b> Multinomial regression</a></li>
<li class="chapter" data-level="15" data-path="ordinal-regression.html"><a href="ordinal-regression.html"><i class="fa fa-check"></i><b>15</b> Ordinal regression</a></li>
<li class="chapter" data-level="16" data-path="hierarchical-regression.html"><a href="hierarchical-regression.html"><i class="fa fa-check"></i><b>16</b> Hierarchical regression</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="common-probability-distributions.html"><a href="common-probability-distributions.html"><i class="fa fa-check"></i><b>A</b> Common probability distributions</a><ul>
<li class="chapter" data-level="A.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>A.1</b> Selected continuous distributions of random variables</a><ul>
<li class="chapter" data-level="A.1.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#normal-distribution"><i class="fa fa-check"></i><b>A.1.1</b> Normal distribution</a></li>
<li class="chapter" data-level="A.1.2" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#chi-squared-distribution"><i class="fa fa-check"></i><b>A.1.2</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="A.1.3" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#f-distribution"><i class="fa fa-check"></i><b>A.1.3</b> F distribution</a></li>
<li class="chapter" data-level="A.1.4" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#student-t-distribution"><i class="fa fa-check"></i><b>A.1.4</b> Student t-distribution</a></li>
<li class="chapter" data-level="A.1.5" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#beta-distribution"><i class="fa fa-check"></i><b>A.1.5</b> Beta distribution</a></li>
<li class="chapter" data-level="A.1.6" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>A.1.6</b> Uniform distribution</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>A.2</b> Selected discrete distributions of random variables</a><ul>
<li class="chapter" data-level="A.2.1" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#binomial-distribution"><i class="fa fa-check"></i><b>A.2.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="A.2.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#bernoulli-distribution"><i class="fa fa-check"></i><b>A.2.2</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="A.2.3" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#beta-binomial-distribution"><i class="fa fa-check"></i><b>A.2.3</b> Beta-Binomial distribution</a></li>
<li class="chapter" data-level="A.2.4" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>A.2.4</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="understanding-distributions-as-random-variables.html"><a href="understanding-distributions-as-random-variables.html"><i class="fa fa-check"></i><b>A.3</b> Understanding distributions as random variables</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="exponential-family-and-maximum-entropy.html"><a href="exponential-family-and-maximum-entropy.html"><i class="fa fa-check"></i><b>B</b> Exponential Family and Maximum Entropy</a><ul>
<li class="chapter" data-level="B.1" data-path="an-important-family-the-exponential-family.html"><a href="an-important-family-the-exponential-family.html"><i class="fa fa-check"></i><b>B.1</b> An important family: The Exponential Family</a></li>
<li class="chapter" data-level="B.2" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html"><i class="fa fa-check"></i><b>B.2</b> Excursos: “Information Entropy” and “Maximum Entropy Principal”</a><ul>
<li class="chapter" data-level="B.2.1" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html#information-entropy"><i class="fa fa-check"></i><b>B.2.1</b> Information Entropy</a></li>
<li class="chapter" data-level="B.2.2" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>B.2.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modeling" class="section level2">
<h2><span class="header-section-number">6.2</span> Modeling</h2>
<div id="introductory-example" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Introductory example</h3>
<p>As introductory example a coin flip experiment is considered. The question is if a particular coin is . In order to investigate this question a coin is flipped <span class="math inline">\(x\)</span> times (=trials) and the number of success (i.e. number of “head”) <span class="math inline">\(k\)</span> is recorded. This is repeated <span class="math inline">\(n\)</span> times (=observations).</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="co">#this code is just copy&amp;paste from above [it is included again for better comprehension]</span></a>
<a class="sourceLine" id="cb67-2" data-line-number="2"><span class="co">#simulate coin flip data set</span></a>
<a class="sourceLine" id="cb67-3" data-line-number="3">sample.space &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb67-4" data-line-number="4">theta &lt;-<span class="st"> </span><span class="fl">0.5</span>              <span class="co"># probability of a success (here: head)</span></a>
<a class="sourceLine" id="cb67-5" data-line-number="5">X &lt;-<span class="st"> </span><span class="dv">30</span>                   <span class="co"># number of trials in the experiment</span></a>
<a class="sourceLine" id="cb67-6" data-line-number="6">n &lt;-<span class="st"> </span><span class="dv">10</span>                   <span class="co"># number of observations</span></a>
<a class="sourceLine" id="cb67-7" data-line-number="7">k &lt;-<span class="st"> </span><span class="dv">0</span>                    <span class="co"># number of heads [initialization]</span></a>
<a class="sourceLine" id="cb67-8" data-line-number="8"></a>
<a class="sourceLine" id="cb67-9" data-line-number="9">## repeat experiment N-times</a>
<a class="sourceLine" id="cb67-10" data-line-number="10"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="st"> </span>n) {</a>
<a class="sourceLine" id="cb67-11" data-line-number="11">  k[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">sample</span>(sample.space, <span class="dt">size =</span> X, <span class="dt">replace =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb67-12" data-line-number="12">                     <span class="dt">prob =</span> <span class="kw">c</span>(theta, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta)))</a>
<a class="sourceLine" id="cb67-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb67-14" data-line-number="14"></a>
<a class="sourceLine" id="cb67-15" data-line-number="15">## show results in a tibble</a>
<a class="sourceLine" id="cb67-16" data-line-number="16">coin.flip &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="st">&quot;n&quot;</span> =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">1</span>, <span class="dt">to=</span>n, <span class="dt">by=</span><span class="dv">1</span>),</a>
<a class="sourceLine" id="cb67-17" data-line-number="17">                    <span class="st">&quot;k&quot;</span> =<span class="st"> </span>k,</a>
<a class="sourceLine" id="cb67-18" data-line-number="18">                    <span class="st">&quot;x&quot;</span> =<span class="st"> </span>X</a>
<a class="sourceLine" id="cb67-19" data-line-number="19">) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb67-20" data-line-number="20"><span class="st">  </span><span class="kw">print</span>()</a></code></pre></div>
<pre><code>## # A tibble: 10 x 3
##        n     k     x
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1    13    30
##  2     2    14    30
##  3     3    13    30
##  4     4    14    30
##  5     5    18    30
##  6     6    12    30
##  7     7    14    30
##  8     8    11    30
##  9     9    16    30
## 10    10    13    30</code></pre>
<p>The above table shows the observed outcome, but how the underlying probability of coming up  can be derived from that data set?</p>
</div>
<div id="steps-of-data-analysis" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Steps of Data Analysis</h3>
<p>The approach described here is based on <span class="citation">(McElreath <a href="#ref-mcelreath2015">2015</a>, <span class="citation">@kruschke2015</span>)</span>. Although the approach is introduced in a Bayesian context, it can be used as a general guideline (with some caveats):</p>
<ul>
<li>Identify the relevant variables according to the hypothesis (Measurement scales, predicted vs. predictor variables).</li>
<li>Define the descriptive model for the relevant variables.
<ul>
<li>likelihood distribution (distribution of each outcome variable that defines the plausibility of individual observations)</li>
<li>parameters (define and name all parameters of the model in order to relate the likelihood to the predictor variable(s))</li>
</ul></li>
<li>Bayesian context: Specify prior distribution(s).</li>
</ul>
<p>Further steps that will be subject of later chapters:</p>
<ul>
<li>Inference and interpretation of the results.</li>
<li>Model checking (Is the defined model adequate?)</li>
</ul>
<p><em>In the following we are interested in the question if a certain coin is biased.</em></p>
<p><strong>First step</strong> is to <em>identify the relevant variables</em>. For the coin flip experiment a coin is flipped <span class="math inline">\(n\)</span> times, whereby each observation consists of <span class="math inline">\(x\)</span> trials. The variable  <span class="math inline">\(Y\)</span> is dichotomous with the possible outcomes “head” and “tail”. For each observation the outcome is recorded: “0” for coming up tail and “1” for coming up head. The data are summarized for each observation. The variable <span class="math inline">\(k\)</span> indicates the number of heads coming up in <span class="math inline">\(x\)</span> trials.</p>
<p>In <strong>the second step</strong> a <em>descriptive model for the identified variables</em> has to be defined. An underlying probability <span class="math inline">\(\theta\)</span> is assumed, indicating the probability of heads coming up <span class="math inline">\(p(y=1)\)</span>. The probability that the outcome is head, given a value of parameter <span class="math inline">\(\theta\)</span>, is the value of <span class="math inline">\(\theta\)</span> <span class="citation">(Kruschke <a href="#ref-kruschke2015">2015</a>, 109)</span>. Formally, this can be written as
<span class="math display">\[p(y=1|\theta)=\theta\]</span>
As only two outcomes of <span class="math inline">\(Y\)</span> exists, the probability that the outcome is tail is the complementary probability <span class="math inline">\(1-\theta\)</span>. Both probabilities can be combined in one probability expression:
<span class="math display">\[Pr(Y|n,\theta)=\frac{n!}{y!(n-y)!}\theta^{y}(1-\theta)^{n-y}.\]</span>
This probability distribution is called the <strong>Binomial distribution</strong>. The fracture at the beginning indicates how many ordered sequences of <span class="math inline">\(n\)</span> outcomes a count <span class="math inline">\(y\)</span> have, therefore the important conceptional part is the latter one.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1"><span class="co"># Plot probability distribution: What would be the expected observed number </span></a>
<a class="sourceLine" id="cb69-2" data-line-number="2"><span class="co"># of &quot;head&quot; given the underlying prob. theta?</span></a>
<a class="sourceLine" id="cb69-3" data-line-number="3"> </a>
<a class="sourceLine" id="cb69-4" data-line-number="4"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb69-5" data-line-number="5">## theta=0.2</a>
<a class="sourceLine" id="cb69-6" data-line-number="6"><span class="kw">hist</span>(</a>
<a class="sourceLine" id="cb69-7" data-line-number="7">  <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="fl">1e6</span>, <span class="dt">size =</span> <span class="dv">30</span>, <span class="dt">prob =</span> <span class="fl">0.2</span>),</a>
<a class="sourceLine" id="cb69-8" data-line-number="8">  <span class="dt">xlab =</span> <span class="st">&quot;k&quot;</span>,</a>
<a class="sourceLine" id="cb69-9" data-line-number="9">  <span class="dt">main =</span> <span class="st">&quot;Binomial(1e6,0.2)&quot;</span>,</a>
<a class="sourceLine" id="cb69-10" data-line-number="10">  <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),</a>
<a class="sourceLine" id="cb69-11" data-line-number="11">  <span class="dt">freq =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb69-12" data-line-number="12">)</a>
<a class="sourceLine" id="cb69-13" data-line-number="13">## theta=0.5</a>
<a class="sourceLine" id="cb69-14" data-line-number="14"><span class="kw">hist</span>(</a>
<a class="sourceLine" id="cb69-15" data-line-number="15">  <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="fl">1e6</span>, <span class="dt">size =</span> <span class="dv">30</span>, <span class="dt">prob =</span> <span class="fl">0.5</span>),</a>
<a class="sourceLine" id="cb69-16" data-line-number="16">  <span class="dt">xlab =</span> <span class="st">&quot;k&quot;</span>,</a>
<a class="sourceLine" id="cb69-17" data-line-number="17">  <span class="dt">main =</span> <span class="st">&quot;Binomial(1e6,0.5)&quot;</span>,</a>
<a class="sourceLine" id="cb69-18" data-line-number="18">  <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),</a>
<a class="sourceLine" id="cb69-19" data-line-number="19">  <span class="dt">freq =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb69-20" data-line-number="20">)</a>
<a class="sourceLine" id="cb69-21" data-line-number="21">## theta=0.8</a>
<a class="sourceLine" id="cb69-22" data-line-number="22"><span class="kw">hist</span>(</a>
<a class="sourceLine" id="cb69-23" data-line-number="23">  <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="fl">1e6</span>, <span class="dt">size =</span> <span class="dv">30</span>, <span class="dt">prob =</span> <span class="fl">0.8</span>),</a>
<a class="sourceLine" id="cb69-24" data-line-number="24">  <span class="dt">xlab =</span> <span class="st">&quot;k&quot;</span>,</a>
<a class="sourceLine" id="cb69-25" data-line-number="25">  <span class="dt">main =</span> <span class="st">&quot;Binomial(1e6,0.8)&quot;</span>,</a>
<a class="sourceLine" id="cb69-26" data-line-number="26">  <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),</a>
<a class="sourceLine" id="cb69-27" data-line-number="27">  <span class="dt">freq =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb69-28" data-line-number="28">)</a></code></pre></div>
<p><img src="I2DA_files/figure-html/unnamed-chunk-40-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>When the coin is flipped only once, then the probabilty can be written as:
<span class="math display">\[Pr(Y|\theta)=\theta^{y}(1-\theta)^{1-y}.\]</span>
This special variant of the Binomial distribution is the so-called <strong>Bernoulli distribution</strong>. To see the connection to the first considerations: When the outcome “head” is observed the equation reduces to <span class="math inline">\(Pr(y=1|\theta)=\theta\)</span> and when the outcome “tail” is observed the equation results in <span class="math inline">\(Pr(y=0|\theta)=(1-\theta).\)</span></p>
<p>Accordingly, for the introductory example it can be noted that the coin flip variable <span class="math inline">\(Y\)</span>  Binomial distribution. (Note: For Bayes’ rule the  is needed. Remember, the likelihood function treats <span class="math inline">\(\theta\)</span> as unknow and the data as known. This role of parameter is exchanged in a probability distribution.)</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1"><span class="co"># calculate the Liklihood function</span></a>
<a class="sourceLine" id="cb70-2" data-line-number="2">binomial.likelihood &lt;-<span class="st"> </span><span class="cf">function</span>(n, k, theta){theta<span class="op">^</span>k<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>theta)<span class="op">^</span>(n<span class="op">-</span>k)}</a>
<a class="sourceLine" id="cb70-3" data-line-number="3">theta &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">0</span>, <span class="dt">to=</span><span class="dv">1</span>, <span class="dt">by=</span><span class="fl">0.01</span>)</a>
<a class="sourceLine" id="cb70-4" data-line-number="4"></a>
<a class="sourceLine" id="cb70-5" data-line-number="5"><span class="co"># Plot likelihood: What would be the expected underlying prob. theta given </span></a>
<a class="sourceLine" id="cb70-6" data-line-number="6"><span class="co"># observed number of &quot;head&quot; in 100 observations?</span></a>
<a class="sourceLine" id="cb70-7" data-line-number="7"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb70-8" data-line-number="8"><span class="kw">plot</span>(theta, <span class="kw">binomial.likelihood</span>(<span class="dv">100</span>,<span class="dv">20</span>,theta), <span class="dt">xlab=</span><span class="kw">expression</span>(theta), </a>
<a class="sourceLine" id="cb70-9" data-line-number="9">     <span class="dt">ylab=</span><span class="st">&quot;likelihood&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb70-10" data-line-number="10"><span class="kw">plot</span>(theta,<span class="kw">binomial.likelihood</span>(<span class="dv">100</span>,<span class="dv">50</span>,theta), <span class="dt">xlab=</span><span class="kw">expression</span>(theta), </a>
<a class="sourceLine" id="cb70-11" data-line-number="11">     <span class="dt">ylab=</span><span class="st">&quot;likelihood&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb70-12" data-line-number="12"><span class="kw">plot</span>(theta,<span class="kw">binomial.likelihood</span>(<span class="dv">100</span>,<span class="dv">80</span>,theta), <span class="dt">xlab=</span><span class="kw">expression</span>(theta), </a>
<a class="sourceLine" id="cb70-13" data-line-number="13">     <span class="dt">ylab=</span><span class="st">&quot;likelihood&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</a></code></pre></div>
<p><img src="I2DA_files/figure-html/unnamed-chunk-41-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>The third step</strong> is solely a , that is the <em>incorporation of prior knowledge</em>. What do we believe about the coin bias <span class="math inline">\(\theta\)</span> before seeing the data? Assuming that no expectation about <span class="math inline">\(\theta\)</span> exists a priori, indicating that all values of <span class="math inline">\(\theta\)</span> between 0 and 1 are equally probable. This can be modeled by a uniform distribution or as already visualized as Beta distribution with parameters a=1 and b=1 (see following figure).</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1"><span class="co"># Modelling prior knowledge &quot;ignorance&quot;</span></a>
<a class="sourceLine" id="cb71-2" data-line-number="2"></a>
<a class="sourceLine" id="cb71-3" data-line-number="3"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb71-4" data-line-number="4">## simulated a uniform(0,1) distribution</a>
<a class="sourceLine" id="cb71-5" data-line-number="5">rethinking<span class="op">::</span><span class="kw">dens</span>(<span class="kw">runif</span>(<span class="dt">n=</span><span class="fl">1e6</span>,<span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">1</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">1.5</span>), </a>
<a class="sourceLine" id="cb71-6" data-line-number="6">     <span class="dt">xlab=</span><span class="kw">expression</span>(theta), <span class="dt">main=</span><span class="st">&quot;Uniform(0,1)&quot;</span>)</a>
<a class="sourceLine" id="cb71-7" data-line-number="7">## simulates a beta(1,1) distribution</a>
<a class="sourceLine" id="cb71-8" data-line-number="8">rethinking<span class="op">::</span><span class="kw">dens</span>(<span class="kw">rbeta</span>(<span class="dt">n=</span><span class="fl">1e6</span>,<span class="dt">shape1=</span><span class="dv">1</span>,<span class="dt">shape2=</span><span class="dv">1</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">1.5</span>), </a>
<a class="sourceLine" id="cb71-9" data-line-number="9">     <span class="dt">xlab=</span><span class="kw">expression</span>(theta), <span class="dt">main=</span><span class="st">&quot;Beta(1,1)&quot;</span>)</a></code></pre></div>
<p>So far, the coin flip model is define conceptionally. In the following some notational considerations have to be made.</p>
</div>
<div id="notation" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Notation</h3>
<div id="textual-notation" class="section level4">
<h4><span class="header-section-number">6.2.3.1</span> Textual notation</h4>
<p>In the textual notation, first the prior assumptions (if the Bayesian perspective is taken) are described. For the coin flip example this is:
<span class="math display">\[\theta \sim Beta(1,1).\]</span>
The symbol “<span class="math inline">\(\sim\)</span>” means “is distributed as”, thus, the above equation says before seeing the data all possible values of <span class="math inline">\(\theta\)</span> between 0 and 1 are assumed to be equally likely.</p>
<p>Subsequently, the descriptive model for the data has to be defined. As already described in the section above, it is assumed that the observed data (upcoming of heads <span class="math inline">\(k\)</span>) are distributed as Binomial distribution with given <span class="math inline">\(n\)</span> (number of observations) and unknown <span class="math inline">\(\theta\)</span>. This relation is denoted symbollically as
<span class="math display">\[k\sim Binomial(\theta|n).\]</span>
To summarize the current model (whereby the prior knowledge is only considered from a Bayesian perspective):
<span class="math display">\[\theta \sim Beta(1,1),\]</span>
<span class="math display">\[k\sim Binomial(\theta|n).\]</span></p>
</div>
<div id="graphical-notation" class="section level4">
<h4><span class="header-section-number">6.2.3.2</span> Graphical notation</h4>
<p>When models get very complex and incorporate many parameters it can be difficult to tease out all relations between the model components. In such a situation a graphical notation of a model might be helpful. In the following the convention described in Wagenmakers and Lee’s  (2014) is used: The graph structure is used to indicate dependencies between the variables, with children depending on their parents <span class="citation">(Lee and Wagenmakers <a href="#ref-leeWagen2014">2014</a>)</span>. General conventions:</p>
<ul>
<li>Nodes - problem relevant variables,</li>
<li>shaded nodes - observed variables,</li>
<li>unshaded nodes - unobserved variables,</li>
<li>circular nodes - continuous variables,</li>
<li>square nodes - discrete variables,</li>
<li>single line - stochastic dependency, and</li>
<li>double line - deterministic dependency.</li>
</ul>
<p>For the introductory example this indicates:</p>
<ul>
<li>relevant variables: number of trials (<span class="math inline">\(n\)</span>), number of success (<span class="math inline">\(k\)</span>) and probability for a success (<span class="math inline">\(\theta\)</span>),</li>
<li>observed variables: <span class="math inline">\(n\)</span> and <span class="math inline">\(k\)</span>,</li>
<li>unobserved variables: <span class="math inline">\(\theta\)</span>,</li>
<li>continuous variable: <span class="math inline">\(\theta\)</span>,</li>
<li>discrete variables: <span class="math inline">\(n\)</span> and <span class="math inline">\(k\)</span>.</li>
</ul>
<p>In the next step the dependencies have to be determined:</p>
<p>The number of success <span class="math inline">\(k\)</span> depends on the probability of a success <span class="math inline">\(\theta\)</span> as well as on the number of trials <span class="math inline">\(n\)</span>.</p>
<p>Finally, the graphical structure together with the textual notation can be represented:</p>
<div class="figure">
<img src="https://github.com/michael-franke/intro-data-analysis/blob/master/chapters/images/Graph_Binom.png" alt="Graphical notation Beta-Binomial Modell - One group" />
<p class="caption">Graphical notation Beta-Binomial Modell - One group</p>
</div>
</div>
</div>
<div id="an-outlook-hierarchical-models" class="section level3">
<h3><span class="header-section-number">6.2.4</span> An outlook: Hierarchical models</h3>
<p>Often data can be considered as part of an overall structure. Single observations can be modelled belonging into different groups. These groups in turn are part of a superordinate group etc. Such information are presented in a model in form of a hierarchy.</p>
<p>For example, consider again the coin flip experiment. The outcome of  is influenced by the probability <span class="math inline">\(\theta\)</span>. Further, <span class="math inline">\(\theta\)</span> is assumed to be distributed as Beta(1,1). Remember that the parameter a and b of a Beta-distribution can be considered in this context as: <span class="math inline">\(a=\)</span>number of heads and <span class="math inline">\(b=\)</span> number of tails, consequently, <span class="math inline">\(n=a+b\)</span>.</p>
<div id="reparameterization-of-a-beta-distribution" class="section level4">
<h4><span class="header-section-number">6.2.4.1</span> Reparameterization of a Beta distribution</h4>
<p>Probability distributions can be described by their  and  (or dispersion). The  of a Beta distribution is defined as:</p>
<p><span class="math inline">\(\omega=\frac{a-1}{a+b-2}\)</span>,</p>
<p>and the concentration as:</p>
<p><span class="math inline">\(\kappa=a+b.\)</span></p>
<p>The nice thing is, that the definition of the  as well as of the  consists solely of the parameters a and b. Therefore, it is possible to re-express the parameters of a Beta density in terms of <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\kappa\)</span>, such that:</p>
<p><span class="math display">\[Beta(a,b)=Beta\left(\omega(\kappa -2)+1, (1-\omega)(\kappa -2)+1\right).\]</span></p>
<p><em>Why this is useful? And what is its value in connection with hierarchical modeling?</em></p>
<p>Return back to the coin flip experiment. So far, the parameters of the prior on <span class="math inline">\(\theta\)</span> are fixed: <span class="math inline">\(a=1\)</span> and <span class="math inline">\(b=1\)</span>. Assume that we get further information: The manifacturing process of the coins has a bias near <span class="math inline">\(\omega\)</span> (example taken from <span class="citation">(Kruschke <a href="#ref-kruschke2015">2015</a>)</span>). But how to incorporate this additional knowledge in the model?</p>
<p>At this point, the hierarchy and the reparameterization come into play. Hierarchy because a further assumption is placed on top of the existing model and reparameterization, because we want to express the prior in terms of the mode <span class="math inline">\(\omega\)</span>.</p>
<p>Such that the model can be assumed as follows:</p>
<div class="figure">
<img src="https://github.com/michael-franke/intro-data-analysis/blob/master/chapters/images/binom-onelevel.png" alt="Graphical notation hierarchical Beta-Binomial Modell - One group" />
<p class="caption">Graphical notation hierarchical Beta-Binomial Modell - One group</p>
</div>
<p>Now, the parameters of the hyperpriors (Gamma and Beta) are fixed, but they can be treated as parameters as well..as such hierarchical models can be created with any degree of complexity:</p>
<div class="figure">
<img src="https://github.com/michael-franke/intro-data-analysis/blob/master/chapters/images/hierarchical-model.png" alt="Graphical notation hierarchical Beta-Binomial Modell - One group" />
<p class="caption">Graphical notation hierarchical Beta-Binomial Modell - One group</p>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-kruschke2015">
<p>Kruschke, John. 2015. <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press.</p>
</div>
<div id="ref-leeWagen2014">
<p>Lee, Michael D., and Eric-Jan Wagenmakers. 2014. <em>Bayesian cognitive modeling: A practical course</em>. Cambridge university press.</p>
</div>
<div id="ref-mcelreath2015">
<p>McElreath, Richard. 2015. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</em>. Chapman; Hall/CRC.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="likelihood-prior-posterior.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="further-examples.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

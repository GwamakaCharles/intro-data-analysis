[
["index.html", "Introduction to Data Analysis Preface 0.1 Testing / Showcasing", " Introduction to Data Analysis last rendered at: 2019-09-21 14:30:19 Preface The book introduces key concepts of data analysis from a frequentist and a Bayesian tradition. It uses R to handle, plot and analyze data. It relies on simulation to illustrate selected statistical concepts. 0.1 Testing / Showcasing Don’t pay too much attention to what is written here. 0.1.1 Quotes This is a quote: Tidy datasets […] have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. — Wickham (2014) 0.1.2 Infobox At certain stages, possibly at the end of chapters or after important concepts, we might want to use a special infobox (see .infobox in styles.css) to summarise it or give food for thought. Like this: A horse walks into a bar and orders a pint. The barkeep says “you’re in here pretty often. Think you might be an alcoholic?”, to which the horse says “I don’t think I am.”, and vanishes from existence. See, the joke is about Descartes’ famous philosophy of ’I think therefore, I am&quot;, but to explain that part before the rest of the joke would be to put Descartes before the horse. We can have boxes with different icons for different purposes: This might be useful for excercises or general questions. Do you like it? Sometimes there are things that are really important, like exceptions to general rules. This box might be appropriate for these. “More research needs to be done” as an infobox. 0.1.3 Plots This is a plot of quite a famous dataset (Anscombe 1973): tibble( grp = rep(c(&quot;I&quot;, &quot;II&quot;, &quot;III&quot;, &quot;IV&quot;), each = 11), x = c(anscombe$x1, anscombe$x2, anscombe$x3, anscombe$x4), y = c(anscombe$y1, anscombe$y2, anscombe$y3, anscombe$y4) ) %&gt;% ggplot(aes(x, y)) + geom_smooth(method = lm, se = F) + geom_point(color = &quot;orange&quot;, size = 2) + scale_y_continuous(breaks = scales::pretty_breaks()) + scale_x_continuous(breaks = scales::pretty_breaks()) + labs(title = &quot;Anscombe&#39;s Quartet&quot;, x = NULL, y = NULL, subtitle = bquote(y == 0.5 * x + 3 ~ (R^2 %~~% .667) ~ &quot;for all datasets&quot;)) + facet_wrap(~grp, ncol = 2, scales = &quot;free_x&quot;) + theme(strip.background = element_rect(fill = &quot;#f2f2f2&quot;, colour = &quot;white&quot;)) References "],
["general-introduction.html", "1 General Introduction", " 1 General Introduction what stats is about different practices learning goals "],
["data.html", "2 Data", " 2 Data learning goal: how to arrange, summarize and visualize (aspects of data) to address a question of interest (“hypothesis-driven data poking”) different kinds of data summary statistics data wrangling data plotting "],
["basics-of-probability-theory.html", "3 Basics of Probability Theory 3.1 Probability 3.2 Structured events &amp; marginal distributions", " 3 Basics of Probability Theory to be covered: axiomatic definition, interpretation, joint distributions, marginalization, conditional probability &amp; Bayes rule. Random variables: discrete and continuous, expected values &amp; variance, examples. learning goal: get comfortable with basic notions of probability theory 3.1 Probability 3.1.1 Outcomes, events, observations We are interested in the space \\(\\Omega\\) of all elementary outcome \\(\\omega_1, \\omega_2, \\dots\\) of a process or event whose execution is (partially) random or unknown. Elementary outcomes are mutually exclusive. The set \\(\\Omega\\) exhausts all possibilities.1 Example. The set of elementary outcomes of a single coin flip is \\(\\Omega_{\\text{coin flip}} = \\left \\{ \\text{heads}, \\text{tails} \\right \\}\\). The elementary outcomes of tossing a six-sided die is \\(\\Omega_{\\text{standard die}} = \\{\\) ⚀ , ⚁ , ⚂ , ⚃ , ⚄ , ⚅ \\(\\}\\).2 An event \\(A\\) is a subset of \\(\\Omega\\). Think of an event as a (possibly partial) observation. We might observe, for instance, not the full outcome of tossing a die, but only that there is a dot in the middle. This would correspond to the event \\(A = \\{\\) ⚀ , ⚂ , ⚄ \\(\\}\\), i.e., observing an odd numbered outcome. The trivial observation \\(A = \\Omega\\) and the impossible observation \\(A = \\emptyset\\) are counted as events, too. The latter is included for technical reasons. For any two events \\(A, B \\subseteq \\Omega\\), standard set operations correspond to logical connections in the usual way. For example, the conjunction \\(A \\cap B\\) is the observation of both \\(A\\) and \\(B\\); the disjunction \\(A \\cup B\\) is the observation that it is either \\(A\\) or \\(B\\); the negation of \\(A\\), \\(\\overline{A} = \\left \\{ \\omega \\in \\Omega \\mid \\omega \\not \\in A \\right \\}\\), is the observation that it is not \\(A\\). 3.1.2 Probability distributions A probability distribution \\(P\\) over \\(\\Omega\\) is a function \\(P \\ \\colon \\ \\mathfrak{P}(\\Omega) \\rightarrow \\mathbb{R}\\) that assigns to all events \\(A \\subseteq \\Omega\\) a real number (from the unit interval, see A1 below), such that the following (so-called Kolmogorov axioms) are satisfied: A1. \\(0 \\le P(A) \\le 1\\) A2. \\(P(\\Omega) = 1\\) A3. $P(A_1 A_2 A_3 ) = P(A_1) + P(A_2) + P(A_3) + $ whenever \\(A_1, A_2, A_3, \\dots\\) are mutually exclusive3 Occasionally we encounter notation \\(P \\in \\Delta(\\Omega)\\) to express that \\(P\\) is a probability distribution over \\(\\Omega\\). (E.g., in physics, theoretical economics or game theory. Less so in psychology or statistics.) If \\(\\omega \\in \\Omega\\) is an elementary event, we often write \\(P(\\omega)\\) as a shorthand for \\(P(\\left \\{ \\omega \\right \\})\\). In fact, if \\(\\Omega\\) is finite, it suffices to assign probabilities to elementary outcomes. A number of rules follow immediately from of this definition (prove this!): C1. \\(P(\\emptyset) = 0\\) C2. \\(P(\\overline{A}) = 1 - P(A)\\) C3. \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) for any \\(A, B \\subseteq \\Omega\\) 3.1.3 Interpretations of probability It is reasonably safe, at least preliminarily, to think of probability, as defined above, as a handy mathematical primitive which is useful for certain applications. There are at least three ways of thinking about where this primitive probability might come from, roughly paraphrasable like so: Frequentist: Probabilities are generalizations of intuitions/facts about frequencies of events in repeated executions of a random event. Subjectivist: Probabilities are subjective beliefs by a rational agent who is uncertain about the outcome of a random event. Realist: Probabilities are a property of an intrinsically random world. 3.1.4 Urns and frequencies Think of an urn as a container which contains a number of \\(N &gt; 1\\) balls. Balls can be of different color. For example, let us suppose that our urn has \\(k &gt; 0\\) black balls and \\(N-k\\) white balls. (There is at least one black and one white ball.) For a single random draw from our urn we have: \\(\\Omega_{\\text{our urn}} = \\left \\{ \\text{white}, \\text{black} \\right \\}\\). If we imagine an infinite sequence of single draws from our urn, putting whichever ball we drew back in after every draw, the limiting proportion with which we draw a black ball is \\(\\frac{k}{N}\\). (If in doubt, execute this experiment. By hand or by computer.) This statement about frequency is what motivates saying that the probability of drawing a black ball on a single trial is (or should be4) \\(P(\\text{black}) = \\frac{k}{N}\\). 3.2 Structured events &amp; marginal distributions 3.2.1 Probability table for a flip-&amp;-draw scenario Suppose we have two urns. Both have \\(N=10\\) balls. Urn 1 has \\(k_1=2\\) black and \\(N-k_1 = 8\\) white balls. Urn 2 has \\(k_2=4\\) black and \\(N-k_2=6\\) white balls. We sometimes draw from urn 1, sometimes from urn 2. To decide, we flip a fair coin. If it comes up heads, we draw from urn 1; if it comes up tails, we draw from urn 2. An elementary outcome of this two-step process of flip-&amp;-draw is a pair \\(\\langle \\text{outcome-flip}, \\text{outcome-draw} \\rangle\\). The set of all possible such outcomes is \\(\\Omega_{\\text{flip-&amp;-draw}} = \\left \\{ \\langle \\text{heads}, \\text{black} \\rangle, \\langle \\text{heads}, \\text{white} \\rangle, \\langle \\text{tails}, \\text{black} \\rangle, \\langle \\text{tails}, \\text{white} \\rangle \\right \\}\\). The probability of event \\(\\langle \\text{heads}, \\text{black} \\rangle\\) is given by multiplying the probability of seeing “heads” on the first flip, which happens with probability \\(0.5\\), and then drawing a black ball, which happens with probability \\(0.2\\), so that \\(P(\\langle \\text{heads}, \\text{black} \\rangle) = 0.5 \\cdot 0.2 = 0.1\\). The probability distribution over \\(\\Omega_{\\text{flip-draw}}\\) is consequently as in Table 3.1. (If in doubt, start flipping &amp; drawing and count your outcomes.) Table 3.1: my first table black white heads \\(0.5 \\cdot 0.2 = 0.1\\) \\(0.5 \\cdot 0.4 = 0.2\\) tails \\(0.5 \\cdot 0.8 = 0.4\\) \\(0.5 \\cdot 0.6 = 0.3\\) 3.2.2 Structured events and joint-probability distributions Table 3.1 is an example of a joint probability distribution over a structured event space, which here has two dimensions. Since our space of outcomes is the Cartesian product of two simpler outcome spaces, namely \\(\\Omega_{flip-\\&amp;-draw} = \\Omega_{flip} \\times \\Omega_{draw}\\),5 we can use notation \\(P(\\text{heads}, \\text{black})\\) as shorthand for \\(P(\\langle \\text{heads}, \\text{black} \\rangle)\\). More generally, if \\(\\Omega = \\Omega_1 \\times \\dots \\Omega_n\\), we can think of \\(P \\in \\Delta(\\Omega)\\) as a joint probability distribution over \\(n\\) subspaces. 3.2.3 Marginalization If \\(P\\) is a joint-probability distribution over event space \\(\\Omega = \\Omega_1 \\times \\dots \\Omega_n\\), the marginal distribution over subspace \\(\\Omega_i\\), \\(1 \\le i \\le n\\) is the probability distribution that assigns to all \\(A_i \\subseteq \\Omega_i\\) the probability:6 \\[ P(A_i) = \\sum_{A_1 \\subseteq \\Omega_{1}, \\dots , A_{i-1} \\subseteq \\Omega_{i-1}, A_{i+1} \\subseteq \\Omega_{i+1}, \\dots, A_n \\subseteq \\Omega_n} P(A_1, \\dots, A_{i-1}, A_{i}, A_{i+1}, \\dots A_n) \\] For example, the marginal distribution over coin flips derivable from the joint probability distribution in Table 3.1 gives \\(P(\\text{heads}) = P(\\text{tails}) = 0.5\\), since the sum of each row is exactly \\(0.5\\). The marginal distribution over flips derivable from Table~ has \\(P(\\text{black}) = 0.3\\) and \\(P(\\text{black}) = 0.7\\).7 For simplicity of exposure, we gloss over subtleties arising when dealing with infinite sets \\(\\Omega\\). We make up for this when we define probability density functions for continuous random variables, which is all the uncountable infinity that we will usually be concerned with in applied statistics.↩ Think of \\(\\Omega\\) as a partition of the space of all possible ways in which the world could be, where we lump together into one partition cell all ways in which the world could be that are equivalent regarding those aspects of reality that we are interested in. We do not care whether the coin lands in the mud or in the sand. It only matters whether it came up heads or tails. Each elementary event can be realized in myriad ways. \\(\\Omega\\) is our, the modellers’, first crude simplification of nature, abstracting away aspects we currently do not care about.↩ A3 is the axiom of countable additivity. Finite additivity may be enough for finite or countable sets \\(\\Omega\\), but infinite additivity is necessary for full generality in the uncountable case.↩ If probabilities are subjective beliefs, a rational agent is, in a sense, normatively required to assign exactly this probability.↩ With \\(\\Omega_{\\text{flip}} = \\left \\{ \\text{heads}, \\text{tails} \\right \\}\\) and \\(\\Omega_{\\text{draw}} = \\left \\{ \\text{black}, \\text{white} \\right \\}\\).↩ This notation, using \\(\\sum\\), assumes that subspaces are countable. In other cases, a parallel definition with integrals can be used.↩ The term ``marginal distribution’’ derives from such probability tables, where traditionally the sum of each row/column was written in the margins.↩ "],
["part-4-models.html", "4 Part 4: Models 4.1 Overview 4.2 Two notions of probability 4.3 Likelihood, Prior, &amp; Posterior 4.4 Modeling 4.5 Notation 4.6 Further examples 4.7 Further elaboration on modeling (in anticipation of the topic “estimation”)", " 4 Part 4: Models Lecture: Introduction to Statistics Winter term 2019/2020 4.1 Overview In the first section we introduce the based on the debate between and . After a short overview and background with the main ideas of each approach we formalize the conceptual ideas and the components of the presented model. We finish by discussing three models: , and model. 4.2 Two notions of probability What are probabilities? We look at two viewpoints: probabilities exist “outside in the world” or they are “subjective beliefs” (Kruschke 2015). Although both notions imply different approaches how to deal with probabilities, the mathematical properties are quite similar (Kruschke 2015). 4.2.1 Frequentism — Probabilities as properties of the world We now assume that probabilities are existent and properties of the world. When observing a particular object, then in the long run, we should be able to deduce from our observations the “inherent” probability of an outcome of this object. Frequentism is an approach that searches for relative frequencies in a large number of trials (Vallverdú 2016). Tossing a coin results in head or tail (for simplicity we do not consider the possibility that it stands on its edge). A Frequentist would toss a coin many times, take a note on each observation and, finally, calculate the relative frequency of each outcome. That is, the observed outcome divided by the number of tosses. In the long run, the outcome “head” or “tail” will be observed around 50% (given the coin is fair, the toss is not manipulated, no external factors like wind etc. influences the outcome, …). Therefore it is mandatory to obtain a large number of trials from which emerged the relative frequency from an event. — Vallverdú (2016), p.50 (emphasis is taken from the original) In other words: For Frequentists probabilities (relative frequencies) describe rather than subjective beliefs. 4.2.2 Bayesianism — Probabilities as subjective beliefs Another notion of probabilities is to think of them as “beliefs” inside our head. For example considering again the coin flip example, we could have a relatively strong belief that a coin is fair or we actually believe that a coin is fair but we are not so certain about that or we “just do not know” (see Fig. from left to right). The core of Bayesian methods is Bayes’ theorem which tell us how prior belief is combined with observed data: \\[P(H|Data)=\\frac{P(Data|H)*P(H)}{P(Data)}\\] \\[Posterior=\\frac{Likelihood*Prior}{Marginal\\textrm{ } Likelihood},\\] where \\(P(H|Data)\\) is the conditional probability () of the hypothesis H given a particular result (Data); \\(P(Data|H)\\) is the conditional probability () of a result(data) given the hypothesis H; \\(P(H)\\) is the of the hypothesis H; \\(P(Data)\\) is the of the data irrespective of the truth of any hypothesis. The job of the “marginal Likelihood” in the denominator is to standardize the posterior, to ensure it sums up to one (integrates to one). Therefore, the key lesson of Bayes’ theorem is (McElreath 2015): \\[Posterior \\propto Likelihood * Prior\\] What does that mean? Consider again the coin flip experiment. We have observed a certain amount of coin flip trials, thus we can describe a probability distribution: a list of possible outcomes and their corresponding probabilities (Likelihood) (Kruschke 2015). Furthermore, as we have stated above, we express a prior belief about our hypothesis, for example we might belief, that the coin is a trick coin and therefore extremely biased. Again, the mathematical way of expressing our belief is by assigning numbers to a set of mutually exclusive events (the prior). From that, finally, the rules of probability theory define a uniquely logical posterior for the prior, likelihood and data (Posterior). At this point we see an important difference between Frequentist and Bayesian methods: A parameter in Bayesian methods is conceptualized as a random variable with its own distribution (the posterior) that summarizes the current state of knowledge. The expected value of the posterior is the best guess about the true value of the parameter and its variability reflects the amount of uncertainty (Kline 2013). In Frequentist statistics, a parameter is seen as a constant that should be estimated with sample statistics (Kline 2013). 4.3 Likelihood, Prior, &amp; Posterior So far we wanted to clearly state the most important conceptual differences between Frequentism and Bayesianism and to introduce the core of Bayesian methods: Bayes’ theorem. Before we go further into the topic of modelling, some conceptual notions are neccessary. 4.3.1 Probability density function vs. Likelihood function As we already know from the “probability”-lecture, for a coin flip the probability of each outcome can be described with the , as there exist two discrete outcomes (head or tail) and a constant probability \\(\\theta\\): \\[p([X=x]|\\theta)=\\theta^{[x]}(1-\\theta)^{(1-[x])}\\] where \\(\\theta\\) is the probability of “head” for the coin flip; the bracket -[ ] indicates that we assume this parameter as unknown. With the formula above we assume that we know the probability \\(\\theta\\) and derive from this the distribution of possible outcomes. But we might be interested in a different perspective, that is the assumption that we have the data fixed but \\(\\theta\\) is unknown: the — a mathematical formula that specifies the plausibility of the data. It states the probability of any possible observation: \\[p(X=x|[\\theta])=[\\theta]^x(1-[\\theta])^{(1-x)}\\] In the first case, we assume the outcome to be an unknown parameter (variable), whereas in the latter case the unknown parameter is \\(\\theta\\). Please be aware that through exchanging the roles of \\(x\\) and \\(\\theta\\) in the second equation (likelihood function) this function is no longer a probability distribution and thus does not integrate to 1. 4.3.2 Priors General introduction to priors… A prior is a initial probability assignment for each possible value of the parameter (McElreath 2015). 4.3.3 Posterior 4.4 Modeling 4.4.1 Introductory example As introductory example a coin flip experiment is considered. The question is if a particular coin is . In order to investigate this question a coin is flipped \\(x\\) times (=trials) and the number of success (i.e. number of “head”) \\(k\\) is recorded. This is repeated \\(n\\) times (=observations). #simulate coin flip data set sample.space &lt;- c(0, 1) theta &lt;- 0.5 # probability of a success (here: head) X &lt;- 30 # number of trials in the experiment n &lt;- 10 # number of observations k &lt;- 0 # number of heads [initialization] ## repeat experiment N-times for (i in 1: n) { k[i] &lt;- sum(sample(sample.space, size = X, replace = TRUE, prob = c(theta, 1 - theta))) } ## show results in a tibble coin.flip &lt;- tibble(&quot;n&quot; = seq(from=1, to=n, by=1), &quot;k&quot; = k, &quot;x&quot; = X ) %&gt;% print() ## # A tibble: 10 x 3 ## n k x ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 12 30 ## 2 2 12 30 ## 3 3 16 30 ## 4 4 18 30 ## 5 5 17 30 ## 6 6 13 30 ## 7 7 13 30 ## 8 8 14 30 ## 9 9 11 30 ## 10 10 16 30 The above table shows the observed outcome, but how the underlying probability of coming up can be derived from that data set? 4.4.2 Steps of Data Analysis The approach described here is based on (McElreath 2015, @kruschke2015). Although the approach is introduced in a Bayesian context, it can be used as a general guideline (with some caveats): Identify the relevant variables according to the hypothesis. (Measurement scales, predicted vs. predictor variables). Define the descriptive model for the relevant variables. likelihood distribution (distribution of each outcome variable that defines the plausibility of individual observations) parameters (define and name all parameters of the model in order to relate the likelihood to the predictor variable(s)) Bayesian context: Specify a prior distribution. Further steps that will be subject of later chapters: Inference and interpretion of the results. Model checking (Is the defined model adequate?) The hypothesis for the introductory example: . First step is to identify the relevant variables. For the coin flip experiment a coin is flipped \\(n\\) times, wherby each observation consists of \\(x\\) trials. The variable \\(Y\\) is dichotomous with the possible outcomes “head” and “tail”. For each observation the outcome is recorded: “0” for coming up tail and “1” for coming up head. The data are summarized for each observation. The variable \\(k\\) indicates the number of heads coming up in \\(x\\) trials. In the second step a descriptive model for the described variables has to be defined. An underlying probability \\(\\theta\\) is assumed, indicating the probability of heads coming up \\(p(y=1)\\). The probability that the outcome is head, given a value of parameter \\(\\theta\\), is the value of \\(\\theta\\) (Kruschke 2015, 109). Formally, this can be written as \\[p(y=1|\\theta)=\\theta\\] As only two outcomes of \\(Y\\) exists, the probability that the outcome is tail is the complementary probability \\(1-\\theta\\). Both probabilities can be combined in one probability expression: \\[Pr(Y|n,\\theta)=\\frac{n!}{y!(n-y)!}\\theta^{y}(1-\\theta)^{n-y}.\\] This probability distribution is called the Binomial distribution. The fracture at the beginning indicates how many ordered sequences of \\(n\\) outcomes a count \\(y\\) have, therefore the important conceptional part is the latter one. # Plot probability distribution: What would be the expected observed number # of &quot;head&quot; given the underlying prob. theta? par(mfrow = c(2, 2)) ## theta=0.2 hist( rbinom(n = 1e6, size = 30, prob = 0.2), xlab = &quot;k&quot;, main = &quot;Binomial(1e6,0.2)&quot;, xlim = c(0, 30), freq = FALSE ) ## theta=0.5 hist( rbinom(n = 1e6, size = 30, prob = 0.5), xlab = &quot;k&quot;, main = &quot;Binomial(1e6,0.5)&quot;, xlim = c(0, 30), freq = FALSE ) ## theta=0.8 hist( rbinom(n = 1e6, size = 30, prob = 0.8), xlab = &quot;k&quot;, main = &quot;Binomial(1e6,0.8)&quot;, xlim = c(0, 30), freq = FALSE ) When the coin is flipped only once, then the probabilty can be written as: \\[Pr(Y|\\theta)=\\theta^{y}(1-\\theta)^{1-y}.\\] This special variant of the Binomial distribution is the so-called Bernoulli distribution. To see the connection to the first considerations: When the outcome “head” is observed the equation reduces to \\(Pr(y=1|\\theta)=\\theta\\) and when the outcome “tail” is observed the equation results in \\(Pr(y=0|\\theta)=(1-\\theta).\\) Accordingly, for the introductory example it can be noted that the coin flip variable \\(Y\\) Binomial distribution. (Note: For Bayes’ rule the is needed. Remember, the likelihood function treats \\(\\theta\\) as unknow and the data as known, while this role of parameter is exchanged in a probability distribution.) # calculate the Liklihood function binomial.likelihood &lt;- function(n, k, theta){theta^k*(1-theta)^(n-k)} theta &lt;- seq(from=0, to=1, by=0.01) # Plot likelihood: What would be the expected underlying prob. theta given # observed number of &quot;head&quot; in 100 observations? par(mfrow=c(2,2)) plot(theta, binomial.likelihood(100,20,theta), xlab=expression(theta), ylab=&quot;likelihood&quot;, type=&quot;l&quot;) plot(theta,binomial.likelihood(100,50,theta), xlab=expression(theta), ylab=&quot;likelihood&quot;, type=&quot;l&quot;) plot(theta,binomial.likelihood(100,80,theta), xlab=expression(theta), ylab=&quot;likelihood&quot;, type=&quot;l&quot;) The third step is solely a , that is the incorporation of prior knowledge. What do we believe about the coin bias \\(\\theta\\) before seeing the data? Assuming that no expectation about \\(\\theta\\) exists a priori, indicating that all values of \\(\\theta\\) between 0 and 1 are equally probable. This can be modeld by a uniform distribution or a Beta distribution with parameters a=1 and b=1 (see following figure). # Modelling prior knowledge &quot;ignorance&quot; par(mfrow = c(2, 2)) ## simulated a uniform(0,1) distribution rethinking::dens(runif(n=1e6,min=0, max=1), ylim = c(0,1.5), xlab=expression(theta), main=&quot;Uniform(0,1)&quot;) ## simulates a beta(1,1) distribution rethinking::dens(rbeta(n=1e6,shape1=1,shape2=1), ylim = c(0,1.5), xlab=expression(theta), main=&quot;Beta(1,1)&quot;) So far, the coin flip model is define conceptionally. In the following some notational considerations have to made. 4.5 Notation 4.5.1 Textual notation In the textual notation, first the prior assumptions (if the Bayesian perspective is taken) are indicated. For the coin flip example this is: \\[\\theta \\sim Beta(1,1).\\] The symbol “\\(\\sim\\)” means “is distributed as”, thus, the above equation says before seeing the data all possible values of \\(\\theta\\) between 0 and 1 are assumed to be equally likely. Subsequently, the descriptive model for the data has to be defined. As already described in the section above, it is assumed that the observed data (upcoming of heads \\(k\\)) are distributed as Binomial distribution with given \\(n\\) (number of observations) and unknown \\(\\theta\\). This relation is denoted symbollically as \\[k\\sim Binomial(\\theta|n).\\] To summarize the current model (whereby the prior knowledge is only considered from a Bayesian perspective): \\[\\theta \\sim Beta(1,1),\\] \\[k\\sim Binomial(\\theta|n).\\] 4.5.2 Graphical notation When models get very complex and incorporate many parameters it can be difficult to tease out all relations between the model components. In such a situation a graphical notation of a model might be helpful. In the following the convention described in Wagenmakers and Lee’s (2014) is used: The graph structure is used to indicate dependencies between the variables, with children depending on their parents (Lee and Wagenmakers 2014). General conventions: Nodes - problem relevant variables, shaded nodes - observed variables, unshaded nodes - unobserved variables, circular nodes - continuous variables, square nodes - discrete variables, single line - stochastic dependency, and double line - deterministic dependency. For the introductory example this indicates: relevant variables: number of trials (\\(n\\)), number of success (\\(k\\)) and probability for a success (\\(\\theta\\)), observed variables: \\(n\\) and \\(k\\), unobserved variables: \\(\\theta\\), continuous variable: \\(\\theta\\), discrete variables: \\(n\\) and \\(k\\). In the next step the dependencies have to be determined: The number of success \\(k\\) depends on the probability of a success \\(\\theta\\) as well as on the number of trials \\(n\\). Finally, the graphical structure together with the textual notation can be represented: 4.6 Further examples 4.6.1 Difference between two groups In the introductory example we asked for the underlying probility \\(\\theta\\) of a single coin that was flipped repeatedley. Consider now, that a second coin \\(y_2\\) is introduced. One question that arises might be for example: #simulate flipps of two coins sample.space &lt;- c(0,1) ##First coin: theta1 &lt;- 0.5 # probability of a success (here: head) X1 &lt;- 30 # number of trials in the experiment n1 &lt;- 100 # number of observations k1 &lt;- 0 # number of heads [initialization] for (i in 1: n1) { k1[i] &lt;- sum(sample(sample.space, size = X1, replace = TRUE, prob = c(theta1, 1 - theta1))) } ##Second coin: theta2 &lt;- 0.7 # probability of a success (here: head) X2 &lt;- 30 # number of trials in the experiment n2 &lt;- 100 # number of observations k2 &lt;- 0 # number of heads [initialization] ## repeat experiment N-times for (i in 1: n2) { k2[i] &lt;- sum(sample(sample.space, size = X2, replace = TRUE, prob = c(theta2, 1 - theta2))) } ## show results in a tibble coin.flip2 &lt;- tibble(&quot;coin&quot; = c(replicate(n1,&quot;coin1&quot;),replicate(n2,&quot;coin2&quot;)), &quot;n&quot; = c(seq(from=1, to=n1, by=1),seq(from=1, to=n2, by=1)), &quot;k&quot; = c(k1,k2), &quot;x&quot; = c(replicate(n1,X1),replicate(n2,X2)) ) %&gt;% print() ## # A tibble: 200 x 4 ## coin n k x ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 coin1 1 13 30 ## 2 coin1 2 19 30 ## 3 coin1 3 9 30 ## 4 coin1 4 15 30 ## 5 coin1 5 15 30 ## 6 coin1 6 16 30 ## 7 coin1 7 18 30 ## 8 coin1 8 15 30 ## 9 coin1 9 18 30 ## 10 coin1 10 18 30 ## # … with 190 more rows #Plotting the observed results ggplot(data=coin.flip2,mapping = aes(x=k, fill=coin ))+ geom_histogram() 4.6.1.1 Conceptual steps for modeling We suppose that the underlying probabilities of the two coins correspond to different latent variables \\(\\theta_1\\) and \\(\\theta_2\\). First step is again the identification of the relevant variables according to the research question. As already indicated for the “one coin” example we have: the observed number of heads \\(k_1\\) and \\(k_2\\) (for each coin, respectively), which is influenced by the number of observations \\(n_1\\) and \\(n_2\\) and by the underlying probabilities \\(\\theta_1\\) and \\(\\theta_2\\). Furthermore, from a conceptional perspective, we are interested in the difference between the coin biases. Therefore a further variable will be introduced \\(\\delta\\), defined by: \\[\\delta =\\theta_1 - \\theta_2.\\] The distributional assumptions, according to the second and third step, can be adopted from the “one coin” example, such that the graphical notation (including the textual notation) can be denoted as follows: 4.6.1.2 Notation Beta-Binomial Model - Two Groups 4.6.2 Simple linear regression with one metric predictor The following example originates from a data set in which speed of cars and the distance taken to stop was recorded. It is a simple data set good for introducing the basic ideas for simple linear regression. #The &quot;cars&quot; data set data(cars) #take a look at the variables included in the data set str(cars) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ speed: num 4 4 7 7 8 9 10 10 10 11 ... ## $ dist : num 2 10 4 22 16 10 18 26 34 17 ... One possible question could be how much the stopping distance increases when the speed of a car increases. 4.6.2.1 Conceptual steps for modeling First step is to identify the relevant variables. In this case these are “speed” measured in mph and “distance” measured in ft, thus, both variables are metric variables. As distance will be predicted from speed. The is “distance” and the is “speed”. A scatter plot can visualize a possible relationship between both variables. plot(x=cars$speed,y=cars$dist, type=&quot;p&quot;, main=&quot;scatter plot of cars data set&quot;, ylab=&quot;distance in ft&quot;, xlab=&quot;speed in mph&quot;) Next step is to define a descriptive model of the data. According to the scatter plot it is not too absurd to think that distance might be proportional to speed. Therefore, a linear relationship between both variables can be assumed, where speed is used i order to predict distance. But how can the distribution of the predicted variable “distance” be described? The following plot shows in blue the density of the actual distance values. #density of distance values in blue #(in black simulation of a normal distribution) dens(cars$dist, col=&quot;blue&quot;, norm.comp = TRUE, main=&quot;Distribution of distance&quot;, xlab=&quot;distance in ft&quot;) Although the distribution of “distance” values is not identical to the corresponding normal distribution, it can be assumed that the values follow a normal distribution. The underlying consideration is that the distance values \\(y_i\\) are distributed randomly according to a normal distribution around the predicted value \\(\\hat{y}\\) and with a standard deviation denoted with \\(\\sigma\\). This can be denoted as: \\[y_i\\sim Normal(\\mu, \\sigma).\\] The index \\(i\\) indicates each element (i.e. car) of the list \\(y\\), which in turn is the list of distances. 4.6.2.2 Small excursos: “iid” The short model description above incorporates often already an assumption about the distribution of distance-values: . Often the abbreviation can be found for this assumption: \\[y_i\\overset{\\text{iid}}{\\sim} Normal(\\mu, \\sigma).\\] The abbreviation indicates that each value \\(y_i\\) has the same probability function, independent of the other \\(y\\) values and using the same parameters (McElreath 2015). In the third step, a Bayesian perspective is taken the prior knowlege (before seeing the data) has to be defined. The parameters of the current model are the predicted value \\(\\mu\\) and the standard deviation \\(\\sigma\\). For the parameter \\(\\mu\\) a normal distribution can be assumend with parameters that reflect the estimated values from the sample. #descriptive statistics from the sample tibble(variables=c(&quot;speed&quot;, &quot;distance&quot;), mean=c(mean(cars$speed),mean(cars$dist)), sigma = c(sd(cars$speed), sd(cars$dist))) ## # A tibble: 2 x 3 ## variables mean sigma ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 speed 15.4 5.29 ## 2 distance 43.0 25.8 \\[\\mu\\sim Normal(43,26)\\] For the standard deviation \\(\\sigma\\) a uniform distribution is assumed: \\[\\sigma\\sim Uniform(0,40)\\] 4.6.3 Notation Simple Regression model 4.7 Further elaboration on modeling (in anticipation of the topic “estimation”) 4.7.1 Beta-Binomial model - one group (revisited) Sofar the existence of the underlying probability \\(\\theta\\) for observing head as outcome of a coin flip has been discussed. But the estimation of \\(\\theta\\) has been ignored until yet. Although “estimation” will be topic of next chapter, it is helpful at this point to discuss the introduced models further. In order to estimate \\(\\theta\\) are needed. When it comes to estimation exactly this/these parameter(s) will be the result(s), therefore is is important to see already the connection to the models that were developed in this chapter. For the coin flip example the value of interest is the underlying probability, thus, only one parameter is needed:\\(\\beta_0\\). (Note: Latin letters are used when we refer to the sample, greek letters are used when we refer to the population.) How is \\(\\beta_0\\) linked to the latent variable \\(\\theta\\)? Considering for example the simplest case: a (see next plot left side). The problem which arises at this point is that \\(\\theta\\) represents a probability, and is therefore bounded to the range 0-1 (grey shaded area). #Different relationships between the parameter and expected value x &lt;- seq(from=-4, to=4, length.out = 100) y &lt;- x #linear relationship y.log &lt;- inv_logit_scaled(x) #logistic relationship par(mfrow = c(1, 2)) #set both plot beside each other plot(x,y,type=&quot;l&quot;, ylab=expression(theta), xlab=expression(beta[0])) rect(-5,0,5,1,col = rgb(0.5,0.5,0.5,1/4), border = NA) plot(x,y.log,type=&quot;l&quot;, ylab=expression(logit~(theta)), xlab=expression(beta[0])) rect(-5,0,5,1,col = rgb(0.5,0.5,0.5,1/4), border = NA) A mathematical transformation is needed such that the parameter \\(\\beta_0\\) can take any value while \\(\\theta\\) is bounded to the range 0-1. One transformation that offers exactly this possibility is the (see aboth plot right side) \\[logit(\\theta) = \\beta_0.\\] As the underlying assumption maps the parameter to the latent variable \\(\\theta\\) (and not the other way around) from a conceptional point of view the is more appropriate, which is the in this case: \\[\\theta = logistic(\\beta_0).\\] It is defined as \\[\\theta=\\frac{exp(\\beta_0)}{1+exp(\\beta_0)}.\\] Both expression, and link achieve mathematically the same result but it is conceptionally just a different matter of emphasis (Kruschke 2015). 4.7.1.1 Notation of beta-binomial model - one group (revisited) The current descriptive model incorporates the idea that parameter \\(\\beta_0\\) is estimated from the given sample. It defines the latent variable \\(\\theta\\). The parameter is maped to \\(\\theta\\) by a logistic link function. The underlying probability \\(\\theta\\) designates the observed number of upcoming heads. The number of upcoming heads in turn, is assumed to be distributed as Binomial distribution. 4.7.2 Beta-Binomial model - two groups (revisited) In the above model for two coins the latent variable \\(\\delta\\) was already introduced. It is defined by the difference between the underlying probabilities \\(\\theta_1-\\theta_2\\). Which parameters should be used in order to estimate the difference between both groups? As we will see, it turns out that the same mathematical form can be used, as one would use for simple linear regression: \\[\\theta_j=\\beta_0+\\beta_1*X_{Group_j},\\] \\[\\textrm{with } X_{Group_j}=\\begin{cases} 0, \\textrm{if coin 2,}\\\\ 1, \\textrm{if coin 1.} \\end{cases}\\] Considering coin 2, the above equation would result in \\[\\theta_2 = \\beta_0,\\] which is the and indicates the proportion of head coming up for coin 2. Considering by contrast coin 1, then the equation would result in: \\[\\theta_1 = \\beta_0 + \\beta_1.\\] The proportion of coming up head for coin 1 has to be calcuated by summing up the \\(\\beta_0\\) and the \\(\\beta_1\\). Taken togehter: What is the interpretation of the slope \\(\\beta_1\\)? The difference \\(\\delta=\\theta_1-\\theta2\\) is \\[\\theta_1 - \\theta_2 = (\\beta_0+\\beta_1)-\\beta_0=\\beta_1=\\delta,\\] the slope \\(\\beta_1\\), thus, we can see that this parameterization enables us to estimate the difference between two groups. When in comes to estimation and interpretation the results will be the intercept \\(b_0\\) and the slope \\(b_1\\). 4.7.3 Simple linear regression model (revisited) References "],
["inference.html", "5 Inference", " 5 Inference MLE vs posterior confidence intervals credible intervals briefly: algorithms for MLE &amp; Bayesian inference "],
["hypothesis-testing.html", "6 Hypothesis Testing", " 6 Hypothesis Testing binomial test t-test ANOVA linear regression "],
["model-comparison.html", "7 Model Comparison", " 7 Model Comparison AIC likelihood ratio test Bayes factor "],
["generalized-regression-modeling.html", "8 Generalized Regression Modeling", " 8 Generalized Regression Modeling applications "],
["references.html", "References", " References "]
]

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>References | Introduction to Data Analysis</title>
  <meta name="description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="generator" content="bookdown 0.16.5 and GitBook 2.6.7" />

  <meta property="og:title" content="References | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="References | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  

<meta name="author" content="Michael Franke" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="app-93-data-sets-avocado.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!--<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.css">-->
<link rel="stylesheet" href="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.css">

<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-editor-1.0.9.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-viz-0.7.11.js"></script>
<script src="https://s3-us-west-2.amazonaws.com/cdn.webppl.org/webppl-v0.9.13.js" defer async></script>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
<link rel="stylesheet" href="webppl-editor.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="Chap-01-00-intro-learning-goals.html"><a href="Chap-01-00-intro-learning-goals.html"><i class="fa fa-check"></i><b>1.1</b> Learning goals</a></li>
<li class="chapter" data-level="1.2" data-path="Chap-01-00-intro-course-structure.html"><a href="Chap-01-00-intro-course-structure.html"><i class="fa fa-check"></i><b>1.2</b> Course structure</a></li>
<li class="chapter" data-level="1.3" data-path="Chap-01-00-intro-tools-methods.html"><a href="Chap-01-00-intro-tools-methods.html"><i class="fa fa-check"></i><b>1.3</b> Tools and topics covered (and not covered) here</a></li>
<li class="chapter" data-level="1.4" data-path="Chap-01-00-intro-data-sets.html"><a href="Chap-01-00-intro-data-sets.html"><i class="fa fa-check"></i><b>1.4</b> Data sets covered</a></li>
<li class="chapter" data-level="1.5" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html"><i class="fa fa-check"></i><b>1.5</b> Installation</a><ul>
<li class="chapter" data-level="1.5.1" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html#Chap-01-00-intro-installation-VirtualBox"><i class="fa fa-check"></i><b>1.5.1</b> VirtualBox Setup</a></li>
<li class="chapter" data-level="1.5.2" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html#Chap-01-00-intro-installation-Manual"><i class="fa fa-check"></i><b>1.5.2</b> Manual installation</a></li>
<li class="chapter" data-level="1.5.3" data-path="Chap-01-00-intro-installation.html"><a href="Chap-01-00-intro-installation.html#Chap-01-00-intro-installation-Updating"><i class="fa fa-check"></i><b>1.5.3</b> Updating the course package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Chap-01-01-R.html"><a href="Chap-01-01-R.html"><i class="fa fa-check"></i><b>2</b> Basics of R</a><ul>
<li class="chapter" data-level="2.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html"><i class="fa fa-check"></i><b>2.1</b> First steps</a><ul>
<li class="chapter" data-level="2.1.1" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#functions"><i class="fa fa-check"></i><b>2.1.1</b> Functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#variables"><i class="fa fa-check"></i><b>2.1.2</b> Variables</a></li>
<li class="chapter" data-level="2.1.3" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#literate-coding"><i class="fa fa-check"></i><b>2.1.3</b> Literate coding</a></li>
<li class="chapter" data-level="2.1.4" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#objects"><i class="fa fa-check"></i><b>2.1.4</b> Objects</a></li>
<li class="chapter" data-level="2.1.5" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#packages"><i class="fa fa-check"></i><b>2.1.5</b> Packages</a></li>
<li class="chapter" data-level="2.1.6" data-path="ch1-first-steps.html"><a href="ch1-first-steps.html#Chap-01-01-R-help"><i class="fa fa-check"></i><b>2.1.6</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html"><i class="fa fa-check"></i><b>2.2</b> Data types</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch1-data-types.html"><a href="ch1-data-types.html#numeric-vectors-matrices"><i class="fa fa-check"></i><b>2.2.1</b> Numeric vectors &amp; matrices</a></li>
<li class="chapter" data-level="2.2.2" data-path="ch1-data-types.html"><a href="ch1-data-types.html#booleans"><i class="fa fa-check"></i><b>2.2.2</b> Booleans</a></li>
<li class="chapter" data-level="2.2.3" data-path="ch1-data-types.html"><a href="ch1-data-types.html#special-values"><i class="fa fa-check"></i><b>2.2.3</b> Special values</a></li>
<li class="chapter" data-level="2.2.4" data-path="ch1-data-types.html"><a href="ch1-data-types.html#characters-strings"><i class="fa fa-check"></i><b>2.2.4</b> Characters (= strings)</a></li>
<li class="chapter" data-level="2.2.5" data-path="ch1-data-types.html"><a href="ch1-data-types.html#factors"><i class="fa fa-check"></i><b>2.2.5</b> Factors</a></li>
<li class="chapter" data-level="2.2.6" data-path="ch1-data-types.html"><a href="ch1-data-types.html#lists-data-frames-tibbles"><i class="fa fa-check"></i><b>2.2.6</b> Lists, data frames &amp; tibbles</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html"><i class="fa fa-check"></i><b>2.3</b> Functions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#some-important-built-in-functions"><i class="fa fa-check"></i><b>2.3.1</b> Some important built-in functions</a></li>
<li class="chapter" data-level="2.3.2" data-path="Chap-01-01-functions.html"><a href="Chap-01-01-functions.html#defining-your-own-functions"><i class="fa fa-check"></i><b>2.3.2</b> Defining your own functions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ch-01-01-loops-and-maps.html"><a href="ch-01-01-loops-and-maps.html"><i class="fa fa-check"></i><b>2.4</b> Loops and maps</a></li>
<li class="chapter" data-level="2.5" data-path="Chap-01-01-piping.html"><a href="Chap-01-01-piping.html"><i class="fa fa-check"></i><b>2.5</b> Piping</a></li>
<li class="chapter" data-level="2.6" data-path="ch-01-01-Rmarkdown.html"><a href="ch-01-01-Rmarkdown.html"><i class="fa fa-check"></i><b>2.6</b> Rmarkdown</a></li>
</ul></li>
<li class="part"><span><b>II Data</b></span></li>
<li class="chapter" data-level="3" data-path="Chap-02-01-data.html"><a href="Chap-02-01-data.html"><i class="fa fa-check"></i><b>3</b> Data, variables &amp; experimental designs</a><ul>
<li class="chapter" data-level="3.1" data-path="Chap-02-01-data-kinds-of-data.html"><a href="Chap-02-01-data-kinds-of-data.html"><i class="fa fa-check"></i><b>3.1</b> Different kinds of data</a></li>
<li class="chapter" data-level="3.2" data-path="Chap-02-01-data-variables.html"><a href="Chap-02-01-data-variables.html"><i class="fa fa-check"></i><b>3.2</b> On the notion of “variables”</a></li>
<li class="chapter" data-level="3.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html"><i class="fa fa-check"></i><b>3.3</b> Basics of experimental design</a><ul>
<li class="chapter" data-level="3.3.1" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#what-to-analyze-dependent-variables"><i class="fa fa-check"></i><b>3.3.1</b> What to analyze? – Dependent variables</a></li>
<li class="chapter" data-level="3.3.2" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#conditions-trials-items"><i class="fa fa-check"></i><b>3.3.2</b> Conditions, trials, items</a></li>
<li class="chapter" data-level="3.3.3" data-path="Chap-02-01-data-exp-design.html"><a href="Chap-02-01-data-exp-design.html#sample-size"><i class="fa fa-check"></i><b>3.3.3</b> Sample size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="Chap-02-02-data-IO.html"><a href="Chap-02-02-data-IO.html"><i class="fa fa-check"></i><b>4.1</b> Data in, data out</a></li>
<li class="chapter" data-level="4.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html"><i class="fa fa-check"></i><b>4.2</b> Tidy data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#running-example"><i class="fa fa-check"></i><b>4.2.1</b> Running example</a></li>
<li class="chapter" data-level="4.2.2" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>4.2.2</b> Definition of <em>tidy data</em></a></li>
<li class="chapter" data-level="4.2.3" data-path="Chap-02-02-data-tidy-data.html"><a href="Chap-02-02-data-tidy-data.html#excursion-non-redundant-data"><i class="fa fa-check"></i><b>4.2.3</b> Excursion: non-redundant data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html"><i class="fa fa-check"></i><b>4.3</b> Data manipulation: the basics</a><ul>
<li class="chapter" data-level="4.3.1" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#pivoting"><i class="fa fa-check"></i><b>4.3.1</b> Pivoting</a></li>
<li class="chapter" data-level="4.3.2" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#subsetting-row-columns"><i class="fa fa-check"></i><b>4.3.2</b> Subsetting row &amp; columns</a></li>
<li class="chapter" data-level="4.3.3" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#Chap-02-02-tidy-selection"><i class="fa fa-check"></i><b>4.3.3</b> Tidy selection of column names</a></li>
<li class="chapter" data-level="4.3.4" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#adding-changing-and-renaming-columns"><i class="fa fa-check"></i><b>4.3.4</b> Adding, changing and renaming columns</a></li>
<li class="chapter" data-level="4.3.5" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#splitting-and-uniting-columns"><i class="fa fa-check"></i><b>4.3.5</b> Splitting and uniting columns</a></li>
<li class="chapter" data-level="4.3.6" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#sorting-a-data-set"><i class="fa fa-check"></i><b>4.3.6</b> Sorting a data set</a></li>
<li class="chapter" data-level="4.3.7" data-path="Chap-02-02-data-preprocessing-cleaning.html"><a href="Chap-02-02-data-preprocessing-cleaning.html#combining-tibbles"><i class="fa fa-check"></i><b>4.3.7</b> Combining tibbles</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Chap-02-02-data-grouping-nesting.html"><a href="Chap-02-02-data-grouping-nesting.html"><i class="fa fa-check"></i><b>4.4</b> Grouped operations</a></li>
<li class="chapter" data-level="4.5" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html"><i class="fa fa-check"></i><b>4.5</b> Case study: the King of France</a><ul>
<li class="chapter" data-level="4.5.1" data-path="Chap-02-02-data-case-study-KoF.html"><a href="Chap-02-02-data-case-study-KoF.html#cleaning-the-data"><i class="fa fa-check"></i><b>4.5.1</b> Cleaning the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Chap-02-03-summary-statistics.html"><a href="Chap-02-03-summary-statistics.html"><i class="fa fa-check"></i><b>5</b> Summary statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html"><i class="fa fa-check"></i><b>5.1</b> Counts and proportions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#loading-and-inspecting-the-data"><i class="fa fa-check"></i><b>5.1.1</b> Loading and inspecting the data</a></li>
<li class="chapter" data-level="5.1.2" data-path="Chap-02-03-summary-statistics-counts.html"><a href="Chap-02-03-summary-statistics-counts.html#obtaining-counts-with-n-count-and-tally"><i class="fa fa-check"></i><b>5.1.2</b> Obtaining counts with <code>n</code>, <code>count</code> and <code>tally</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html"><i class="fa fa-check"></i><b>5.2</b> Central tendency and dispersion</a><ul>
<li class="chapter" data-level="5.2.1" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#the-data-for-the-remainder-of-the-chapter"><i class="fa fa-check"></i><b>5.2.1</b> The data for the remainder of the chapter</a></li>
<li class="chapter" data-level="5.2.2" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>5.2.2</b> Measures of central tendency</a></li>
<li class="chapter" data-level="5.2.3" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#measures-of-dispersion"><i class="fa fa-check"></i><b>5.2.3</b> Measures of dispersion</a></li>
<li class="chapter" data-level="5.2.4" data-path="Chap-02-03-summary-statistics-1D.html"><a href="Chap-02-03-summary-statistics-1D.html#quantifying-confidence-with-bootstrapping"><i class="fa fa-check"></i><b>5.2.4</b> Quantifying confidence with bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html"><i class="fa fa-check"></i><b>5.3</b> Co-variance &amp; correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#covariance"><i class="fa fa-check"></i><b>5.3.1</b> Covariance</a></li>
<li class="chapter" data-level="5.3.2" data-path="Chap-02-03-summary-statistics-2D.html"><a href="Chap-02-03-summary-statistics-2D.html#correlation"><i class="fa fa-check"></i><b>5.3.2</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Chap-02-02-visualization.html"><a href="Chap-02-02-visualization.html"><i class="fa fa-check"></i><b>6</b> Data Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="Chap-02-04-Anscombe-example.html"><a href="Chap-02-04-Anscombe-example.html"><i class="fa fa-check"></i><b>6.1</b> Motivating example: Anscombe’s quartet</a></li>
<li class="chapter" data-level="6.2" data-path="Chap-02-04-good-visualization.html"><a href="Chap-02-04-good-visualization.html"><i class="fa fa-check"></i><b>6.2</b> Visualization: the good, the bad and the info-graphic</a></li>
<li class="chapter" data-level="6.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html"><i class="fa fa-check"></i><b>6.3</b> Basics of <code>ggplot</code></a><ul>
<li class="chapter" data-level="6.3.1" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#incrementally-composition-of-a-plot"><i class="fa fa-check"></i><b>6.3.1</b> Incrementally composition of a plot</a></li>
<li class="chapter" data-level="6.3.2" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#elements-in-the-layered-grammar-of-graphs"><i class="fa fa-check"></i><b>6.3.2</b> Elements in the layered grammar of graphs</a></li>
<li class="chapter" data-level="6.3.3" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#layers-and-groups"><i class="fa fa-check"></i><b>6.3.3</b> Layers and groups</a></li>
<li class="chapter" data-level="6.3.4" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#grouping"><i class="fa fa-check"></i><b>6.3.4</b> Grouping</a></li>
<li class="chapter" data-level="6.3.5" data-path="Chap-02-04-ggplot.html"><a href="Chap-02-04-ggplot.html#example-of-a-customized-plot"><i class="fa fa-check"></i><b>6.3.5</b> Example of a customized plot</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html"><i class="fa fa-check"></i><b>6.4</b> A rendezvous with popular geoms</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#scatter-plots-with-geom_point"><i class="fa fa-check"></i><b>6.4.1</b> Scatter plots with <code>geom_point</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#smooth"><i class="fa fa-check"></i><b>6.4.2</b> Smooth</a></li>
<li class="chapter" data-level="6.4.3" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#line"><i class="fa fa-check"></i><b>6.4.3</b> Line</a></li>
<li class="chapter" data-level="6.4.4" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#barplot"><i class="fa fa-check"></i><b>6.4.4</b> Barplot</a></li>
<li class="chapter" data-level="6.4.5" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#plotting-distributions-histograms-boxplots-densities-and-violins"><i class="fa fa-check"></i><b>6.4.5</b> Plotting distributions: histograms, boxplots, densities and violins</a></li>
<li class="chapter" data-level="6.4.6" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#rugs"><i class="fa fa-check"></i><b>6.4.6</b> Rugs</a></li>
<li class="chapter" data-level="6.4.7" data-path="Chap-02-04-geoms.html"><a href="Chap-02-04-geoms.html#annotation"><i class="fa fa-check"></i><b>6.4.7</b> Annotation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Chap-02-04-faceting.html"><a href="Chap-02-04-faceting.html"><i class="fa fa-check"></i><b>6.5</b> Faceting</a></li>
<li class="chapter" data-level="6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html"><i class="fa fa-check"></i><b>6.6</b> Customization etc.</a><ul>
<li class="chapter" data-level="6.6.1" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#themes"><i class="fa fa-check"></i><b>6.6.1</b> Themes</a></li>
<li class="chapter" data-level="6.6.2" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#guides"><i class="fa fa-check"></i><b>6.6.2</b> Guides</a></li>
<li class="chapter" data-level="6.6.3" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#axes-ticks-and-tick-labels"><i class="fa fa-check"></i><b>6.6.3</b> Axes, ticks and tick labels</a></li>
<li class="chapter" data-level="6.6.4" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#labels"><i class="fa fa-check"></i><b>6.6.4</b> Labels</a></li>
<li class="chapter" data-level="6.6.5" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#combining-arranging-plots"><i class="fa fa-check"></i><b>6.6.5</b> Combining &amp; arranging plots</a></li>
<li class="chapter" data-level="6.6.6" data-path="Chap-02-04-customization.html"><a href="Chap-02-04-customization.html#latex-expressions-in-plot-labels"><i class="fa fa-check"></i><b>6.6.6</b> LaTeX expressions in plot labels</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Models and inferences</b></span></li>
<li class="chapter" data-level="7" data-path="Chap-03-01-probability.html"><a href="Chap-03-01-probability.html"><i class="fa fa-check"></i><b>7</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="7.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html"><i class="fa fa-check"></i><b>7.1</b> Probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#outcomes-events-observations"><i class="fa fa-check"></i><b>7.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.3" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#interpretations-of-probability"><i class="fa fa-check"></i><b>7.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="7.1.4" data-path="Chap-03-01-probability-basics.html"><a href="Chap-03-01-probability-basics.html#urns-frequencies-distributions-as-samples"><i class="fa fa-check"></i><b>7.1.4</b> Urns, frequencies &amp; distributions as samples</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html"><i class="fa fa-check"></i><b>7.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#probability-table-for-a-flip-and-draw-scenario"><i class="fa fa-check"></i><b>7.2.1</b> Probability table for a flip-and-draw scenario</a></li>
<li class="chapter" data-level="7.2.2" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>7.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="7.2.3" data-path="Chap-03-01-probability-marginal.html"><a href="Chap-03-01-probability-marginal.html#marginalization"><i class="fa fa-check"></i><b>7.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html"><i class="fa fa-check"></i><b>7.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="7.3.1" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#bayes-rule"><i class="fa fa-check"></i><b>7.3.1</b> Bayes rule</a></li>
<li class="chapter" data-level="7.3.2" data-path="Chap-03-01-probability-conditional.html"><a href="Chap-03-01-probability-conditional.html#Chap-03-01-probability-independence"><i class="fa fa-check"></i><b>7.3.2</b> Stochastic (in-)dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html"><i class="fa fa-check"></i><b>7.4</b> Random variables</a><ul>
<li class="chapter" data-level="7.4.1" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#notation-terminology"><i class="fa fa-check"></i><b>7.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="7.4.2" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>7.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
<li class="chapter" data-level="7.4.3" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#expected-value-variance"><i class="fa fa-check"></i><b>7.4.3</b> Expected value &amp; variance</a></li>
<li class="chapter" data-level="7.4.4" data-path="Chap-03-01-probability-random-variables.html"><a href="Chap-03-01-probability-random-variables.html#composite-random-variables"><i class="fa fa-check"></i><b>7.4.4</b> Composite random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="Chap-03-01-probability-R.html"><a href="Chap-03-01-probability-R.html"><i class="fa fa-check"></i><b>7.5</b> Probability distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="Chap-03-03-models.html"><a href="Chap-03-03-models.html"><i class="fa fa-check"></i><b>8</b> Models</a><ul>
<li class="chapter" data-level="8.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html"><i class="fa fa-check"></i><b>8.1</b> Probabilistic models in statistics</a><ul>
<li class="chapter" data-level="8.1.1" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html#Chap-03-03-models-general-urn-example"><i class="fa fa-check"></i><b>8.1.1</b> Example 1: a single draw from an urn</a></li>
<li class="chapter" data-level="8.1.2" data-path="Chap-03-03-models-general.html"><a href="Chap-03-03-models-general.html#example-2-avocado-prices-by-type"><i class="fa fa-check"></i><b>8.1.2</b> Example 2: avocado prices by type</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html"><i class="fa fa-check"></i><b>8.2</b> Parameters, priors, probability and predictions</a><ul>
<li class="chapter" data-level="8.2.1" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#whats-a-model-parameter"><i class="fa fa-check"></i><b>8.2.1</b> What’s a model parameter?</a></li>
<li class="chapter" data-level="8.2.2" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#Chap-03-02-models-priors"><i class="fa fa-check"></i><b>8.2.2</b> Priors over parameters</a></li>
<li class="chapter" data-level="8.2.3" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#two-notions-of-probability-revisited"><i class="fa fa-check"></i><b>8.2.3</b> Two notions of probability (revisited)</a></li>
<li class="chapter" data-level="8.2.4" data-path="Chap-03-03-models-parameters-priors.html"><a href="Chap-03-03-models-parameters-priors.html#prior-predictions"><i class="fa fa-check"></i><b>8.2.4</b> Prior predictions</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="Chap-03-03-models-three-pillars.html"><a href="Chap-03-03-models-three-pillars.html"><i class="fa fa-check"></i><b>8.3</b> Three pillars of data analysis</a></li>
<li class="chapter" data-level="8.4" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html"><i class="fa fa-check"></i><b>8.4</b> Notation &amp; graphical representation</a><ul>
<li class="chapter" data-level="8.4.1" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#formula-notation"><i class="fa fa-check"></i><b>8.4.1</b> Formula notation</a></li>
<li class="chapter" data-level="8.4.2" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#graphical-notation"><i class="fa fa-check"></i><b>8.4.2</b> Graphical notation</a></li>
<li class="chapter" data-level="8.4.3" data-path="Chap-03-03-models-representation.html"><a href="Chap-03-03-models-representation.html#multiple-observations"><i class="fa fa-check"></i><b>8.4.3</b> Multiple observations</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html"><i class="fa fa-check"></i><b>8.5</b> Strolling the zoo of models</a><ul>
<li class="chapter" data-level="8.5.1" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#Chap-03-03-models-examples-binomial"><i class="fa fa-check"></i><b>8.5.1</b> The Binomial Model</a></li>
<li class="chapter" data-level="8.5.2" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#flip-and-draw-model"><i class="fa fa-check"></i><b>8.5.2</b> Flip-and-Draw Model</a></li>
<li class="chapter" data-level="8.5.3" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#flip-and-draw-hypergeometric-model"><i class="fa fa-check"></i><b>8.5.3</b> Flip-and-Draw-Hypergeometric Model</a></li>
<li class="chapter" data-level="8.5.4" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#t-test-model-comparing-two-groups"><i class="fa fa-check"></i><b>8.5.4</b> T-Test Model: comparing two groups</a></li>
<li class="chapter" data-level="8.5.5" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>8.5.5</b> Simple Linear Regression Model</a></li>
<li class="chapter" data-level="8.5.6" data-path="Chap-03-03-models-examples.html"><a href="Chap-03-03-models-examples.html#linear-regression-with-two-groups"><i class="fa fa-check"></i><b>8.5.6</b> Linear Regression with Two Groups</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="Chap-03-03-models-hypotheses.html"><a href="Chap-03-03-models-hypotheses.html"><i class="fa fa-check"></i><b>8.6</b> Expressing hypotheses with models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-03-04-parameter-inference.html"><a href="ch-03-04-parameter-inference.html"><i class="fa fa-check"></i><b>9</b> Parameter estimation</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html"><i class="fa fa-check"></i><b>9.1</b> Bayes rule of parameter estimation</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#the-effects-of-prior-and-likelihood-on-the-posterior"><i class="fa fa-check"></i><b>9.1.1</b> The effects of prior and likelihood on the posterior</a></li>
<li class="chapter" data-level="9.1.2" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#posterior-means-and-credible-intervals"><i class="fa fa-check"></i><b>9.1.2</b> Posterior means and credible intervals</a></li>
<li class="chapter" data-level="9.1.3" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#computing-bayesian-posteriors-with-conjugate-priors"><i class="fa fa-check"></i><b>9.1.3</b> Computing Bayesian posteriors with conjugate priors</a></li>
<li class="chapter" data-level="9.1.4" data-path="ch-03-03-estimation-bayes.html"><a href="ch-03-03-estimation-bayes.html#sequential-updating"><i class="fa fa-check"></i><b>9.1.4</b> Sequential updating</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html"><i class="fa fa-check"></i><b>9.2</b> A frequentist approach to parameter estimation</a><ul>
<li class="chapter" data-level="9.2.1" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html#maximum-likelihood-estimate"><i class="fa fa-check"></i><b>9.2.1</b> Maximum likelihood estimate</a></li>
<li class="chapter" data-level="9.2.2" data-path="ch-03-03-estimation-frequentist.html"><a href="ch-03-03-estimation-frequentist.html#confidence-intervals"><i class="fa fa-check"></i><b>9.2.2</b> Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ch-03-03-estimation-testing.html"><a href="ch-03-03-estimation-testing.html"><i class="fa fa-check"></i><b>9.3</b> Addressing point-valued hypotheses with parameter estimation</a></li>
<li class="chapter" data-level="9.4" data-path="ch-03-03-estimation-comparison.html"><a href="ch-03-03-estimation-comparison.html"><i class="fa fa-check"></i><b>9.4</b> Comparing Bayesian and frequentist estimates</a></li>
<li class="chapter" data-level="9.5" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html"><i class="fa fa-check"></i><b>9.5</b> Algorithms for parameter estimation</a><ul>
<li class="chapter" data-level="9.5.1" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#optimizing-functions"><i class="fa fa-check"></i><b>9.5.1</b> Optimizing functions</a></li>
<li class="chapter" data-level="9.5.2" data-path="Ch-03-03-estimation-algorithms.html"><a href="Ch-03-03-estimation-algorithms.html#approximating-posterior-distributions"><i class="fa fa-check"></i><b>9.5.2</b> Approximating posterior distributions</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html"><i class="fa fa-check"></i><b>9.6</b> Probabilistic modeling with <code>greta</code></a><ul>
<li class="chapter" data-level="9.6.1" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html#basics-of-greta"><i class="fa fa-check"></i><b>9.6.1</b> Basics of <code>greta</code></a></li>
<li class="chapter" data-level="9.6.2" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html#binomial-model"><i class="fa fa-check"></i><b>9.6.2</b> Binomial Model</a></li>
<li class="chapter" data-level="9.6.3" data-path="ch-03-03-estimation-greta.html"><a href="ch-03-03-estimation-greta.html#t-test-model-for-mental-chronometry"><i class="fa fa-check"></i><b>9.6.3</b> T-Test Model for Mental Chronometry</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-03-05-hypothesis-testing.html"><a href="ch-03-05-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html"><i class="fa fa-check"></i><b>10.1</b> <em>p</em>-values</a><ul>
<li class="chapter" data-level="10.1.1" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#binomial-model---frequentist-version"><i class="fa fa-check"></i><b>10.1.1</b> Binomial Model - frequentist version</a></li>
<li class="chapter" data-level="10.1.2" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-for-the-binomial-model"><i class="fa fa-check"></i><b>10.1.2</b> <em>p</em>-values for the Binomial Model</a></li>
<li class="chapter" data-level="10.1.3" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#statistical-significance"><i class="fa fa-check"></i><b>10.1.3</b> Statistical significance</a></li>
<li class="chapter" data-level="10.1.4" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#p-values-and-alpha-errors"><i class="fa fa-check"></i><b>10.1.4</b> <em>p</em>-values and <span class="math inline">\(\alpha\)</span>-errors</a></li>
<li class="chapter" data-level="10.1.5" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#relation-of-p-values-to-confidence-intervals"><i class="fa fa-check"></i><b>10.1.5</b> Relation of <em>p</em>-values to confidence intervals</a></li>
<li class="chapter" data-level="10.1.6" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#distribution-of-p-values"><i class="fa fa-check"></i><b>10.1.6</b> Distribution of <span class="math inline">\(p\)</span>-values</a></li>
<li class="chapter" data-level="10.1.7" data-path="ch-03-05-hypothesis-p-values.html"><a href="ch-03-05-hypothesis-p-values.html#how-not-to-interpret-p-values"><i class="fa fa-check"></i><b>10.1.7</b> How (not) to interpret <em>p</em>-values</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ch-03-05-hypothesis-testing-CLT.html"><a href="ch-03-05-hypothesis-testing-CLT.html"><i class="fa fa-check"></i><b>10.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="10.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html"><i class="fa fa-check"></i><b>10.3</b> Selected tests</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-Pearsons-Chi"><i class="fa fa-check"></i><b>10.3.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span>-tests</a></li>
<li class="chapter" data-level="10.3.2" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-z-test"><i class="fa fa-check"></i><b>10.3.2</b> <em>z</em>-test</a></li>
<li class="chapter" data-level="10.3.3" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-t-test"><i class="fa fa-check"></i><b>10.3.3</b> <em>t</em>-tests</a></li>
<li class="chapter" data-level="10.3.4" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-ANOVA"><i class="fa fa-check"></i><b>10.3.4</b> ANOVA</a></li>
<li class="chapter" data-level="10.3.5" data-path="ch-03-05-hypothesis-testing-tests.html"><a href="ch-03-05-hypothesis-testing-tests.html#ch-03-05-hypothesis-testing-linear-regression"><i class="fa fa-check"></i><b>10.3.5</b> Linear regression</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html"><i class="fa fa-check"></i><b>10.4</b> Three approaches</a><ul>
<li class="chapter" data-level="10.4.1" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#fisher"><i class="fa fa-check"></i><b>10.4.1</b> Fisher</a></li>
<li class="chapter" data-level="10.4.2" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#neyman-pearson"><i class="fa fa-check"></i><b>10.4.2</b> Neyman-Pearson</a></li>
<li class="chapter" data-level="10.4.3" data-path="ch-03-05-hypothesis-testing-3-approaches.html"><a href="ch-03-05-hypothesis-testing-3-approaches.html#hypbrid-modern-nhst"><i class="fa fa-check"></i><b>10.4.3</b> Hypbrid modern NHST</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ch-03-05-hypothesis-testing-3-model-checking.html"><a href="ch-03-05-hypothesis-testing-3-model-checking.html"><i class="fa fa-check"></i><b>10.5</b> Relation to model checking Section</a></li>
<li class="chapter" data-level="10.6" data-path="snippets-formal-results.html"><a href="snippets-formal-results.html"><i class="fa fa-check"></i><b>10.6</b> Snippets / Formal results</a><ul>
<li class="chapter" data-level="10.6.1" data-path="snippets-formal-results.html"><a href="snippets-formal-results.html#anova-sum-of-squares-decomposition"><i class="fa fa-check"></i><b>10.6.1</b> ANOVA Sum of Squares decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Chap-03-06-model-comparison.html"><a href="Chap-03-06-model-comparison.html"><i class="fa fa-check"></i><b>11</b> Model Comparison</a></li>
<li class="chapter" data-level="12" data-path="ch-03-07-hypothesis-testing-Bayes.html"><a href="ch-03-07-hypothesis-testing-Bayes.html"><i class="fa fa-check"></i><b>12</b> Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="13" data-path="Chap-03-08-model-criticism.html"><a href="Chap-03-08-model-criticism.html"><i class="fa fa-check"></i><b>13</b> Model criticism</a></li>
<li class="part"><span><b>IV Appliied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="14" data-path="Chap-04-01-simple-linear-regression.html"><a href="Chap-04-01-simple-linear-regression.html"><i class="fa fa-check"></i><b>14</b> Simple linear regression</a></li>
<li class="chapter" data-level="15" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>15</b> Logistic regression</a><ul>
<li class="chapter" data-level="15.0.1" data-path="logistic-regression.html"><a href="logistic-regression.html#beta-binomial-model---one-group-revisited"><i class="fa fa-check"></i><b>15.0.1</b> Beta-Binomial model - one group (revisited)</a></li>
<li class="chapter" data-level="15.0.2" data-path="logistic-regression.html"><a href="logistic-regression.html#beta-binomial-model---two-groups-revisited"><i class="fa fa-check"></i><b>15.0.2</b> Beta-Binomial model - two groups (revisited)</a></li>
<li class="chapter" data-level="15.0.3" data-path="logistic-regression.html"><a href="logistic-regression.html#simple-linear-regression-model-revisited"><i class="fa fa-check"></i><b>15.0.3</b> Simple linear regression model (revisited)</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="multinomial-regression.html"><a href="multinomial-regression.html"><i class="fa fa-check"></i><b>16</b> Multinomial regression</a></li>
<li class="chapter" data-level="17" data-path="ordinal-regression.html"><a href="ordinal-regression.html"><i class="fa fa-check"></i><b>17</b> Ordinal regression</a></li>
<li class="chapter" data-level="18" data-path="ch-05-05-hierarchical-modeling.html"><a href="ch-05-05-hierarchical-modeling.html"><i class="fa fa-check"></i><b>18</b> Hierarchical regression</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-90-further-material.html"><a href="app-90-further-material.html"><i class="fa fa-check"></i><b>A</b> Further useful material</a><ul>
<li class="chapter" data-level="A.1" data-path="material-on-introduction-to-probability.html"><a href="material-on-introduction-to-probability.html"><i class="fa fa-check"></i><b>A.1</b> Material on <em>Introduction to Probability</em>:</a></li>
<li class="chapter" data-level="A.2" data-path="material-on-bayesian-data-analysis.html"><a href="material-on-bayesian-data-analysis.html"><i class="fa fa-check"></i><b>A.2</b> Material on <em>Bayesian Data Analysis</em>:</a></li>
<li class="chapter" data-level="A.3" data-path="material-on-frequentist-statistics.html"><a href="material-on-frequentist-statistics.html"><i class="fa fa-check"></i><b>A.3</b> Material on <em>frequentist statistics</em>:</a></li>
<li class="chapter" data-level="A.4" data-path="material-on-r-tidyverse-etc-.html"><a href="material-on-r-tidyverse-etc-.html"><i class="fa fa-check"></i><b>A.4</b> Material on <em>R, tidyverse, etc.</em>:</a></li>
<li class="chapter" data-level="A.5" data-path="further-information-for-rstudio.html"><a href="further-information-for-rstudio.html"><i class="fa fa-check"></i><b>A.5</b> Further information for RStudio</a></li>
<li class="chapter" data-level="A.6" data-path="resources-on-webppl.html"><a href="resources-on-webppl.html"><i class="fa fa-check"></i><b>A.6</b> Resources on WebPPL</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="app-91-distributions.html"><a href="app-91-distributions.html"><i class="fa fa-check"></i><b>B</b> Common probability distributions</a><ul>
<li class="chapter" data-level="B.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.1</b> Selected continuous distributions of random variables</a><ul>
<li class="chapter" data-level="B.1.1" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-normal"><i class="fa fa-check"></i><b>B.1.1</b> Normal distribution</a></li>
<li class="chapter" data-level="B.1.2" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-chi2"><i class="fa fa-check"></i><b>B.1.2</b> Chi-squared distribution</a></li>
<li class="chapter" data-level="B.1.3" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#f-distribution"><i class="fa fa-check"></i><b>B.1.3</b> F distribution</a></li>
<li class="chapter" data-level="B.1.4" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-students-t"><i class="fa fa-check"></i><b>B.1.4</b> Student’s <em>t</em>-distribution</a></li>
<li class="chapter" data-level="B.1.5" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#app-91-distributions-beta"><i class="fa fa-check"></i><b>B.1.5</b> Beta distribution</a></li>
<li class="chapter" data-level="B.1.6" data-path="selected-continuous-distributions-of-random-variables.html"><a href="selected-continuous-distributions-of-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>B.1.6</b> Uniform distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html"><i class="fa fa-check"></i><b>B.2</b> Selected discrete distributions of random variables</a><ul>
<li class="chapter" data-level="B.2.1" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-binomial"><i class="fa fa-check"></i><b>B.2.1</b> Binomial distribution</a></li>
<li class="chapter" data-level="B.2.2" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-bernoulli"><i class="fa fa-check"></i><b>B.2.2</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="B.2.3" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#app-91-distributions-beta-binomial"><i class="fa fa-check"></i><b>B.2.3</b> Beta-Binomial distribution</a></li>
<li class="chapter" data-level="B.2.4" data-path="selected-discrete-distributions-of-random-variables.html"><a href="selected-discrete-distributions-of-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>B.2.4</b> Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="understanding-distributions-as-random-variables.html"><a href="understanding-distributions-as-random-variables.html"><i class="fa fa-check"></i><b>B.3</b> Understanding distributions as random variables</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-92-exponential-family.html"><a href="app-92-exponential-family.html"><i class="fa fa-check"></i><b>C</b> Exponential Family and Maximum Entropy</a><ul>
<li class="chapter" data-level="C.1" data-path="an-important-family-the-exponential-family.html"><a href="an-important-family-the-exponential-family.html"><i class="fa fa-check"></i><b>C.1</b> An important family: The Exponential Family</a></li>
<li class="chapter" data-level="C.2" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html"><i class="fa fa-check"></i><b>C.2</b> Excursos: “Information Entropy” and “Maximum Entropy Principal”</a><ul>
<li class="chapter" data-level="C.2.1" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html#information-entropy"><i class="fa fa-check"></i><b>C.2.1</b> Information Entropy</a></li>
<li class="chapter" data-level="C.2.2" data-path="excursos-information-entropy-and-maximum-entropy-principal.html"><a href="excursos-information-entropy-and-maximum-entropy-principal.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>C.2.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="app-93-data-sets.html"><a href="app-93-data-sets.html"><i class="fa fa-check"></i><b>D</b> Data sets used in the book</a><ul>
<li class="chapter" data-level="D.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html"><i class="fa fa-check"></i><b>D.1</b> Mental Chronometry</a><ul>
<li class="chapter" data-level="D.1.1" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#nature-origin-and-rationale-of-the-data"><i class="fa fa-check"></i><b>D.1.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.1.2" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#loading-and-preprocessing-the-data"><i class="fa fa-check"></i><b>D.1.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.1.3" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#cleaning-the-data-1"><i class="fa fa-check"></i><b>D.1.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.1.4" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#exploration-summary-stats-plots"><i class="fa fa-check"></i><b>D.1.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.1.5" data-path="app-93-data-sets-mental-chronometry.html"><a href="app-93-data-sets-mental-chronometry.html#data-analysis"><i class="fa fa-check"></i><b>D.1.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="simon-task.html"><a href="simon-task.html"><i class="fa fa-check"></i><b>D.2</b> Simon Task</a><ul>
<li class="chapter" data-level="D.2.1" data-path="simon-task.html"><a href="simon-task.html#experiment"><i class="fa fa-check"></i><b>D.2.1</b> Experiment</a></li>
<li class="chapter" data-level="D.2.2" data-path="simon-task.html"><a href="simon-task.html#results"><i class="fa fa-check"></i><b>D.2.2</b> Results</a></li>
<li class="chapter" data-level="D.2.3" data-path="simon-task.html"><a href="simon-task.html#analysis"><i class="fa fa-check"></i><b>D.2.3</b> Analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html"><i class="fa fa-check"></i><b>D.3</b> World Values Survey (wave 6 | 2010-2014)</a><ul>
<li class="chapter" data-level="D.3.1" data-path="world-values-survey-wave-6-2010-2014.html"><a href="world-values-survey-wave-6-2010-2014.html#nature-origin-and-rationale-of-the-data-1"><i class="fa fa-check"></i><b>D.3.1</b> Nature, origin and rationale of the data</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html"><i class="fa fa-check"></i><b>D.4</b> King of France</a><ul>
<li class="chapter" data-level="D.4.1" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#app-93-data-sets-king-of-france-background"><i class="fa fa-check"></i><b>D.4.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.4.2" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#loading-and-preprocessing-the-data-1"><i class="fa fa-check"></i><b>D.4.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.4.3" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#cleaning-the-data-2"><i class="fa fa-check"></i><b>D.4.3</b> Cleaning the data</a></li>
<li class="chapter" data-level="D.4.4" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#exploration-summary-stats-plots-1"><i class="fa fa-check"></i><b>D.4.4</b> Exploration: summary stats &amp; plots</a></li>
<li class="chapter" data-level="D.4.5" data-path="app-93-data-sets-king-of-france.html"><a href="app-93-data-sets-king-of-france.html#data-analysis-1"><i class="fa fa-check"></i><b>D.4.5</b> Data analysis</a></li>
</ul></li>
<li class="chapter" data-level="D.5" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html"><i class="fa fa-check"></i><b>D.5</b> Bio-Logic Jazz-Metal (and where to consume it)</a><ul>
<li class="chapter" data-level="D.5.1" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#nature-origin-and-rationale-of-the-data-2"><i class="fa fa-check"></i><b>D.5.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.5.2" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#loading-and-preprocessing-the-data-2"><i class="fa fa-check"></i><b>D.5.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.5.3" data-path="app-93-data-sets-BLJM.html"><a href="app-93-data-sets-BLJM.html#exploration-counts-plots"><i class="fa fa-check"></i><b>D.5.3</b> Exploration: counts &amp; plots</a></li>
</ul></li>
<li class="chapter" data-level="D.6" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html"><i class="fa fa-check"></i><b>D.6</b> Avocado prices</a><ul>
<li class="chapter" data-level="D.6.1" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#nature-origin-and-rationale-of-the-data-3"><i class="fa fa-check"></i><b>D.6.1</b> Nature, origin and rationale of the data</a></li>
<li class="chapter" data-level="D.6.2" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#loading-and-preprocessing-the-data-3"><i class="fa fa-check"></i><b>D.6.2</b> Loading and preprocessing the data</a></li>
<li class="chapter" data-level="D.6.3" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#summary-statistics"><i class="fa fa-check"></i><b>D.6.3</b> Summary statistics</a></li>
<li class="chapter" data-level="D.6.4" data-path="app-93-data-sets-avocado.html"><a href="app-93-data-sets-avocado.html#plots"><i class="fa fa-check"></i><b>D.6.4</b> Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references">
<div>
<p>Abrusán, Márta, and Kriszta Szendröi. 2013. “Experimenting with the King of France: Topics, Verifiability and Definite Descriptions.” <em>Semantics &amp; Pragmatics</em> 6 (1): 1–43.</p>
</div>
<div>
<p>Academy, Khan. 2019. “Lagrange multipliers, introduction.” 2019. <a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint" class="uri">https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint</a>.</p>
</div>
<div>
<p>Anscombe, F. J. 1973. “Graphs in Statistical Analysis.” <em>The American Statistician</em> 27 (1). [American Statistical Association, Taylor &amp; Francis, Ltd.]: 17–21. <a href="https://doi.org/10.2307/2682899" class="uri">https://doi.org/10.2307/2682899</a>.</p>
</div>
<div>
<p>Blitzstein, Joseph K., and Jessica Hwang. 2014. <em>Introduction to Probability</em>. Chapman; Hall/CRC.</p>
</div>
<div>
<p>Box, George E. P. 1979. “Robustness in the Strategy of Scientific Model Building.” In <em>Robustness in Statistics</em>, edited by R. L. Launer and G. N. Wilkinson, 201–36. Cambridge, MA: Academic Press.</p>
</div>
<div>
<p>Bürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” <em>Journal of Statistical Software</em> 80 (1): 1–28. <a href="https://doi.org/10.18637/jss.v080.i01" class="uri">https://doi.org/10.18637/jss.v080.i01</a>.</p>
</div>
<div>
<p>Carpenter, Bob, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. “Stan: A Probabilistic Programming Language.” <em>Journal of Statistical Software</em> 76 (1). <a href="https://doi.org/10.18637/jss.v076.i01" class="uri">https://doi.org/10.18637/jss.v076.i01</a>.</p>
</div>
<div>
<p>De Martino, Andrea, and Daniele De Martino. 2018. “An Introduction to the Maximum Entropy Approach and its Application to Inference Problems in Biology.” <em>Heliyon</em> 4 (4). Elsevier.</p>
</div>
<div>
<p>Finlayson, Sam. 2017. “Deriving probability distributions using the Principal of Maximum Entropy.” 2017. <a href="https://sgfin.github.io/2017/03/16/Deriving-probability-distributions-using-the-Principle-of-Maximum-Entropy/#introduction ">https://sgfin.github.io/2017/03/16/Deriving-probability-distributions-using-the-Principle-of-Maximum-Entropy/#introduction</a>.</p>
</div>
<div>
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Chapman; Hall/CRC.</p>
</div>
<div>
<p>Gigerenzer, Gerd. 2004. “Mindless Statistics.” <em>Journal of Social Economy</em> 33: 587–606.</p>
</div>
<div>
<p>Golding, Nick. 2019. <em>greta: Simple and Scalable Statistical Modelling in R</em>. <a href="https://CRAN.R-project.org/package=greta" class="uri">https://CRAN.R-project.org/package=greta</a>.</p>
</div>
<div>
<p>Goodman, Noah D, and Andreas Stuhlmüller. 2014. “The Design and Implementation of Probabilistic Programming Languages.” <a href="http://dippl.org" class="uri">http://dippl.org</a>.</p>
</div>
<div>
<p>Haller, Heiko, and Stefan Krauss. 2002. “Misinterpretations of Significance: A Problem Students Share with Their Teachers?” <em>Methods of Psychological Research Online</em> 7 (1): 1–20.</p>
</div>
<div>
<p>Halpern, Joseph Y. 2003. <em>Reasoning about Uncertainty</em>. MIT Press.</p>
</div>
<div>
<p>Healy, Kieran. 2018. <em>Data Visualization</em>. New Jersey, USA: Princeton University Press.</p>
</div>
<div>
<p>Jaynes, Edwin T. 2003. <em>Probability Theory: The Logic of Science</em>. Cambridge university press.</p>
</div>
<div>
<p>Keng, Brian. 2017. “Maximum Entropy Distributions.” 2017. <a href="http://bjlkeng.github.io/posts/maximum-entropy-distributions/ ">http://bjlkeng.github.io/posts/maximum-entropy-distributions/</a>.</p>
</div>
<div>
<p>Klingenberg, Bernhard. n.d. “Art of Stat.” <a href="http://www.artofstat.com/home.html" class="uri">http://www.artofstat.com/home.html</a>.</p>
</div>
<div>
<p>Kruschke, John. 2015. <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press.</p>
</div>
<div>
<p>Lee, Michael D., and Eric-Jan Wagenmakers. 2014. <em>Bayesian cognitive modeling: A practical course</em>. Cambridge university press.</p>
</div>
<div>
<p>McElreath, Richard. 2015. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</em>. Chapman; Hall/CRC.</p>
</div>
<div>
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div>
<p>Reza, Fazlollah M. 1994. <em>An Introduction to Information Theory</em>. Courier Corporation.</p>
</div>
<div>
<p>Tufte, Edward. 1983. <em>The Visual Display of Quantitative Information</em>. Graphics Press.</p>
</div>
<div>
<p>Vallverdú, Jordi. 2016. <em>Bayesians Versus Frequentists: A Philosophical Debate on Statistical Reasoning</em>. Heidelberg: Springer.</p>
</div>
<div>
<p>Wickham, Hadley. 2010. “A Layered Grammar of Graphics.” <em>Journal of Computational and Graphical Statistics</em> 19 (1): 3–28.</p>
</div>
<div>
<p>———. 2014. “Tidy Data.” <em>Journal of Statistical Software</em> 59 (10).</p>
</div>
<div>
<p>———. 2017. <em>tidyverse: Easily Install and Load the ’Tidyverse’</em>. <a href="https://CRAN.R-project.org/package=tidyverse" class="uri">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
<div>
<p>Wickham, Hadley, and Garrett Grolemund. 2016. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. O’Reilly Media, Inc.</p>
</div>
<div>
<p>Winter, Bodo. 2019. <em>Statistics for Linguists: An Introduction Using R</em>. Routledge.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Packages live in the official package repository <a href="https://cran.r-project.org/">CRAN</a>, or are supplied in less standardized forms, e.g., via open repositories, such as GitHub.<a href="Chap-01-01-R.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Line-by-line execution of code is useful for quick development and debugging. Make sure to learn about keyboard shortcuts to execute single lines or chunks of code in your favorite editor, e.g., check the <a href="https://rstudio.com/wp-content/uploads/2016/01/rstudio-IDE-cheatsheet.pdf">RStudio Cheat Sheet</a> for information on its keyboard shortcuts.<a href="ch1-first-steps.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>When starting a session in a terminal, you can exit a running R session by typing <code>quit()</code> or <code>q()</code>.<a href="ch1-first-steps.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>You can produce <code>&lt;-</code> in RStudio with Option-<code>-</code> (on Mac) and Alt-<code>-</code> (on Windows/Linux). For other useful keyboard shortcuts, see <a href="https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts">here</a>.<a href="ch1-first-steps.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>If you are familiar with Python’s <em>scipy</em> and <em>numpy</em> packages, this is R’s default mode of treating numerical information.<a href="ch1-data-types.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Python, on the other hand, uses the reverse <em>row-major mode</em>.<a href="ch1-data-types.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>It is in this sense that the “first index moves fastest” in column-major mode, which is another frequently given explanation of column-major mode.<a href="ch1-data-types.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Notice that we can create strings (actually called ‘characters’ in R) with double quotes<a href="ch1-data-types.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>The pipe symbol <code>%&gt;%</code> can be inserted in RStudio with Ctrl+Shift+M (Win/Linux) or Cmd+Shift+M (Mac).<a href="Chap-01-01-piping.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>A <em>behavioral experiment</em> is an experiment that records participants’ behavioral choices, such as button clicks or linguistic responses in the form of text or speech. This contrasts with, say, <em>neurological experiments</em> in which participants’ brain activity is recorded, such as fMRI or EEG, or, e.g., in a psycholinguistic context, <em>processing-related experiments</em> in which secondary measures of cognitive activity are measured, such as eye-movements, pupil dilation or galvanic skin responses.<a href="Chap-02-01-data.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>We will later speak of <strong>prior/posterior predictions</strong> for this kind of data. Other applicable terms are <strong>repeat data</strong> or sometimes <strong>fake data</strong>.<a href="Chap-02-01-data-kinds-of-data.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>This sense of “data variable” is not to be confused with the notion of a “random variable”, a concept we will introduce later in Section <a href="Chap-03-01-probability-random-variables.html#Chap-03-01-probability-random-variables">7.4</a>. The term “data variable” is not commonly used; the common term is merely “variable”.<a href="Chap-02-01-data-variables.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>The archetypical medical experiment discussed above is a <em>one-factor design</em>. In contrast, the term ‘factorial design’ is usually used to refer to what is also often called a <strong>full factorial design</strong>. These are designs with at least two independent variables.<a href="Chap-02-01-data-exp-design.html#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>Other packages help with reading data from and writing data to other file types, such as excel sheets. Look at the <a href="https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf">data I/O cheat sheet</a> for more information.<a href="Chap-02-02-data-IO.html#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>There are alternative possibilities for specifying names of the value and name column, which allow for more dynamic construction of strings. We will not cover all of these details here, but we will use some of these alternative specifications in subsequent examples.<a href="Chap-02-02-data-preprocessing-cleaning.html#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p>The helpers from the <code>tidyselect</code> package also accept regular expressions.<a href="Chap-02-02-data-preprocessing-cleaning.html#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p>Useful base R functions for obtaining counts are <code>table</code> and <code>prop.table</code>.<a href="Chap-02-03-summary-statistics-counts.html#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>For current purpose it is not important what biased or unbiased estimator is and why this subtle change in the formula matters. We will come back to the issue of estimation in Chapter <a href="ch-03-04-parameter-inference.html#ch-03-04-parameter-inference">9</a>.<a href="Chap-02-03-summary-statistics-1D.html#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p><span class="math inline">\(D^{\textrm{rep}}\)</span> is short for “repeated Data”. We will use this concept more later on. The idea is that we consider “hypothetical data” which we have not perceived, but which we might have. Repeated data is (usually) of the same shape and form as the original, observed data, which is also sometimes noted as <span class="math inline">\(D^{\textrm{obs}}\)</span> for clarity in comparison to <span class="math inline">\(D^{\textrm{rep}}\)</span>.<a href="Chap-02-03-summary-statistics-1D.html#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>It is not important to understand this code when you first read this chapter. But at the end of the chapter you should be able to understand (passively) what is going on here.<a href="Chap-02-04-Anscombe-example.html#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p>If your community only understands scatter plots and bar plots, it will not help communication but only mark you as a pompous show-off if you communicate in any other way, no matter how much better you think this is.<a href="Chap-02-04-good-visualization.html#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>For more disinspiration, see for example <a href="https://www.biostat.wisc.edu/~kbroman/topten_worstgraphs/">this curated list of delightfully bad visualizations from actual publications</a>.<a href="Chap-02-04-good-visualization.html#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>Image retrieved from <a href="http://www.nigelholmes.com">Nigel Holmes’ website</a> website on November 25 2019.<a href="Chap-02-04-good-visualization.html#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>If you run this code for yourself, the output is likely to look different from what is shown here. This is because this web-book uses a default theme for all of its plots. We will come back to customization with themes later.<a href="Chap-02-04-ggplot.html#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p>Notice that, as soon as we add the linear regression line, it makes sense to use the logarith of the <code>total_volume_sold</code> because otherwise the fit is quite ridiculous. The logarithm helps to spread out the large number of data points where <code>total_volume_sold</code> is very low, and to “bring back to the flock” the data points where the <code>total_volume_sold</code> is outliery high. It can be quite useful to use such transformations, if they are well understood. It is controversial whether such transformations should precede statistical analyses, but that is not important right now.<a href="Chap-02-04-ggplot.html#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p>For simplicity of exposure, we gloss over subtleties arising when
dealing with infinite sets <span class="math inline">\(\Omega\)</span>. We make up for this when we define probability
<em>density</em> functions for continuous random variables, which is all the uncountable
infinity that we will usually be concerned with in applied statistics.<a href="Chap-03-01-probability-basics.html#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>Think of <span class="math inline">\(\Omega\)</span> as a partition of the space of all possible ways in which the world could be, where we lump together into one partition cell all ways in which the world could be that are equivalent regarding those aspects of reality that we are interested in. We do not care whether the coin lands in the mud or in the sand. It only matters whether it came up heads or tails. Each elementary event can be realized in myriad ways. <span class="math inline">\(\Omega\)</span> is our, the modellers’, first crude simplification of nature, abstracting away aspects we currently do not care about.<a href="Chap-03-01-probability-basics.html#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p>A3 is the axiom of <em>countable additivity</em>. Finite additivity may be enough for finite or countable sets <span class="math inline">\(\Omega\)</span>, but infinite additivity is necessary for full generality in the uncountable case.<a href="Chap-03-01-probability-basics.html#fnref28" class="footnote-back">↩</a></p></li>
<li id="fn29"><p>If probabilities are subjective beliefs, a rational agent is, in a sense, normatively required to assign exactly this probability.<a href="Chap-03-01-probability-basics.html#fnref29" class="footnote-back">↩</a></p></li>
<li id="fn30"><p>With
<span class="math inline">\(\Omega_{\text{flip}} = \left \{ \text{heads}, \text{tails} \right \}\)</span> and
<span class="math inline">\(\Omega_{\text{draw}} = \left \{ \text{black}, \text{white} \right \}\)</span>.<a href="Chap-03-01-probability-marginal.html#fnref30" class="footnote-back">↩</a></p></li>
<li id="fn31"><p>This notation, using <span class="math inline">\(\sum\)</span>, assumes that subspaces are countable. In other cases, a parallel definition with integrals can be used.<a href="Chap-03-01-probability-marginal.html#fnref31" class="footnote-back">↩</a></p></li>
<li id="fn32"><p>The term ``marginal distribution’’ derives from such probability tables, where traditionally the sum of each row/column was written in the margins.<a href="Chap-03-01-probability-marginal.html#fnref32" class="footnote-back">↩</a></p></li>
<li id="fn33"><p>We also verbalize this as “the conditional probability of <span class="math inline">\(A\)</span> conditioned on <span class="math inline">\(B\)</span>.”<a href="Chap-03-01-probability-conditional.html#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p>Updating with events which have probability zero entails far more severe adjustments of the underlying belief system than just ruling out information hitherto considered possible. Formal systems that capture such <em>belief revision</em> are studied in formal epistemology <span class="citation">Halpern (<a href="#ref-Halpern2003:Reasoning-about">2003</a>)</span> .<a href="Chap-03-01-probability-conditional.html#fnref34" class="footnote-back">↩</a></p></li>
<li id="fn35"><p>The terms <em>prior</em> and <em>posterior</em>
make sense when we think about an agent’s belief state before (prior to) and after (posterior
to) an observation.<a href="Chap-03-01-probability-conditional.html#fnref35" class="footnote-back">↩</a></p></li>
<li id="fn36"><p>This is not immediately obvious from our definition, but it is intuitive and you can derive it.<a href="Chap-03-01-probability-random-variables.html#fnref36" class="footnote-back">↩</a></p></li>
<li id="fn37"><p>Naturally, <span class="math inline">\(D_{\text{DV}}\)</span> and <span class="math inline">\(D_{\text{IV}}\)</span> are disjoint: it makes no sense to predict or explain <span class="math inline">\(x\)</span> based on an observation of <span class="math inline">\(x\)</span>.<a href="Chap-03-03-models-general.html#fnref37" class="footnote-back">↩</a></p></li>
<li id="fn38"><p>A truncated normal distribution is like a normal distribution, but restricted to a certain range of possible values. In general, if <span class="math inline">\(P\)</span> is a continuous probability distribution on some interval which properly contains <span class="math inline">\([a;b]\)</span>, a truncated version of <span class="math inline">\(P\)</span> to the interval <span class="math inline">\([a;b]\)</span> such that:
<span class="math display">\[ \text{Trunc-}P(x, \text{min} = a, \text{max} = b) = 
\begin{cases} 
\frac{P(x)}{\int_{a}^{b} P(x&#39;) \text{d}x&#39;} &amp; \text{ if } a \le x \le b \\
0 &amp; \text{otherwise}
\end{cases} \]</span> <a href="Chap-03-03-models-general.html#fnref38" class="footnote-back">↩</a></p></li>
<li id="fn39"><p>We should actually speak of a class of (infinitely many) models, all sharing the same likelihood function. Sloppily, we still speak of “the” Binomial Model.<a href="Chap-03-03-models-parameters-priors.html#fnref39" class="footnote-back">↩</a></p></li>
<li id="fn40"><p>We will not go into the topic of objective priors in this course. This is a topic we must reserve for a follow-up course. It is therefore also not important to “see” from Figure <a href="Chap-03-03-models-parameters-priors.html#fig:ch-03-02-models-types-of-priors">8.2</a> how or why the curve shown in an objective prior.<a href="Chap-03-03-models-parameters-priors.html#fnref40" class="footnote-back">↩</a></p></li>
<li id="fn41"><p>With slight but pragmatically justifiable abuse of terminology, we could still speak of the observations <span class="math inline">\(y_i\)</span> in the T-Test Model as iid (independently and identically distributed) if we contextually enrich the intended meaning of “identically distributed” in the obvious way to mean “identically distributed <em>given the group the observation <span class="math inline">\(i\)</span> belongs to</em>”.<a href="Chap-03-03-models-representation.html#fnref41" class="footnote-back">↩</a></p></li>
<li id="fn42"><p>To learn about WebPPL the fast way, try <a href="http://www.problang.org/chapters/app-06-intro-to-webppl.html">this tutorial</a>.<a href="Chap-03-03-models-examples.html#fnref42" class="footnote-back">↩</a></p></li>
<li id="fn43"><p>Since parameter estimation is only about one model, it should do not harm to omit the index <span class="math inline">\(M\)</span> in the probability notation. Moreover, since in many contexts the meaning will be clear enough, we follow common practice and write <span class="math inline">\(P(D \mid \theta)\)</span> as a shortcut for <span class="math inline">\(P(\mathcal{D} = D \mid \Theta = \theta)\)</span>. Here <span class="math inline">\(\mathcal{D}\)</span> is the class of all relevant observable data and <span class="math inline">\(\Theta\)</span> is the range of a possibly high-dimensional vector of parameter values. We diverge from common practice of using capital roman letters for random variables and small roman letters for values from these random variables, because parameter vectors are traditionally written as <span class="math inline">\(\theta\)</span> and the small letter <span class="math inline">\(\textrm{d}\)</span> (albeit non-italic) is reserved fro differentials.<a href="ch-03-03-estimation-bayes.html#fnref43" class="footnote-back">↩</a></p></li>
<li id="fn44"><p>This is also known as <em>Laplace’s
rule</em>, or the <em>rule of succession</em>.<a href="ch-03-03-estimation-bayes.html#fnref44" class="footnote-back">↩</a></p></li>
<li id="fn45"><p>Also frequently called “highest-density intervals”, even when we are dealing not with density but probability mass.<a href="ch-03-03-estimation-bayes.html#fnref45" class="footnote-back">↩</a></p></li>
<li id="fn46"><p>Not all random variables have a credible interval for a given <span class="math inline">\(\gamma\)</span>, according to this definition. A bimodal distribution might not, for example. A bi-modal distribution has two regions of high probability. We can therefore generalize the concept to a finite set of disjoint convex <em>credible regions</em>, all of which have the second property of the definition above and all of which conjointly are realized with <span class="math inline">\(\gamma\%\)</span> probability. Unfortunately, common parlor uses the term “credible interval” to refer to credible regions as well. The same disaster occurs with alternative terms, such as “<span class="math inline">\(\gamma\%\)</span> highest-density intervals”, which also often refers to what should better be called “highest-density regions”.<a href="ch-03-03-estimation-bayes.html#fnref46" class="footnote-back">↩</a></p></li>
<li id="fn47"><p>We will see such an example later for the case of linear regression with correlated independent variables, so-called collinearity.<a href="ch-03-03-estimation-comparison.html#fnref47" class="footnote-back">↩</a></p></li>
<li id="fn48"><p>Even if the math seems daunting, this method is much more tangible and applicable and requires only basic programming experience.<a href="ch-03-03-estimation-comparison.html#fnref48" class="footnote-back">↩</a></p></li>
<li id="fn49"><p>This is already not innocuous. We are fixing, as it were, an assumption about how likely ground-truths should actually occur in the real world.<a href="ch-03-03-estimation-comparison.html#fnref49" class="footnote-back">↩</a></p></li>
<li id="fn50"><p>The term “null hypothesis” does not want to imply that the hypothesis is that some value of interest is equal to zero (although in practice that is frequently the case). The term rather implicates that this hypothesis is put out there in order to be possibly refuted, i.e., nullified, by the data <span class="citation">(Gigerenzer <a href="#ref-Gigerenzer2004:Mindless-Statis">2004</a>)</span>.<a href="ch-03-05-hypothesis-testing.html#fnref50" class="footnote-back">↩</a></p></li>
<li id="fn51"><p>There is no universally accepted Bayesian treatment either. This is why it is important to apply rational deliberation in each case, and not to succumb to the temptation of following easy recipes too quickly.<a href="ch-03-05-hypothesis-testing.html#fnref51" class="footnote-back">↩</a></p></li>
<li id="fn52"><p>To preview later material (see Section <a href="ch-03-05-hypothesis-testing-3-approaches.html#ch-03-05-hypothesis-testing-3-approaches">10.4</a>), the Neyman-Pearson approach goes further and also looks at evidence in favor of the null-hypothesis. It also tries to quantify something like evidence in favor of the research hypothesis. But Fisher’s approach and some flavors of the hybrid approach only consider how much the data speaks against the null hypothesis.<a href="ch-03-05-hypothesis-p-values.html#fnref52" class="footnote-back">↩</a></p></li>
<li id="fn53"><p>This latter aspect has been particularly important historically. Given more readily available computing power, alternative approaches based on Monte Carlo simulation of <span class="math inline">\(p\)</span>-values can also be used.<a href="ch-03-05-hypothesis-p-values.html#fnref53" class="footnote-back">↩</a></p></li>
<li id="fn54"><p>It is admittedly a bit of a notational overkill to write this comparison relation as a function of <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span> (the alternative hypothesis). Other definitions of the <span class="math inline">\(p\)</span>-value do not. But the comparison <em>is</em> context dependent, and you deserve to see this clearly. To see it clearly, a certain heaviness of notation is the price to pay.<a href="ch-03-05-hypothesis-p-values.html#fnref54" class="footnote-back">↩</a></p></li>
<li id="fn55"><p>Most often the random variable capturing the sampling distribution is just written as <span class="math inline">\(T\)</span>, but it does make sense to stress also notationally that <span class="math inline">\(T\)</span> depends crucially on <span class="math inline">\(H_0\)</span>.<a href="ch-03-05-hypothesis-p-values.html#fnref55" class="footnote-back">↩</a></p></li>
<li id="fn56"><p>Here, the bracket notation <span class="math inline">\([ \mathit{Boolean} ]\)</span> is the <a href="https://en.wikipedia.org/wiki/Iverson_bracket">Iverson bracket</a>, evaluation to 1 if the Boolean expression is true and to 0 otherwise.<a href="ch-03-05-hypothesis-p-values.html#fnref56" class="footnote-back">↩</a></p></li>
<li id="fn57"><p>The problem for interval-valued null hypothesis is that we would need to specify some more information about how to rank parameters, if only to say that they are all ranked equally (plausible, <em>a priori</em>), which is something that we try to avoid in frequentist approaches.<a href="ch-03-05-hypothesis-p-values.html#fnref57" class="footnote-back">↩</a></p></li>
<li id="fn58"><p>An important caveat applies here. There can be different (approximate) ways of defining <span class="math inline">\(p\)</span>-values and confidence intervals. The relation described here does not hold, when the (approximate) way of computing the <span class="math inline">\(p\)</span>-value does not match the (approximate) way of computing the confidence interval.<a href="ch-03-05-hypothesis-p-values.html#fnref58" class="footnote-back">↩</a></p></li>
<li id="fn59"><p>Though the result is more general, it is convenient to think of a natural application as the case where all <span class="math inline">\(X_i\)</span> are samples from the exact same distribution.<a href="ch-03-05-hypothesis-testing-CLT.html#fnref59" class="footnote-back">↩</a></p></li>
<li id="fn60"><p>As with the Law of Large Numbers, the most common application is the case where all <span class="math inline">\(X_i\)</span> are samples from the exact same distribution.<a href="ch-03-05-hypothesis-testing-CLT.html#fnref60" class="footnote-back">↩</a></p></li>
<li id="fn61"><p>Notice that for economy or presentation we now (again) gloss over the “raw” data of individual choices, and present the summarized count data instead. In the previous case of the Binomial Test it made good pedagogical sense to tease apart the “raw” observations from the summarized counts because this helped to show what the test statistic is for a case where the choice of test statistic was very, very obvious; so much so, that we would normally not even bother to make it explicit. Now that we understood what a test statistic is in principle, we can gloss over some steps of data summarizing.<a href="ch-03-05-hypothesis-testing-tests.html#fnref61" class="footnote-back">↩</a></p></li>
<li id="fn62"><p>A proof of this fact is non-trivial, but an intuition why this might be so is available, if we think of each cell independently first. In each cell, with more and more samples, the distribution of counts will approximate a normal distribution by the CLT. The <span class="math inline">\(\chi^2\)</span>-distribution rests (by construction) on a sum of squared samples from a standard normal distribution.<a href="ch-03-05-hypothesis-testing-tests.html#fnref62" class="footnote-back">↩</a></p></li>
<li id="fn63"><p>Notice that this is a one-sided test due to the nature of the test statistic, which measures squared deviation from the baseline and not deviation in any particular direction (because it is hard to say what a “direction” would be in this case anyway).<a href="ch-03-05-hypothesis-testing-tests.html#fnref63" class="footnote-back">↩</a></p></li>
<li id="fn64"><p>Notice that the original avocado data set contains information also about the place of measurement, which would in principle allow us to treat the price measurements as paired samples (one pair for each week and place). For simplicity, but with a note of care that this makes us lose possibly relevant structural information, we here treat the avocado data as if it contained unpaired samples.<a href="ch-03-05-hypothesis-testing-tests.html#fnref64" class="footnote-back">↩</a></p></li>
<li id="fn65"><p>This may seem a harsh step, but when data acquisition is cheap, it’s generally not a bad strategy to be very strict in exclusion criteria, and to apply rules that are not strongly context-dependent.<a href="app-93-data-sets-mental-chronometry.html#fnref65" class="footnote-back">↩</a></p></li>
<li id="fn66"><p>We recruited 100 participants, but the data from three participants was not recorded due to technical problems.<a href="app-93-data-sets-king-of-france.html#fnref66" class="footnote-back">↩</a></p></li>
<li id="fn67"><p>These research questions are a compromise between actual theoretical relevance and practical (= educational) considerations.<a href="app-93-data-sets-king-of-france.html#fnref67" class="footnote-back">↩</a></p></li>
<li id="fn68"><p>Notice how easy it is to motivate any-old psychological theory. Some other scientific disciplines are much better at smothering nonsensical ideas from the start.<a href="app-93-data-sets-BLJM.html#fnref68" class="footnote-back">↩</a></p></li>
</ol>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Gigerenzer2004:Mindless-Statis">
<p>Gigerenzer, Gerd. 2004. “Mindless Statistics.” <em>Journal of Social Economy</em> 33: 587–606.</p>
</div>
<div id="ref-Halpern2003:Reasoning-about">
<p>Halpern, Joseph Y. 2003. <em>Reasoning about Uncertainty</em>. MIT Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="app-93-data-sets-avocado.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

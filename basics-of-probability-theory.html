<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Basics of Probability Theory | Introduction to Data Analysis</title>
  <meta name="description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="generator" content="bookdown 0.13.2 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Basics of Probability Theory | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Basics of Probability Theory | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  

<meta name="author" content="" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data.html"/>
<link rel="next" href="models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#testing-showcasing"><i class="fa fa-check"></i><b>0.1</b> Testing / Showcasing</a><ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#quotes"><i class="fa fa-check"></i><b>0.1.1</b> Quotes</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#infobox"><i class="fa fa-check"></i><b>0.1.2</b> Infobox</a></li>
<li class="chapter" data-level="0.1.3" data-path="index.html"><a href="index.html#plots"><i class="fa fa-check"></i><b>0.1.3</b> Plots</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Foundations</b></span></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> Data</a></li>
<li class="chapter" data-level="3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html"><i class="fa fa-check"></i><b>3</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probability"><i class="fa fa-check"></i><b>3.1</b> Probability</a><ul>
<li class="chapter" data-level="3.1.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#outcomes-events-observations"><i class="fa fa-check"></i><b>3.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probability-distributions"><i class="fa fa-check"></i><b>3.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="3.1.3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#interpretations-of-probability"><i class="fa fa-check"></i><b>3.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="3.1.4" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#urns-and-frequencies"><i class="fa fa-check"></i><b>3.1.4</b> Urns and frequencies</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#structured-events-marginal-distributions"><i class="fa fa-check"></i><b>3.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="3.2.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probability-table-for-a-flip--draw-scenario"><i class="fa fa-check"></i><b>3.2.1</b> Probability table for a flip-&amp;-draw scenario</a></li>
<li class="chapter" data-level="3.2.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>3.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="3.2.3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#marginalization"><i class="fa fa-check"></i><b>3.2.3</b> Marginalization</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>3.3</b> Conditional probability</a><ul>
<li class="chapter" data-level="3.3.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#bayes-rule"><i class="fa fa-check"></i><b>3.3.1</b> Bayes rule</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>3.4</b> Random variables</a><ul>
<li class="chapter" data-level="3.4.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#notation-terminology"><i class="fa fa-check"></i><b>3.4.1</b> Notation &amp; terminology</a></li>
<li class="chapter" data-level="3.4.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#cumulative-distribution-functions-mass-density"><i class="fa fa-check"></i><b>3.4.2</b> Cumulative distribution functions, mass &amp; density</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#expected-value-variance"><i class="fa fa-check"></i><b>3.5</b> Expected value &amp; variance</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>4</b> Models</a><ul>
<li class="chapter" data-level="4.1" data-path="models.html"><a href="models.html#overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="models.html"><a href="models.html#two-notions-of-probability"><i class="fa fa-check"></i><b>4.2</b> Two notions of probability</a><ul>
<li class="chapter" data-level="4.2.1" data-path="models.html"><a href="models.html#frequentism-probabilities-as-properties-of-the-world"><i class="fa fa-check"></i><b>4.2.1</b> Frequentism — Probabilities as properties of the world</a></li>
<li class="chapter" data-level="4.2.2" data-path="models.html"><a href="models.html#bayesianism-probabilities-as-subjective-beliefs"><i class="fa fa-check"></i><b>4.2.2</b> Bayesianism — Probabilities as subjective beliefs</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="models.html"><a href="models.html#likelihood-prior-posterior"><i class="fa fa-check"></i><b>4.3</b> Likelihood, Prior, &amp; Posterior</a><ul>
<li class="chapter" data-level="4.3.1" data-path="models.html"><a href="models.html#probability-density-function-vs.likelihood-function"><i class="fa fa-check"></i><b>4.3.1</b> Probability density function vs. Likelihood function</a></li>
<li class="chapter" data-level="4.3.2" data-path="models.html"><a href="models.html#priors"><i class="fa fa-check"></i><b>4.3.2</b> Priors</a></li>
<li class="chapter" data-level="4.3.3" data-path="models.html"><a href="models.html#posterior"><i class="fa fa-check"></i><b>4.3.3</b> Posterior</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="models.html"><a href="models.html#modeling"><i class="fa fa-check"></i><b>4.4</b> Modeling</a><ul>
<li class="chapter" data-level="4.4.1" data-path="models.html"><a href="models.html#introductory-example"><i class="fa fa-check"></i><b>4.4.1</b> Introductory example</a></li>
<li class="chapter" data-level="4.4.2" data-path="models.html"><a href="models.html#steps-of-data-analysis"><i class="fa fa-check"></i><b>4.4.2</b> Steps of Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="models.html"><a href="models.html#notation"><i class="fa fa-check"></i><b>4.5</b> Notation</a><ul>
<li class="chapter" data-level="4.5.1" data-path="models.html"><a href="models.html#textual-notation"><i class="fa fa-check"></i><b>4.5.1</b> Textual notation</a></li>
<li class="chapter" data-level="4.5.2" data-path="models.html"><a href="models.html#graphical-notation"><i class="fa fa-check"></i><b>4.5.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="models.html"><a href="models.html#further-examples"><i class="fa fa-check"></i><b>4.6</b> Further examples</a><ul>
<li class="chapter" data-level="4.6.1" data-path="models.html"><a href="models.html#difference-between-two-groups"><i class="fa fa-check"></i><b>4.6.1</b> Difference between two groups</a></li>
<li class="chapter" data-level="4.6.2" data-path="models.html"><a href="models.html#simple-linear-regression-with-one-metric-predictor"><i class="fa fa-check"></i><b>4.6.2</b> Simple linear regression with one metric predictor</a></li>
<li class="chapter" data-level="4.6.3" data-path="models.html"><a href="models.html#notation-simple-regression-model"><i class="fa fa-check"></i><b>4.6.3</b> Notation Simple Regression model</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="models.html"><a href="models.html#further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation"><i class="fa fa-check"></i><b>4.7</b> Further elaboration on modeling (in anticipation of the topic “estimation”)</a><ul>
<li class="chapter" data-level="4.7.1" data-path="models.html"><a href="models.html#beta-binomial-model---one-group-revisited"><i class="fa fa-check"></i><b>4.7.1</b> Beta-Binomial model - one group (revisited)</a></li>
<li class="chapter" data-level="4.7.2" data-path="models.html"><a href="models.html#beta-binomial-model---two-groups-revisited"><i class="fa fa-check"></i><b>4.7.2</b> Beta-Binomial model - two groups (revisited)</a></li>
<li class="chapter" data-level="4.7.3" data-path="models.html"><a href="models.html#simple-linear-regression-model-revisited"><i class="fa fa-check"></i><b>4.7.3</b> Simple linear regression model (revisited)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>5</b> Inference</a></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="7" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>7</b> Model Comparison</a></li>
<li class="chapter" data-level="8" data-path="bayesian-hypothesis-testing.html"><a href="bayesian-hypothesis-testing.html"><i class="fa fa-check"></i><b>8</b> Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="9" data-path="model-criticism.html"><a href="model-criticism.html"><i class="fa fa-check"></i><b>9</b> Model criticism</a></li>
<li class="part"><span><b>II Appliied (generalized) linear modeling</b></span></li>
<li class="chapter" data-level="10" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>10</b> Simple linear regression</a></li>
<li class="chapter" data-level="11" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>11</b> Logistic regression</a></li>
<li class="chapter" data-level="12" data-path="multinomial-regression.html"><a href="multinomial-regression.html"><i class="fa fa-check"></i><b>12</b> Multinomial regression</a></li>
<li class="chapter" data-level="13" data-path="ordinal-regression.html"><a href="ordinal-regression.html"><i class="fa fa-check"></i><b>13</b> Ordinal regression</a></li>
<li class="chapter" data-level="14" data-path="hierarchical-regression.html"><a href="hierarchical-regression.html"><i class="fa fa-check"></i><b>14</b> Hierarchical regression</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html"><i class="fa fa-check"></i><b>A</b> Appendix: Common probability distributions</a><ul>
<li class="chapter" data-level="A.1" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#excursos-maximum-entropy"><i class="fa fa-check"></i><b>A.1</b> Excursos: Maximum Entropy</a><ul>
<li class="chapter" data-level="A.1.1" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#information-entropy"><i class="fa fa-check"></i><b>A.1.1</b> Information Entropy</a></li>
<li class="chapter" data-level="A.1.2" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#entropy-shannons-theorem"><i class="fa fa-check"></i><b>A.1.2</b> Entropy: Shannon’s theorem</a></li>
<li class="chapter" data-level="A.1.3" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#the-wallis-derivation"><i class="fa fa-check"></i><b>A.1.3</b> The Wallis derivation</a></li>
<li class="chapter" data-level="A.1.4" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#conclusion-maximum-entropy-principle"><i class="fa fa-check"></i><b>A.1.4</b> Conclusion: Maximum Entropy Principle</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#deriving-probability-distributions-using-the-maximum-entropy-principle"><i class="fa fa-check"></i><b>A.2</b> Deriving Probability Distributions using the Maximum Entropy Principle</a><ul>
<li class="chapter" data-level="A.2.1" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#lagrangian-multiplier-technique"><i class="fa fa-check"></i><b>A.2.1</b> Lagrangian multiplier technique</a></li>
<li class="chapter" data-level="A.2.2" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#example-1-derivation-of-maximum-entropy-pdf-with-no-other-constraints"><i class="fa fa-check"></i><b>A.2.2</b> Example 1: Derivation of maximum entropy pdf with no other constraints</a></li>
<li class="chapter" data-level="A.2.3" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#example-2-derivation-of-maximum-entropy-pdf-with-given-mean-mu-and-variance-sigma2"><i class="fa fa-check"></i><b>A.2.3</b> Example 2: Derivation of maximum entropy pdf with given mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#exponential-family-and-maximum-entropy"><i class="fa fa-check"></i><b>A.3</b> Exponential family and Maximum Entropy</a></li>
<li class="chapter" data-level="A.4" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#continous-distributions-of-random-variables"><i class="fa fa-check"></i><b>A.4</b> Continous distributions of random variables</a><ul>
<li class="chapter" data-level="A.4.1" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>A.4.1</b> Normal distribution</a></li>
<li class="chapter" data-level="A.4.2" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#chi-square-distribution"><i class="fa fa-check"></i><b>A.4.2</b> Chi-square distribution</a></li>
<li class="chapter" data-level="A.4.3" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#f-distribution"><i class="fa fa-check"></i><b>A.4.3</b> F distribution</a></li>
<li class="chapter" data-level="A.4.4" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#student-t-distribution-not-part-of-exponential-family"><i class="fa fa-check"></i><b>A.4.4</b> Student t-distribution (not part of exponential family)</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="appendix-common-probability-distributions.html"><a href="appendix-common-probability-distributions.html#discrete-distributions-of-random-variables"><i class="fa fa-check"></i><b>A.5</b> Discrete distributions of random variables</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="basics-of-probability-theory" class="section level1">
<h1><span class="header-section-number">3</span> Basics of Probability Theory</h1>
<p><strong>to be covered:</strong> axiomatic definition, interpretation, joint distributions,
marginalization, conditional probability &amp; Bayes rule. Random variables: discrete and
continuous, expected values &amp; variance, examples.</p>
<p><strong>learning goal:</strong> get comfortable with basic notions of probability theory</p>
<div id="probability" class="section level2">
<h2><span class="header-section-number">3.1</span> Probability</h2>
<div id="outcomes-events-observations" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Outcomes, events, observations</h3>
<p>We are interested in the space <span class="math inline">\(\Omega\)</span> of all <strong>elementary outcome</strong> <span class="math inline">\(\omega_1, \omega_2, \dots\)</span> of a process or event whose execution is (partially) random or
unknown. Elementary outcomes are mutually exclusive. The set <span class="math inline">\(\Omega\)</span> exhausts all
possibilities.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> The set of elementary outcomes of a single coin flip is <span class="math inline">\(\Omega_{\text{coin flip}} =  \left \{ \text{heads}, \text{tails} \right \}\)</span>. The elementary outcomes of tossing a six-sided die is
<span class="math inline">\(\Omega_{\text{standard die}} = \{\)</span> ⚀ , ⚁ , ⚂ , ⚃ ,
⚄ , ⚅ <span class="math inline">\(\}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
</div>
<p>An <strong>event</strong> <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(\Omega\)</span>. Think of an event as a (possibly partial)
observation. We might observe, for instance, not the full outcome of tossing a die, but only
that there is a dot in the middle. This would correspond to the event
<span class="math inline">\(A = \{\)</span> ⚀ , ⚂ , ⚄ <span class="math inline">\(\}\)</span>,
i.e., observing an odd numbered outcome. The <em>trivial observation</em> <span class="math inline">\(A = \Omega\)</span> and the
<em>impossible observation</em> <span class="math inline">\(A = \emptyset\)</span> are counted as events, too. The latter is included for
technical reasons.</p>
<p>For any two events <span class="math inline">\(A, B \subseteq \Omega\)</span>, standard set operations correspond to logical
connections in the usual way. For example, the conjunction <span class="math inline">\(A \cap B\)</span> is the observation of
both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>; the disjunction <span class="math inline">\(A \cup B\)</span> is the observation that it is either <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>;
the negation of <span class="math inline">\(A\)</span>, <span class="math inline">\(\overline{A} = \left \{ \omega \in \Omega \mid \omega \not \in A \right \}\)</span>, is the
observation that it is not <span class="math inline">\(A\)</span>.</p>
</div>
<div id="probability-distributions" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Probability distributions</h3>
<p>A <strong>probability distribution</strong> <span class="math inline">\(P\)</span> over <span class="math inline">\(\Omega\)</span> is a function
<span class="math inline">\(P \ \colon \ \mathfrak{P}(\Omega) \rightarrow \mathbb{R}\)</span> that assigns to all events
<span class="math inline">\(A \subseteq \Omega\)</span> a real number (from the unit interval, see A1 below), such that the following (so-called Kolmogorov axioms) are satisfied:</p>
<p>A1. <span class="math inline">\(0 \le P(A) \le 1\)</span></p>
<p>A2. <span class="math inline">\(P(\Omega) = 1\)</span></p>
<p>A3. $P(A_1 A_2 A_3 ) = P(A_1) + P(A_2) + P(A_3) + $ whenever <span class="math inline">\(A_1, A_2, A_3, \dots\)</span> are mutually exclusive<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Occasionally we encounter notation <span class="math inline">\(P \in \Delta(\Omega)\)</span> to express that <span class="math inline">\(P\)</span> is a probability
distribution over <span class="math inline">\(\Omega\)</span>. (E.g., in physics, theoretical economics or game
theory. Less so in psychology or statistics.) If <span class="math inline">\(\omega \in \Omega\)</span> is an elementary event,
we often write <span class="math inline">\(P(\omega)\)</span> as a shorthand for <span class="math inline">\(P(\left \{ \omega \right \})\)</span>. In fact, if <span class="math inline">\(\Omega\)</span> is
finite, it suffices to assign probabilities to elementary outcomes.</p>
<p>A number of rules follow immediately from of this definition (prove this!):</p>
<p>C1. <span class="math inline">\(P(\emptyset) = 0\)</span></p>
<p>C2. <span class="math inline">\(P(\overline{A}) = 1 - P(A)\)</span></p>
<p>C3. <span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span> for any <span class="math inline">\(A, B \subseteq \Omega\)</span></p>
</div>
<div id="interpretations-of-probability" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Interpretations of probability</h3>
<p>It is reasonably safe, at least preliminarily, to think of probability, as defined above, as a
handy mathematical primitive which is useful for certain applications. There are at least three
ways of thinking about where this primitive probability might come from, roughly paraphrasable
like so:</p>
<ol style="list-style-type: decimal">
<li><strong>Frequentist:</strong> Probabilities are generalizations of intuitions/facts about frequencies of events in
repeated executions of a random event.</li>
<li><strong>Subjectivist:</strong> Probabilities are subjective beliefs by a rational agent who is
uncertain about the outcome of a random event.</li>
<li><strong>Realist:</strong> Probabilities are a property of an intrinsically random world.</li>
</ol>
</div>
<div id="urns-and-frequencies" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Urns and frequencies</h3>
<p>Think of an urn as a container which contains a number of <span class="math inline">\(N &gt; 1\)</span> balls. Balls can be of
different color. For example, let us suppose that our urn has <span class="math inline">\(k &gt; 0\)</span> black balls and <span class="math inline">\(N-k\)</span>
white balls. (There is at least one black and one white ball.) For a single random draw from
our urn we have: <span class="math inline">\(\Omega_{\text{our urn}} = \left \{ \text{white}, \text{black} \right \}\)</span>. If we imagine an
infinite sequence of single draws from our urn, putting whichever ball we drew back in after
every draw, the limiting proportion with which we draw a black ball is
<span class="math inline">\(\frac{k}{N}\)</span>. (If in doubt, execute this experiment. By hand or by computer.) This
statement about frequency is what motivates saying that the probability of drawing a black ball
on a single trial is (or should be<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>)
<span class="math inline">\(P(\text{black}) = \frac{k}{N}\)</span>.</p>
</div>
</div>
<div id="structured-events-marginal-distributions" class="section level2">
<h2><span class="header-section-number">3.2</span> Structured events &amp; marginal distributions</h2>
<div id="probability-table-for-a-flip--draw-scenario" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Probability table for a flip-&amp;-draw scenario</h3>
<p>Suppose we have two urns. Both have <span class="math inline">\(N=10\)</span> balls. Urn 1 has <span class="math inline">\(k_1=2\)</span> black and <span class="math inline">\(N-k_1 = 8\)</span> white
balls. Urn 2 has <span class="math inline">\(k_2=4\)</span> black and <span class="math inline">\(N-k_2=6\)</span> white balls. We sometimes draw from urn 1,
sometimes from urn 2. To decide, we flip a fair coin. If it comes up heads, we draw from urn 1;
if it comes up tails, we draw from urn 2.</p>
<p>An elementary outcome of this two-step process of flip-&amp;-draw is a pair
<span class="math inline">\(\langle \text{outcome-flip}, \text{outcome-draw} \rangle\)</span>. The set of all possible such outcomes is
<span class="math inline">\(\Omega_{\text{flip-&amp;-draw}} = \left \{ \langle \text{heads}, \text{black} \rangle, \langle \text{heads},  \text{white} \rangle, \langle \text{tails}, \text{black} \rangle, \langle \text{tails},  \text{white} \rangle \right \}\)</span>. The probability of event <span class="math inline">\(\langle \text{heads}, \text{black} \rangle\)</span> is given by
multiplying the probability of seeing “heads” on the first flip, which happens with
probability <span class="math inline">\(0.5\)</span>, and then drawing a black ball, which happens with probability <span class="math inline">\(0.2\)</span>, so that
<span class="math inline">\(P(\langle \text{heads}, \text{black} \rangle) = 0.5 \times 0.2 = 0.1\)</span>. The probability distribution
over <span class="math inline">\(\Omega_{\text{flip-draw}}\)</span> is consequently as in
Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a>. (If in doubt, start flipping &amp;
drawing and count your outcomes.)</p>
<table>
<caption><span id="tab:flipdrawprobabilities">Table 3.1: </span>my first table</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">black</th>
<th align="left">white</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>heads</td>
<td align="left"><span class="math inline">\(0.5 \times 0.2 = 0.1\)</span></td>
<td align="left"><span class="math inline">\(0.5 \times 0.4 = 0.2\)</span></td>
</tr>
<tr class="even">
<td>tails</td>
<td align="left"><span class="math inline">\(0.5 \times 0.8 = 0.4\)</span></td>
<td align="left"><span class="math inline">\(0.5 \times 0.6 = 0.3\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="structured-events-and-joint-probability-distributions" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Structured events and joint-probability distributions</h3>
<p>Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a> is an example of a <strong>joint probability distribution</strong> over a structured event space, which here has two dimensions. Since
our space of outcomes is the Cartesian product of two simpler outcome spaces, namely
<span class="math inline">\(\Omega_{flip-\&amp;-draw} = \Omega_{flip} \times \Omega_{draw}\)</span>,<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> we can use notation
<span class="math inline">\(P(\text{heads}, \text{black})\)</span> as shorthand for <span class="math inline">\(P(\langle \text{heads}, \text{black} \rangle)\)</span>. More
generally, if <span class="math inline">\(\Omega = \Omega_1 \times \dots \Omega_n\)</span>, we can think of <span class="math inline">\(P \in \Delta(\Omega)\)</span>
as a joint probability distribution over <span class="math inline">\(n\)</span> subspaces.</p>
</div>
<div id="marginalization" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Marginalization</h3>
<p>If <span class="math inline">\(P\)</span> is a joint-probability distribution over event space <span class="math inline">\(\Omega = \Omega_1 \times \dots \Omega_n\)</span>, the <strong>marginal distribution</strong> over subspace <span class="math inline">\(\Omega_i\)</span>, <span class="math inline">\(1 \le i \le n\)</span> is the probability distribution that assigns to all <span class="math inline">\(A_i \subseteq \Omega_i\)</span> the probability:<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p><span class="math display">\[  P(A_i) = \sum_{A_1 \subseteq \Omega_{1}, \dots , A_{i-1} \subseteq \Omega_{i-1}, A_{i+1} \subseteq \Omega_{i+1}, \dots, A_n \subseteq \Omega_n} P(A_1, \dots, A_{i-1}, A_{i}, A_{i+1}, \dots A_n) \]</span></p>
<p>For example, the marginal distribution over coin flips derivable from the joint probability distribution in Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a> gives <span class="math inline">\(P(\text{heads}) = P(\text{tails}) = 0.5\)</span>, since the sum of each row is exactly <span class="math inline">\(0.5\)</span>. The marginal distribution over flips derivable from Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a> has <span class="math inline">\(P(\text{black}) = 0.3\)</span> and <span class="math inline">\(P(\text{black}) = 0.7\)</span>.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
</div>
</div>
<div id="conditional-probability" class="section level2">
<h2><span class="header-section-number">3.3</span> Conditional probability</h2>
<p>Fix probability distribution <span class="math inline">\(P \in \Delta(\Omega)\)</span> and events <span class="math inline">\(A,B \subseteq \Omega\)</span>. The conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, written as <span class="math inline">\(P(A \mid B)\)</span>, gives the probability of <span class="math inline">\(A\)</span> on the assumption that <span class="math inline">\(B\)</span> is true.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> It is defined like so:</p>
<p><span class="math display">\[P(A \mid B) = \frac{P(A \cap B)}{P(B)}\]</span></p>
<p>Conditional probabilities are only defined when <span class="math inline">\(P(B) &gt; 0\)</span>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> If a dice is unbiased, each of its six faces has equal probability to come up after a toss. The probability of event <span class="math inline">\(B = \{\)</span> ⚀ , ⚂ , ⚄ <span class="math inline">\(\}\)</span> that the tossed number is odd has probability <span class="math inline">\(P(B) = \frac{1}{2}\)</span>. The probability of event <span class="math inline">\(A = \{\)</span> ⚂ , ⚃ , ⚄ , ⚅ <span class="math inline">\(\}\)</span> that the tossed number is bigger than two is <span class="math inline">\(P(A) = \frac{2}{3}\)</span>. The probability that the tossed number is bigger than two  odd is <span class="math inline">\(P(A \cap B) = P(\{\)</span> ⚂ , ⚄ <span class="math inline">\(\}) = \frac{1}{3}\)</span>. The conditional probability of tossing a number that is bigger than two, when we know that the toss is even, is <span class="math inline">\(P(A \mid B) = \frac{1 / 3}{1 / 2} = \frac{2}{3}\)</span>.</p>
</div>
<p>Algorithmically, conditional probability first rules out all events in which <span class="math inline">\(B\)</span> is not true
and then simply renormalizes the probabilities assigned to the remaining events in such a way
that the relative probabilities of surviving events remains unchanged. Given this, another way
of interpreting conditional probability is that <span class="math inline">\(P(A \mid B)\)</span> is what a rational agent
 believe about <span class="math inline">\(A\)</span> after observing that <span class="math inline">\(B\)</span> is in fact true and nothing more. The
agent rules out, possibly hypothetically, that <span class="math inline">\(B\)</span> is false, but otherwise does not change
opinion about the relative probabilities of anything that is compatible with <span class="math inline">\(B\)</span>.</p>
<div id="bayes-rule" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Bayes rule</h3>
<p>Looking back at the joint-probability distribution in Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a>, the conditional probability <span class="math inline">\(P(\text{black} \mid \text{heads})\)</span> of drawing a black ball, given that the initial coin flip
showed heads, can be calculated as follows:</p>
<p><span class="math display">\[
P(\text{black} \mid \text{heads}) = 
\frac{P(\text{black} , \text{heads})}{P(\text{heads})} =  
\frac{0.1}{0.5} = 0.2
\]</span>
This calculation, however, is quite spurious. We knew that already from the way the flip-&amp;-draw scenario was set up. After flipping heads, we draw from urn 1, which has <span class="math inline">\(k=2\)</span> out of <span class="math inline">\(N=10\)</span> black balls, so clearly: if the flip is heads, then the probability of a black ball is <span class="math inline">\(0.2\)</span>. Indeed, in a step-wise random generation process like the flip-&amp;-draw scenario, some conditional probabilities are very clear, and sometimes given by definition. These are, usually, the conditional probabilities that define how the process unfolds forward in time, so to speak.</p>
<p><strong>Bayes rule</strong> is a way of expressing, in a manner of speaking, conditional probabilities in terms of the
“reversed” conditional probabilities:</p>
<p><span class="math display">\[P(B \mid A) = \frac{P(A \mid B) \times P(B)}{P(A)}\]</span></p>
<p>Bayes rule is straightforward corollary of the definition of conditional probabilities,
according to which <span class="math inline">\(P(A \cap B) = P(A \mid B) \times P(B)\)</span>, so that:</p>
<p><span class="math display">\[
P(B \mid A) = 
\frac{P(A \cap B)}{P(A)} = 
\frac{P(A \mid B) \cdot P(B)}{P(A)}
\]</span></p>
<p>Bayes rule allows for reasoning backwards from observed causes to likely underlying effects. When we have a feed-forward model of how unobservable effects probabilistically constrain observable outcomes, Bayes rule allows us to draw inferences about <em>latent/unobservable variables</em> based on the observation of their downstream effects.</p>
<p>Consider yet again the flip-&amp;-draw scenario. But now assume that Jones flipped the coin and
drew a ball. We see that it is black. What is the probability that it was drawn from urn 1,
equivalently, that the coin landed heads? It is not <span class="math inline">\(P(\text{heads}) = 0.5\)</span>, the so-called
<em>prior probability</em> of the coin landing heads. It is a conditional probability, also
called the <em>posterior probability</em>,<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> namely <span class="math inline">\(P(\text{heads} \mid \text{black})\)</span>, but one
that is not as easy and straightforward to write down as the reverse
<span class="math inline">\(P(\text{black} \mid \text{heads})\)</span> of which we said above that it is an almost trivial part of
the set up of the flip-&amp;-draw scenario. It is here that Bayes rule has its purpose:</p>
<p><span class="math display">\[
P(\text{heads} \mid \text{black}) = 
\frac{P(\text{black} \mid \text{heads}) \times P(\text{heads})}{P(\text{black})} =
\frac{0.2 \times 0.5}{0.3} = 
\frac{1}{3}
\]</span>
This result is quite intuitive. Drawing a black ball from urn 2 (i.e., after seeing tails) is twice
as likely as drawing a black ball from urn 1 (i.e., after seeing heads). Consequently, after
seeing a black ball drawn, with equal probabilities of heads and tails, the probability that
the coin landed tails is also twice as large as that it landed heads.</p>
</div>
</div>
<div id="random-variables" class="section level2">
<h2><span class="header-section-number">3.4</span> Random variables</h2>
<p>We have so far define a probability distribution as a function that assigns a probability to
each subset of the space <span class="math inline">\(\Omega\)</span> of elementary outcomes. A special case occurs when we are
interested in a space of numeric outcomes.</p>
<p>A <strong>random variable</strong> is a function <span class="math inline">\(X \ \colon \ \Omega \rightarrow \mathbb{R}\)</span> that
assigns to each elementary outcome a numerical value.</p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> For a single flip of a coin we have <span class="math inline">\(\Omega_{\text{coin flip}} = \left \{ \text{heads}, \text{tails} \right \}\)</span>. A usual way of mapping this onto numerical outcomes is to define <span class="math inline">\(X_{\text{coin flip}} \ \colon \ \text{heads} \mapsto 1; \text{tails} \mapsto 0\)</span>. Less trivially, consider flipping a coin two times. Elementary outcomes should be individuated by the outcome of the first flip and the outcome of the second flip, so that we get:
<span class="math display">\[
    \Omega_{\text{two flips}} = \left \{ \langle \text{heads}, \text{heads} \rangle, \langle \text{heads}, \text{tails} \rangle,
    \langle \text{tails}, \text{heads} \rangle, \langle \text{tails}, \text{tails} \rangle \right \}
\]</span>
Consider the random variable <span class="math inline">\(X_{\text{two flips}}\)</span> that counts the total number of heads. Crucially, <span class="math inline">\(X_{\text{two flips}}(\langle \text{heads}, \text{tails} \rangle) = 1 = X_{\text{two flips}}(\langle \text{tails}, \text{heads} \rangle)\)</span>. We assign the same numerical value to different elementary outcomes.</p>
</div>
<div id="notation-terminology" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Notation &amp; terminology</h3>
<p>Traditionally random variables are represented by capital letters, like <span class="math inline">\(X\)</span>. Variables for the numeric values they take on are written as small letters, like <span class="math inline">\(x\)</span>.</p>
<p>We write <span class="math inline">\(P(X = x)\)</span> as a shorthand for the probability <span class="math inline">\(P(\left \{ \omega \in \Omega \mid X(\omega) = 2 \right \})\)</span> that an event occurs that is mapped onto <span class="math inline">\(x\)</span> by random variable <span class="math inline">\(X\)</span>. For example, if our coin is fair, then <span class="math inline">\(P(X_{\text{two flips}} = x) = 0.5\)</span> for <span class="math inline">\(x=1\)</span> and <span class="math inline">\(0.25\)</span> otherwise. Similarly, we can also write <span class="math inline">\(P(X \le x)\)</span> for the probability of observing an event that <span class="math inline">\(X\)</span> maps to a number not bigger than <span class="math inline">\(x\)</span>.</p>
<p>If the range of <span class="math inline">\(X\)</span> is countable, we say that <span class="math inline">\(X\)</span> is <strong>discrete</strong>. For ease of exposition, we may say that if the range of <span class="math inline">\(X\)</span> is an interval of real numbers, <span class="math inline">\(X\)</span> is called <strong>continuous</strong>.</p>
</div>
<div id="cumulative-distribution-functions-mass-density" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Cumulative distribution functions, mass &amp; density</h3>
<p>For a discrete random variable <span class="math inline">\(X\)</span>, the <strong>cumulative distribution function</strong> <span class="math inline">\(F_X\)</span> associated with <span class="math inline">\(X\)</span> is defined as:
<span class="math display">\[
  F_X(x) = P(X \le x) = \sum_{x&#39; \in \left \{ \text{Rng}(X) \mid x&#39; \le x \right \}} P(X = x)
\]</span>
The <strong>probability mass function</strong> <span class="math inline">\(f_x\)</span> associated with <span class="math inline">\(X\)</span> is defined as:
<span class="math display">\[
  f_X(x) = P(X = x)
\]</span></p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> Suppose we flip a coin with a bias of <span class="math inline">\(\theta\)</span> <span class="math inline">\(n\)</span> times. What is the probability that we will see heads <span class="math inline">\(k\)</span> times? If we map the outcome of heads to 1 and tails to 0, this probability is given by the , as follows:
<span class="math display">\[
    \text{Binom}(K = k ; n, \theta) = \binom{n}{k} \,  \theta^{k} \, (1-\theta)^{n-k}
\]</span>
Here <span class="math inline">\(\binom{n}{k} = \frac{n!}{k!(n-k)!}\)</span> is the binomial coefficient. It gives the number of possibilities of drawing an unordered set with <span class="math inline">\(k\)</span> elements from a set with a total of <span class="math inline">\(n\)</span> elements. Figure <a href="basics-of-probability-theory.html#fig:BinomialDistribution-Mass">3.1</a> gives an example of the Binomial distribution, concretely its probability mass function, for two values of the coin’s bias, <span class="math inline">\(\theta = 0.25\)</span> or <span class="math inline">\(\theta = 0.5\)</span>, when flipping the coin <span class="math inline">\(n=24\)</span> times. Figure <a href="basics-of-probability-theory.html#fig:BinomialDistribution-Cumulative">3.2</a> gives the corresponding cumulative distributions.
<!-- add some more explanation --></p>
<div class="figure" style="text-align: center"><span id="fig:BinomialDistribution-Mass"></span>
<img src="I2DA_files/figure-html/BinomialDistribution-Mass-1.png" alt="Examples of the Binomial distribution. The $y$-axis give the probability of seeing $k$ heads when flipping a coin $n=24$ times with a bias of either $\theta = 0.25$ or $\theta = 0.5$." width="672" />
<p class="caption">
Figure 3.1: Examples of the Binomial distribution. The <span class="math inline">\(y\)</span>-axis give the probability of seeing <span class="math inline">\(k\)</span> heads when flipping a coin <span class="math inline">\(n=24\)</span> times with a bias of either <span class="math inline">\(\theta = 0.25\)</span> or <span class="math inline">\(\theta = 0.5\)</span>.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:BinomialDistribution-Cumulative"></span>
<img src="I2DA_files/figure-html/BinomialDistribution-Cumulative-1.png" alt="Examples of the cumulative distribution of the Binomial. The $y$-axis gives the probability of seeing $k$ or less outcomes of heads when flipping a coin $n=24$ times with a bias of either $\theta = 0.25$ or $\theta = 0.5$." width="672" />
<p class="caption">
Figure 3.2: Examples of the cumulative distribution of the Binomial. The <span class="math inline">\(y\)</span>-axis gives the probability of seeing <span class="math inline">\(k\)</span> or less outcomes of heads when flipping a coin <span class="math inline">\(n=24\)</span> times with a bias of either <span class="math inline">\(\theta = 0.25\)</span> or <span class="math inline">\(\theta = 0.5\)</span>.
</p>
</div>
</div>
<p>For a continuous random variable <span class="math inline">\(X\)</span>, the probability <span class="math inline">\(P(X = x)\)</span> will usually be zero: it is virtually impossible that we will see precisely the value <span class="math inline">\(x\)</span> realized in a random event that can realize uncountably many numerical values of <span class="math inline">\(X\)</span>. However, <span class="math inline">\(P(X \le x)\)</span> does take workable values and so we define the  <span class="math inline">\(F_X\)</span> associated with <span class="math inline">\(X\)</span> as:
<span class="math display">\[
  F_X(x) = P(X \le x)
\]</span>
Instead of a probability <strong>mass</strong> function, we derive a <strong>probability density function</strong> from the cumulative function as:
<span class="math display">\[
  f_X(x) = F&#39;(x)
\]</span>
A probability density function can take values greater than one, unlike a probability mass
function.</p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> The <strong>Gaussian or Normal distribution</strong> characterizes many natural distributions of measurements which are symmetrically spread around a central tendency. It is defined as:
<span class="math display">\[
    \mathcal{N}(X = x ; \mu, \sigma) = \frac{1}{\sqrt{2 \sigma^2 \pi}} \exp \left ( -
      \frac{(x-\mu)^2}{2 \sigma^2} \right)
  \]</span>
where parameter <span class="math inline">\(\mu\)</span> is the <em>mean</em>, the central tendency, and parameter <span class="math inline">\(\sigma\)</span> is the <em>standard deviation</em>. Figure <a href="basics-of-probability-theory.html#fig:NormalDistribution-Density">3.3</a> gives examples of the probability density function of two normal distributions. Figure <a href="basics-of-probability-theory.html#fig:NormalDistribution-Cumulative">3.4</a> gives the corresponding cumulative distribution functions.</p>
<div class="figure" style="text-align: center"><span id="fig:NormalDistribution-Density"></span>
<img src="I2DA_files/figure-html/NormalDistribution-Density-1.png" alt="Examples of the Normal distribution. In both cases $\mu = 0$, once with $\sigma = 1$ and once with $\sigma = 4$" width="672" />
<p class="caption">
Figure 3.3: Examples of the Normal distribution. In both cases <span class="math inline">\(\mu = 0\)</span>, once with <span class="math inline">\(\sigma = 1\)</span> and once with <span class="math inline">\(\sigma = 4\)</span>
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:NormalDistribution-Cumulative"></span>
<img src="I2DA_files/figure-html/NormalDistribution-Cumulative-1.png" alt="Examples of the cumulative normal distribution corresponding to the previous probability density functions." width="672" />
<p class="caption">
Figure 3.4: Examples of the cumulative normal distribution corresponding to the previous probability density functions.
</p>
</div>
</div>
</div>
</div>
<div id="expected-value-variance" class="section level2">
<h2><span class="header-section-number">3.5</span> Expected value &amp; variance</h2>
<p>The <strong>expected value</strong> of a random variable <span class="math inline">\(X\)</span> is a measure of central tendency. It tells us, like the name suggests, which average value of <span class="math inline">\(X\)</span> we can expect when repeatedly sampling from <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> is continuous, the expected value is:
<span class="math display">\[
  \mathbb{E}_X = \sum_{x} x \times f_X(x)
\]</span>
If <span class="math inline">\(X\)</span> is continuous, it is:
<span class="math display">\[
  \mathbb{E}_X = \int x \times f_X(x) \ \text{d}x
\]</span>
The expected value is also frequently called the <strong>mean</strong>.</p>
<p>The <strong>variance</strong> of a random variable <span class="math inline">\(X\)</span> is a measure of how much likely values of <span class="math inline">\(X\)</span> are spread or clustered around the expected value. If <span class="math inline">\(X\)</span> is discrete, the variance is:
<span class="math display">\[
  \text{Var}(X) = \sum_x (\mathbb{E}_X - x)^2 \times f_X(x)
\]</span>
If <span class="math inline">\(X\)</span> is continuous, it is:
<span class="math display">\[
  \text{Var}(X) = \int (\mathbb{E}_X - x)^2 \times f_X(x) \ \text{d}x
\]</span></p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> If we flip a coin with bias <span class="math inline">\(\theta = 0.25\)</span> a total of <span class="math inline">\(n=24\)</span>, we expect on average to see <span class="math inline">\(n \times\theta = 24 \times 0.25 = 6\)</span> outcomes showing heads. The variance is <span class="math inline">\(n \times\theta \times(1-\theta) = 24 \times 0.25 \times 0.75 = \frac{24 \times 3}{16} = \frac{18}{4} = 4.5\)</span>.</p>
<p>The expected value of a normal distribution is just its mean <span class="math inline">\(\mu\)</span> and its variance is <span class="math inline">\(\sigma^2\)</span>.</p>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>For simplicity of exposure, we gloss over subtleties arising when
dealing with infinite sets <span class="math inline">\(\Omega\)</span>. We make up for this when we define probability
<em>density</em> functions for continuous random variables, which is all the uncountable
infinity that we will usually be concerned with in applied statistics.<a href="basics-of-probability-theory.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Think of <span class="math inline">\(\Omega\)</span> as a partition of the space of all possible ways in
which the world could be, where we lump together into one partition cell all ways in which
the world could be that are equivalent regarding those aspects of reality that we are
interested in. We do not care whether the coin lands in the mud or in the sand. It only
matters whether it came up heads or tails. Each elementary event can be realized in myriad
ways. <span class="math inline">\(\Omega\)</span> is our, the modellers’, first crude simplification of nature, abstracting away aspects we
currently do not care about.<a href="basics-of-probability-theory.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>A3 is the axiom of <em>countable additivity</em>. Finite additivity may be enough for finite or countable sets <span class="math inline">\(\Omega\)</span>, but infinite additivity is necessary for full generality in the uncountable case.<a href="basics-of-probability-theory.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>If probabilities are subjective beliefs, a rational
agent is, in a sense, normatively required to assign exactly this probability.<a href="basics-of-probability-theory.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>With
<span class="math inline">\(\Omega_{\text{flip}} = \left \{ \text{heads}, \text{tails} \right \}\)</span> and
<span class="math inline">\(\Omega_{\text{draw}} = \left \{ \text{black}, \text{white} \right \}\)</span>.<a href="basics-of-probability-theory.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>This notation, using <span class="math inline">\(\sum\)</span>, assumes that subspaces are countable. In other cases, a parallel definition with integrals can be used.<a href="basics-of-probability-theory.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>The term ``marginal distribution’’ derives from such probability tables, where traditionally the sum of each row/column was written in the margins.<a href="basics-of-probability-theory.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>We also verbalize this as “the conditional probability of <span class="math inline">\(A\)</span> conditioned on <span class="math inline">\(B\)</span>.”<a href="basics-of-probability-theory.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>Updating with events which have probability zero entails far more severe adjustments of the underlying belief system than just ruling out information hitherto considered possible. Formal systems that capture such <em>belief revision</em> are studied in formal epistemology <span class="citation">Halpern (<a href="#ref-Halpern2003:Reasoning-about">2003</a>)</span> .<a href="basics-of-probability-theory.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>The terms <em>prior</em> and <em>posterior</em>
make sense when we think about an agent’s belief state before (prior to) and after (posterior
to) an observation.<a href="basics-of-probability-theory.html#fnref10" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

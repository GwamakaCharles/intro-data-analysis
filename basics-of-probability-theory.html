<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Basics of Probability Theory | Introduction to Data Analysis</title>
  <meta name="description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="generator" content="bookdown 0.13.2 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Basics of Probability Theory | Introduction to Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  <meta name="github-repo" content="michael-franke/intro-data-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Basics of Probability Theory | Introduction to Data Analysis" />
  
  <meta name="twitter:description" content="Course Material for I2DA-2019 in Cognitive Science at University Osnabrück" />
  

<meta name="author" content="" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data.html"/>
<link rel="next" href="part-4-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#testing-showcasing"><i class="fa fa-check"></i><b>0.1</b> Testing / Showcasing</a><ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#quotes"><i class="fa fa-check"></i><b>0.1.1</b> Quotes</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#infobox"><i class="fa fa-check"></i><b>0.1.2</b> Infobox</a></li>
<li class="chapter" data-level="0.1.3" data-path="index.html"><a href="index.html#plots"><i class="fa fa-check"></i><b>0.1.3</b> Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i><b>1</b> General Introduction</a></li>
<li class="chapter" data-level="2" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>2</b> Data</a></li>
<li class="chapter" data-level="3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html"><i class="fa fa-check"></i><b>3</b> Basics of Probability Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probability"><i class="fa fa-check"></i><b>3.1</b> Probability</a><ul>
<li class="chapter" data-level="3.1.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#outcomes-events-observations"><i class="fa fa-check"></i><b>3.1.1</b> Outcomes, events, observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probability-distributions"><i class="fa fa-check"></i><b>3.1.2</b> Probability distributions</a></li>
<li class="chapter" data-level="3.1.3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#interpretations-of-probability"><i class="fa fa-check"></i><b>3.1.3</b> Interpretations of probability</a></li>
<li class="chapter" data-level="3.1.4" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#urns-and-frequencies"><i class="fa fa-check"></i><b>3.1.4</b> Urns and frequencies</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#structured-events-marginal-distributions"><i class="fa fa-check"></i><b>3.2</b> Structured events &amp; marginal distributions</a><ul>
<li class="chapter" data-level="3.2.1" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#probability-table-for-a-flip--draw-scenario"><i class="fa fa-check"></i><b>3.2.1</b> Probability table for a flip-&amp;-draw scenario</a></li>
<li class="chapter" data-level="3.2.2" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#structured-events-and-joint-probability-distributions"><i class="fa fa-check"></i><b>3.2.2</b> Structured events and joint-probability distributions</a></li>
<li class="chapter" data-level="3.2.3" data-path="basics-of-probability-theory.html"><a href="basics-of-probability-theory.html#marginalization"><i class="fa fa-check"></i><b>3.2.3</b> Marginalization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="part-4-models.html"><a href="part-4-models.html"><i class="fa fa-check"></i><b>4</b> Part 4: Models</a><ul>
<li class="chapter" data-level="4.1" data-path="part-4-models.html"><a href="part-4-models.html#overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="part-4-models.html"><a href="part-4-models.html#two-notions-of-probability"><i class="fa fa-check"></i><b>4.2</b> Two notions of probability</a><ul>
<li class="chapter" data-level="4.2.1" data-path="part-4-models.html"><a href="part-4-models.html#frequentism-probabilities-as-properties-of-the-world"><i class="fa fa-check"></i><b>4.2.1</b> Frequentism — Probabilities as properties of the world</a></li>
<li class="chapter" data-level="4.2.2" data-path="part-4-models.html"><a href="part-4-models.html#bayesianism-probabilities-as-subjective-beliefs"><i class="fa fa-check"></i><b>4.2.2</b> Bayesianism — Probabilities as subjective beliefs</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="part-4-models.html"><a href="part-4-models.html#likelihood-prior-posterior"><i class="fa fa-check"></i><b>4.3</b> Likelihood, Prior, &amp; Posterior</a><ul>
<li class="chapter" data-level="4.3.1" data-path="part-4-models.html"><a href="part-4-models.html#probability-density-function-vs.likelihood-function"><i class="fa fa-check"></i><b>4.3.1</b> Probability density function vs. Likelihood function</a></li>
<li class="chapter" data-level="4.3.2" data-path="part-4-models.html"><a href="part-4-models.html#priors"><i class="fa fa-check"></i><b>4.3.2</b> Priors</a></li>
<li class="chapter" data-level="4.3.3" data-path="part-4-models.html"><a href="part-4-models.html#posterior"><i class="fa fa-check"></i><b>4.3.3</b> Posterior</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="part-4-models.html"><a href="part-4-models.html#modeling"><i class="fa fa-check"></i><b>4.4</b> Modeling</a><ul>
<li class="chapter" data-level="4.4.1" data-path="part-4-models.html"><a href="part-4-models.html#introductory-example"><i class="fa fa-check"></i><b>4.4.1</b> Introductory example</a></li>
<li class="chapter" data-level="4.4.2" data-path="part-4-models.html"><a href="part-4-models.html#steps-of-data-analysis"><i class="fa fa-check"></i><b>4.4.2</b> Steps of Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="part-4-models.html"><a href="part-4-models.html#notation"><i class="fa fa-check"></i><b>4.5</b> Notation</a><ul>
<li class="chapter" data-level="4.5.1" data-path="part-4-models.html"><a href="part-4-models.html#textual-notation"><i class="fa fa-check"></i><b>4.5.1</b> Textual notation</a></li>
<li class="chapter" data-level="4.5.2" data-path="part-4-models.html"><a href="part-4-models.html#graphical-notation"><i class="fa fa-check"></i><b>4.5.2</b> Graphical notation</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="part-4-models.html"><a href="part-4-models.html#further-examples"><i class="fa fa-check"></i><b>4.6</b> Further examples</a><ul>
<li class="chapter" data-level="4.6.1" data-path="part-4-models.html"><a href="part-4-models.html#difference-between-two-groups"><i class="fa fa-check"></i><b>4.6.1</b> Difference between two groups</a></li>
<li class="chapter" data-level="4.6.2" data-path="part-4-models.html"><a href="part-4-models.html#simple-linear-regression-with-one-metric-predictor"><i class="fa fa-check"></i><b>4.6.2</b> Simple linear regression with one metric predictor</a></li>
<li class="chapter" data-level="4.6.3" data-path="part-4-models.html"><a href="part-4-models.html#notation-simple-regression-model"><i class="fa fa-check"></i><b>4.6.3</b> Notation Simple Regression model</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="part-4-models.html"><a href="part-4-models.html#further-elaboration-on-modeling-in-anticipation-of-the-topic-estimation"><i class="fa fa-check"></i><b>4.7</b> Further elaboration on modeling (in anticipation of the topic “estimation”)</a><ul>
<li class="chapter" data-level="4.7.1" data-path="part-4-models.html"><a href="part-4-models.html#beta-binomial-model---one-group-revisited"><i class="fa fa-check"></i><b>4.7.1</b> Beta-Binomial model - one group (revisited)</a></li>
<li class="chapter" data-level="4.7.2" data-path="part-4-models.html"><a href="part-4-models.html#beta-binomial-model---two-groups-revisited"><i class="fa fa-check"></i><b>4.7.2</b> Beta-Binomial model - two groups (revisited)</a></li>
<li class="chapter" data-level="4.7.3" data-path="part-4-models.html"><a href="part-4-models.html#simple-linear-regression-model-revisited"><i class="fa fa-check"></i><b>4.7.3</b> Simple linear regression model (revisited)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>5</b> Inference</a></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="7" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>7</b> Model Comparison</a></li>
<li class="chapter" data-level="8" data-path="generalized-regression-modeling.html"><a href="generalized-regression-modeling.html"><i class="fa fa-check"></i><b>8</b> Generalized Regression Modeling</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="basics-of-probability-theory" class="section level1">
<h1><span class="header-section-number">3</span> Basics of Probability Theory</h1>
<p><strong>to be covered:</strong> axiomatic definition, interpretation, joint distributions,
marginalization, conditional probability &amp; Bayes rule. Random variables: discrete and
continuous, expected values &amp; variance, examples.</p>
<p><strong>learning goal:</strong> get comfortable with basic notions of probability theory</p>
<div id="probability" class="section level2">
<h2><span class="header-section-number">3.1</span> Probability</h2>
<div id="outcomes-events-observations" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Outcomes, events, observations</h3>
<p>We are interested in the space <span class="math inline">\(\Omega\)</span> of all <strong>elementary outcome</strong> <span class="math inline">\(\omega_1, \omega_2, \dots\)</span> of a process or event whose execution is (partially) random or
unknown. Elementary outcomes are mutually exclusive. The set <span class="math inline">\(\Omega\)</span> exhausts all
possibilities.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<div style="background-color:lightgray">
<p><strong>Example.</strong> The set of elementary outcomes of a single coin flip is <span class="math inline">\(\Omega_{\text{coin flip}} =  \left \{ \text{heads}, \text{tails} \right \}\)</span>. The elementary outcomes of tossing a six-sided die is
<span class="math inline">\(\Omega_{\text{standard die}} = \{\)</span> ⚀ , ⚁ , ⚂ , ⚃ ,
⚄ , ⚅ <span class="math inline">\(\}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
</div>
<p>An <strong>event</strong> <span class="math inline">\(A\)</span> is a subset of <span class="math inline">\(\Omega\)</span>. Think of an event as a (possibly partial)
observation. We might observe, for instance, not the full outcome of tossing a die, but only
that there is a dot in the middle. This would correspond to the event
<span class="math inline">\(A = \{\)</span> ⚀ , ⚂ , ⚄ <span class="math inline">\(\}\)</span>,
i.e., observing an odd numbered outcome. The <em>trivial observation</em> <span class="math inline">\(A = \Omega\)</span> and the
<em>impossible observation</em> <span class="math inline">\(A = \emptyset\)</span> are counted as events, too. The latter is included for
technical reasons.</p>
<p>For any two events <span class="math inline">\(A, B \subseteq \Omega\)</span>, standard set operations correspond to logical
connections in the usual way. For example, the conjunction <span class="math inline">\(A \cap B\)</span> is the observation of
both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>; the disjunction <span class="math inline">\(A \cup B\)</span> is the observation that it is either <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>;
the negation of <span class="math inline">\(A\)</span>, <span class="math inline">\(\overline{A} = \left \{ \omega \in \Omega \mid \omega \not \in A \right \}\)</span>, is the
observation that it is not <span class="math inline">\(A\)</span>.</p>
</div>
<div id="probability-distributions" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Probability distributions</h3>
<p>A <strong>probability distribution</strong> <span class="math inline">\(P\)</span> over <span class="math inline">\(\Omega\)</span> is a function
<span class="math inline">\(P \ \colon \ \mathfrak{P}(\Omega) \rightarrow \mathbb{R}\)</span> that assigns to all events
<span class="math inline">\(A \subseteq \Omega\)</span> a real number (from the unit interval, see A1 below), such that the following (so-called Kolmogorov axioms) are satisfied:</p>
<p>A1. <span class="math inline">\(0 \le P(A) \le 1\)</span></p>
<p>A2. <span class="math inline">\(P(\Omega) = 1\)</span></p>
<p>A3. $P(A_1 A_2 A_3 ) = P(A_1) + P(A_2) + P(A_3) + $ whenever <span class="math inline">\(A_1, A_2, A_3, \dots\)</span> are mutually exclusive<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Occasionally we encounter notation <span class="math inline">\(P \in \Delta(\Omega)\)</span> to express that <span class="math inline">\(P\)</span> is a probability
distribution over <span class="math inline">\(\Omega\)</span>. (E.g., in physics, theoretical economics or game
theory. Less so in psychology or statistics.) If <span class="math inline">\(\omega \in \Omega\)</span> is an elementary event,
we often write <span class="math inline">\(P(\omega)\)</span> as a shorthand for <span class="math inline">\(P(\left \{ \omega \right \})\)</span>. In fact, if <span class="math inline">\(\Omega\)</span> is
finite, it suffices to assign probabilities to elementary outcomes.</p>
<p>A number of rules follow immediately from of this definition (prove this!):</p>
<p>C1. <span class="math inline">\(P(\emptyset) = 0\)</span></p>
<p>C2. <span class="math inline">\(P(\overline{A}) = 1 - P(A)\)</span></p>
<p>C3. <span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span> for any <span class="math inline">\(A, B \subseteq \Omega\)</span></p>
</div>
<div id="interpretations-of-probability" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Interpretations of probability</h3>
<p>It is reasonably safe, at least preliminarily, to think of probability, as defined above, as a
handy mathematical primitive which is useful for certain applications. There are at least three
ways of thinking about where this primitive probability might come from, roughly paraphrasable
like so:</p>
<ol style="list-style-type: decimal">
<li><strong>Frequentist:</strong> Probabilities are generalizations of intuitions/facts about frequencies of events in
repeated executions of a random event.</li>
<li><strong>Subjectivist:</strong> Probabilities are subjective beliefs by a rational agent who is
uncertain about the outcome of a random event.</li>
<li><strong>Realist:</strong> Probabilities are a property of an intrinsically random world.</li>
</ol>
</div>
<div id="urns-and-frequencies" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Urns and frequencies</h3>
<p>Think of an urn as a container which contains a number of <span class="math inline">\(N &gt; 1\)</span> balls. Balls can be of
different color. For example, let us suppose that our urn has <span class="math inline">\(k &gt; 0\)</span> black balls and <span class="math inline">\(N-k\)</span>
white balls. (There is at least one black and one white ball.) For a single random draw from
our urn we have: <span class="math inline">\(\Omega_{\text{our urn}} = \left \{ \text{white}, \text{black} \right \}\)</span>. If we imagine an
infinite sequence of single draws from our urn, putting whichever ball we drew back in after
every draw, the limiting proportion with which we draw a black ball is
<span class="math inline">\(\frac{k}{N}\)</span>. (If in doubt, execute this experiment. By hand or by computer.) This
statement about frequency is what motivates saying that the probability of drawing a black ball
on a single trial is (or should be<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>)
<span class="math inline">\(P(\text{black}) = \frac{k}{N}\)</span>.</p>
</div>
</div>
<div id="structured-events-marginal-distributions" class="section level2">
<h2><span class="header-section-number">3.2</span> Structured events &amp; marginal distributions</h2>
<div id="probability-table-for-a-flip--draw-scenario" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Probability table for a flip-&amp;-draw scenario</h3>
<p>Suppose we have two urns. Both have <span class="math inline">\(N=10\)</span> balls. Urn 1 has <span class="math inline">\(k_1=2\)</span> black and <span class="math inline">\(N-k_1 = 8\)</span> white
balls. Urn 2 has <span class="math inline">\(k_2=4\)</span> black and <span class="math inline">\(N-k_2=6\)</span> white balls. We sometimes draw from urn 1,
sometimes from urn 2. To decide, we flip a fair coin. If it comes up heads, we draw from urn 1;
if it comes up tails, we draw from urn 2.</p>
<p>An elementary outcome of this two-step process of flip-&amp;-draw is a pair
<span class="math inline">\(\langle \text{outcome-flip}, \text{outcome-draw} \rangle\)</span>. The set of all possible such outcomes is
<span class="math inline">\(\Omega_{\text{flip-&amp;-draw}} = \left \{ \langle \text{heads}, \text{black} \rangle, \langle \text{heads},  \text{white} \rangle, \langle \text{tails}, \text{black} \rangle, \langle \text{tails},  \text{white} \rangle \right \}\)</span>. The probability of event <span class="math inline">\(\langle \text{heads}, \text{black} \rangle\)</span> is given by
multiplying the probability of seeing “heads” on the first flip, which happens with
probability <span class="math inline">\(0.5\)</span>, and then drawing a black ball, which happens with probability <span class="math inline">\(0.2\)</span>, so that
<span class="math inline">\(P(\langle \text{heads}, \text{black} \rangle) = 0.5 \times 0.2 = 0.1\)</span>. The probability distribution
over <span class="math inline">\(\Omega_{\text{flip-draw}}\)</span> is consequently as in
Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a>. (If in doubt, start flipping &amp;
drawing and count your outcomes.)</p>
<table>
<caption><span id="tab:flipdrawprobabilities">Table 3.1: </span>my first table</caption>
<thead>
<tr class="header">
<th></th>
<th align="left">black</th>
<th align="left">white</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>heads</td>
<td align="left"><span class="math inline">\(0.5 \times 0.2 = 0.1\)</span></td>
<td align="left"><span class="math inline">\(0.5 \times 0.4 = 0.2\)</span></td>
</tr>
<tr class="even">
<td>tails</td>
<td align="left"><span class="math inline">\(0.5 \times 0.8 = 0.4\)</span></td>
<td align="left"><span class="math inline">\(0.5 \times 0.6 = 0.3\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="structured-events-and-joint-probability-distributions" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Structured events and joint-probability distributions</h3>
<p>Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a> is an example of a <strong>joint probability distribution</strong> over a structured event space, which here has two dimensions. Since
our space of outcomes is the Cartesian product of two simpler outcome spaces, namely
<span class="math inline">\(\Omega_{flip-\&amp;-draw} = \Omega_{flip} \times \Omega_{draw}\)</span>,<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> we can use notation
<span class="math inline">\(P(\text{heads}, \text{black})\)</span> as shorthand for <span class="math inline">\(P(\langle \text{heads}, \text{black} \rangle)\)</span>. More
generally, if <span class="math inline">\(\Omega = \Omega_1 \times \dots \Omega_n\)</span>, we can think of <span class="math inline">\(P \in \Delta(\Omega)\)</span>
as a joint probability distribution over <span class="math inline">\(n\)</span> subspaces.</p>
</div>
<div id="marginalization" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Marginalization</h3>
<p>If <span class="math inline">\(P\)</span> is a joint-probability distribution over event space <span class="math inline">\(\Omega = \Omega_1 \times \dots \Omega_n\)</span>, the <strong>marginal distribution</strong> over subspace <span class="math inline">\(\Omega_i\)</span>, <span class="math inline">\(1 \le i \le n\)</span> is the probability distribution that assigns to all <span class="math inline">\(A_i \subseteq \Omega_i\)</span> the probability:<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p><span class="math display">\[  P(A_i) = \sum_{A_1 \subseteq \Omega_{1}, \dots , A_{i-1} \subseteq \Omega_{i-1}, A_{i+1} \subseteq \Omega_{i+1}, \dots, A_n \subseteq \Omega_n} P(A_1, \dots, A_{i-1}, A_{i}, A_{i+1}, \dots A_n) \]</span></p>
<p>For example, the marginal distribution over coin flips derivable from the joint probability distribution in Table <a href="basics-of-probability-theory.html#tab:flipdrawprobabilities">3.1</a> gives <span class="math inline">\(P(\text{heads}) = P(\text{tails}) = 0.5\)</span>, since the sum of each row is exactly <span class="math inline">\(0.5\)</span>. The marginal distribution over flips derivable from Table~ has <span class="math inline">\(P(\text{black}) = 0.3\)</span> and <span class="math inline">\(P(\text{black}) = 0.7\)</span>.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>For simplicity of exposure, we gloss over subtleties arising when
dealing with infinite sets <span class="math inline">\(\Omega\)</span>. We make up for this when we define probability
<em>density</em> functions for continuous random variables, which is all the uncountable
infinity that we will usually be concerned with in applied statistics.<a href="basics-of-probability-theory.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Think of <span class="math inline">\(\Omega\)</span> as a partition of the space of all possible ways in
which the world could be, where we lump together into one partition cell all ways in which
the world could be that are equivalent regarding those aspects of reality that we are
interested in. We do not care whether the coin lands in the mud or in the sand. It only
matters whether it came up heads or tails. Each elementary event can be realized in myriad
ways. <span class="math inline">\(\Omega\)</span> is our, the modellers’, first crude simplification of nature, abstracting away aspects we
currently do not care about.<a href="basics-of-probability-theory.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>A3 is the axiom of <em>countable additivity</em>. Finite additivity may be enough for finite or countable sets <span class="math inline">\(\Omega\)</span>, but infinite additivity is necessary for full generality in the uncountable case.<a href="basics-of-probability-theory.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>If probabilities are subjective beliefs, a rational
agent is, in a sense, normatively required to assign exactly this probability.<a href="basics-of-probability-theory.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>With
<span class="math inline">\(\Omega_{\text{flip}} = \left \{ \text{heads}, \text{tails} \right \}\)</span> and
<span class="math inline">\(\Omega_{\text{draw}} = \left \{ \text{black}, \text{white} \right \}\)</span>.<a href="basics-of-probability-theory.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>This notation, using <span class="math inline">\(\sum\)</span>, assumes that subspaces are countable. In other cases, a parallel definition with integrals can be used.<a href="basics-of-probability-theory.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>The term ``marginal distribution’’ derives from such probability tables, where traditionally the sum of each row/column was written in the margins.<a href="basics-of-probability-theory.html#fnref7" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="part-4-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["I2DA.epub", "I2DA.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
